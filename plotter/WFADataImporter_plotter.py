"""
WFADataImporter_plotter.py

ã€åŠŸèƒ½èªªæ˜ã€‘
------------------------------------------------------------
æœ¬æ¨¡çµ„ç‚º WFA å¯è¦–åŒ–å¹³å°çš„æ•¸æ“šå°å…¥æ ¸å¿ƒæ¨¡çµ„ï¼Œè² è²¬è®€å–å’Œè§£æ wfanalyser ç”¢ç”Ÿçš„ parquet æª”æ¡ˆï¼Œ
æ”¯æ´æƒææŒ‡å®šè³‡æ–™å¤¾ã€è§£æçª—å£æ•¸æ“šã€æ§‹å»ºä¹å®®æ ¼åƒæ•¸çŸ©é™£ã€æå– IS å’Œ OOS æŒ‡æ¨™ã€‚

ã€æµç¨‹èˆ‡æ•¸æ“šæµã€‘
------------------------------------------------------------
- ä¸»æµç¨‹ï¼šæƒæç›®éŒ„ â†’ è®€å–æª”æ¡ˆ â†’ è§£æçª—å£ â†’ æ§‹å»ºä¹å®®æ ¼çŸ©é™£ â†’ çµ„ç¹”æ•¸æ“š â†’ è¿”å›çµæœ

ã€ç¶­è­·èˆ‡æ“´å……é‡é»ã€‘
------------------------------------------------------------
- æ–°å¢æ•¸æ“šæ ¼å¼ã€åƒæ•¸çµæ§‹æ™‚ï¼Œè«‹åŒæ­¥æ›´æ–°é ‚éƒ¨è¨»è§£èˆ‡å°æ‡‰æ¨¡çµ„
- è‹¥ parquet æª”æ¡ˆæ ¼å¼æœ‰è®Šå‹•ï¼Œéœ€åŒæ­¥æ›´æ–°è§£æé‚è¼¯

ã€å¸¸è¦‹æ˜“éŒ¯é»ã€‘
------------------------------------------------------------
- æª”æ¡ˆè·¯å¾‘éŒ¯èª¤æˆ–æª”æ¡ˆä¸å­˜åœ¨
- parquet æª”æ¡ˆæ ¼å¼ä¸ç¬¦åˆé æœŸ
- ä¹å®®æ ¼çŸ©é™£æ§‹å»ºé‚è¼¯éŒ¯èª¤

ã€éŒ¯èª¤è™•ç†ã€‘
------------------------------------------------------------
- æª”æ¡ˆä¸å­˜åœ¨æ™‚æä¾›è©³ç´°éŒ¯èª¤è¨Šæ¯
- è§£æå¤±æ•—æ™‚æä¾›è¨ºæ–·å»ºè­°

ã€ç¯„ä¾‹ã€‘
------------------------------------------------------------
- åŸºæœ¬ä½¿ç”¨ï¼šimporter = WFADataImporter("path/to/wfanalyser")
- è¼‰å…¥æ•¸æ“šï¼šdata = importer.load_all_wfa_files()

ã€èˆ‡å…¶ä»–æ¨¡çµ„çš„é—œè¯ã€‘
------------------------------------------------------------
- è¢« WFAVisualizationPlotter èª¿ç”¨ï¼Œæä¾› WFA æ•¸æ“šå°å…¥åŠŸèƒ½
- ä¾è³´ wfanalyser ç”¢ç”Ÿçš„ parquet æª”æ¡ˆæ ¼å¼
- è¼¸å‡ºæ•¸æ“šä¾› WFADashboardGenerator å’Œ WFACallbackHandler ä½¿ç”¨
- ä½¿ç”¨ plotter/utils/FileUtils_utils_plotter.py é€²è¡Œæ–‡ä»¶æƒæ

ã€åƒè€ƒã€‘
------------------------------------------------------------
- WFAVisualization_plotter.py: WFA å¯è¦–åŒ–å¹³å°ä¸»é¡
- WFADashboardGenerator_plotter.py: WFA ç•Œé¢ç”Ÿæˆå™¨
- plotter/README.md: WFA å¯è¦–åŒ–å¹³å°è©³ç´°èªªæ˜
"""

import ast
import glob
import json
import logging
import os
import re
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
import pyarrow.parquet as pq
from rich.text import Text

from utils import show_step_panel, show_warning, show_info


class WFADataImporter:
    """
    WFA æ•¸æ“šå°å…¥å™¨

    è² è²¬è®€å–å’Œè§£æ wfanalyser ç”¢ç”Ÿçš„ parquet æª”æ¡ˆï¼Œ
    æå–çª—å£æ•¸æ“šã€æ§‹å»ºä¹å®®æ ¼åƒæ•¸çŸ©é™£ã€çµ„ç¹” IS å’Œ OOS æŒ‡æ¨™ã€‚
    """

    def __init__(
        self,
        wfa_data_path: Optional[str] = None,
        metrics_data_path: Optional[str] = None,
        logger: Optional[logging.Logger] = None,
    ):
        """
        åˆå§‹åŒ– WFA æ•¸æ“šå°å…¥å™¨

        Args:
            wfa_data_path: wfanalyser ç”¢ç”Ÿçš„ parquet æª”æ¡ˆç›®éŒ„è·¯å¾‘
            metrics_data_path: metricstracker ç”¢ç”Ÿçš„ parquet æª”æ¡ˆç›®éŒ„è·¯å¾‘ï¼ˆå¯é¸ï¼Œç”¨æ–¼ç²å– Sortinoï¼‰
            logger: æ—¥èªŒè¨˜éŒ„å™¨ï¼Œé è¨­ç‚º None
        """
        # è¨­ç½®é»˜èªè·¯å¾‘
        base_dir = os.path.dirname(os.path.dirname(__file__))
        self.wfa_data_path = (
            wfa_data_path
            or os.path.join(base_dir, "records", "wfanalyser")
        )
        self.metrics_data_path = (
            metrics_data_path
            or os.path.join(base_dir, "records", "metricstracker")
        )

        self.logger = logger or logging.getLogger(__name__)
        self.logger.setLevel(logging.WARNING)
        from utils import get_console
        self.console = get_console()

        # ç¢ºä¿ç›®éŒ„å­˜åœ¨
        if not os.path.exists(self.wfa_data_path):
            raise FileNotFoundError(f"WFA æ•¸æ“šç›®éŒ„ä¸å­˜åœ¨: {self.wfa_data_path}")

    def scan_wfa_parquet_files(self) -> List[str]:
        """
        æƒæ wfanalyser ç›®éŒ„ä¸­çš„ parquet æª”æ¡ˆ

        Returns:
            List[str]: parquet æª”æ¡ˆè·¯å¾‘åˆ—è¡¨
        """
        from .utils.FileUtils_utils_plotter import scan_parquet_files as scan_files
        
        return scan_files(self.wfa_data_path, self.logger)

    def parse_optimal_params(self, params_str: str) -> Dict[str, Any]:
        """
        è§£æ optimal_params å­—ç¬¦ä¸²

        Args:
            params_str: åƒæ•¸å­—ç¬¦ä¸²ï¼Œæ ¼å¼å¦‚ "{'MA1': 50, 'MA4': 110}"

        Returns:
            Dict[str, Any]: è§£æå¾Œçš„åƒæ•¸å­—å…¸
        """
        try:
            # å˜—è©¦ä½¿ç”¨ ast.literal_eval å®‰å…¨è§£æ
            if isinstance(params_str, str):
                params_dict = ast.literal_eval(params_str)
                return params_dict if isinstance(params_dict, dict) else {}
            elif isinstance(params_str, dict):
                return params_str
            else:
                return {}
        except (ValueError, SyntaxError) as e:
            self.logger.warning(f"è§£æ optimal_params å¤±æ•—: {params_str}, éŒ¯èª¤: {e}")
            return {}

    def _extract_indicator_combination(self, row: pd.Series) -> str:
        """
        å¾æ•¸æ“šè¡Œä¸­æå–æŒ‡æ¨™çµ„åˆåç¨±ï¼ˆæ ¼å¼èˆ‡åƒæ•¸é«˜åŸä¸€è‡´ï¼šEntry: PERC2 | Exit: PERC3ï¼‰

        Args:
            row: æ•¸æ“šè¡Œï¼ˆåŒ…å« optimal_paramsï¼‰

        Returns:
            str: æŒ‡æ¨™çµ„åˆåç¨±ï¼Œæ ¼å¼å¦‚ "Entry: MA1 | Exit: MA4" æˆ– "Entry: MA1,MA9 | Exit: MA4"
        """
        try:
            params_str = row.get("optimal_params", "{}")
            param_dict = self.parse_optimal_params(params_str)
            
            if not param_dict:
                # å¦‚æœç„¡æ³•è§£æï¼Œè¿”å›é»˜èªæ ¼å¼
                condition_pair_id = row.get("condition_pair_id", 1)
                return f"ç­–ç•¥ {condition_pair_id}"
            
            # å¾åƒæ•¸éµä¸­æå–æŒ‡æ¨™åç¨±ï¼ˆæ–°æ ¼å¼ï¼š{indicator_name}_{param_name}ï¼‰
            # ä¾‹å¦‚ï¼šMA1_period, MA1_ma_type, HL1_n_length, HL1_m_length
            # éœ€è¦æå–å”¯ä¸€çš„æŒ‡æ¨™åç¨±å‰ç¶´
            indicator_names = set()
            
            for key in param_dict.keys():
                # ç§»é™¤åƒæ•¸å¾Œç¶´ï¼ˆå¦‚ _period, _ma_type, _n_length, _m_length ç­‰ï¼‰
                # åŒ¹é…æ¨¡å¼ï¼šæŒ‡æ¨™åç¨±ï¼ˆå­—æ¯+æ•¸å­—ï¼‰å¾Œè·Ÿä¸‹åŠƒç·šå’Œåƒæ•¸å
                match = re.match(r'^([A-Z]+\d+)_', key)
                if match:
                    indicator_name = match.group(1)  # ä¾‹å¦‚ MA1, HL1, PERC2
                    indicator_names.add(indicator_name)
                else:
                    # å¦‚æœæ²’æœ‰åŒ¹é…æ¨™æº–æ ¼å¼ï¼Œå˜—è©¦æå–åŸºç¤åç¨±
                    base_name = key.split('_')[0]
                    if re.match(r'^[A-Z]+\d+$', base_name):
                        indicator_names.add(base_name)
            
            if not indicator_names:
                condition_pair_id = row.get("condition_pair_id", 1)
                return f"ç­–ç•¥ {condition_pair_id}"
            
            # æ ¹æ“š optimal_params ä¸­åƒæ•¸çš„å‡ºç¾é †åºåˆ¤æ–· entry/exit
            # é€šå¸¸ Entry æŒ‡æ¨™çš„åƒæ•¸æœƒå…ˆå‡ºç¾ï¼ŒExit æŒ‡æ¨™çš„åƒæ•¸å¾Œå‡ºç¾
            entry_indicators = []
            exit_indicators = []
            
            # ç²å–æ‰€æœ‰æŒ‡æ¨™åŠå…¶åœ¨åƒæ•¸éµä¸­é¦–æ¬¡å‡ºç¾çš„é †åº
            indicator_order = {}
            for key in sorted(param_dict.keys()):
                match = re.match(r'^([A-Z]+\d+)_', key)
                if match:
                    indicator_name = match.group(1)
                    if indicator_name not in indicator_order:
                        indicator_order[indicator_name] = len(indicator_order)
            
            # æŒ‰ç…§åœ¨åƒæ•¸ä¸­å‡ºç¾çš„é †åºæ’åºæŒ‡æ¨™
            sorted_indicators = sorted(indicator_names, key=lambda x: indicator_order.get(x, 999))
            
            # å¦‚æœåªæœ‰å…©å€‹æŒ‡æ¨™ï¼Œç¬¬ä¸€å€‹é€šå¸¸æ˜¯ Entryï¼Œç¬¬äºŒå€‹é€šå¸¸æ˜¯ Exit
            # å¦‚æœæœ‰å¤šå€‹æŒ‡æ¨™ï¼Œæ ¹æ“šåœ¨åƒæ•¸ä¸­å‡ºç¾çš„é †åºï¼šå‰é¢çš„ä½œç‚º Entryï¼Œå¾Œé¢çš„ä½œç‚º Exit
            if len(sorted_indicators) == 2:
                entry_indicators.append(sorted_indicators[0])
                exit_indicators.append(sorted_indicators[1])
            elif len(sorted_indicators) == 1:
                # åªæœ‰ä¸€å€‹æŒ‡æ¨™æ™‚ï¼Œç„¡æ³•åˆ¤æ–·ï¼Œé»˜èªä½œç‚º Entry
                entry_indicators.append(sorted_indicators[0])
            else:
                # å¤šå€‹æŒ‡æ¨™æ™‚ï¼ŒæŒ‰ç…§å‡ºç¾é †åºï¼šå‰é¢çš„ä½œç‚º Entryï¼Œå¾Œé¢çš„ä½œç‚º Exit
                # é€šå¸¸ Entry æŒ‡æ¨™æœƒå…ˆå‡ºç¾
                mid_point = len(sorted_indicators) // 2
                entry_indicators = sorted_indicators[:mid_point]
                exit_indicators = sorted_indicators[mid_point:]
            
            # å»é‡ä¸¦æ’åº
            entry_indicators = sorted(set(entry_indicators))
            exit_indicators = sorted(set(exit_indicators))
            
            # æ§‹å»ºé¡¯ç¤ºåç¨±ï¼ˆèˆ‡åƒæ•¸é«˜åŸæ ¼å¼ä¸€è‡´ï¼Œä½¿ç”¨ | åˆ†éš”å¤šå€‹æŒ‡æ¨™ï¼‰
            if entry_indicators and exit_indicators:
                entry_str = " | ".join(entry_indicators)
                exit_str = " | ".join(exit_indicators)
                return f"Entry: {entry_str} | Exit: {exit_str}"
            elif entry_indicators:
                entry_str = " | ".join(entry_indicators)
                return f"Entry: {entry_str}"
            elif exit_indicators:
                exit_str = " | ".join(exit_indicators)
                return f"Exit: {exit_str}"
            else:
                condition_pair_id = row.get("condition_pair_id", 1)
                return f"ç­–ç•¥ {condition_pair_id}"
                
        except Exception as e:
            self.logger.warning(f"æå–æŒ‡æ¨™çµ„åˆå¤±æ•—: {e}")
            condition_pair_id = row.get("condition_pair_id", 1)
            return f"ç­–ç•¥ {condition_pair_id}"
    
    def _extract_indicator_combination_from_param_info(self, param_info: Optional[Dict[str, Any]], row: pd.Series) -> str:
        """
        å¾ param_info ä¸­æå–æŒ‡æ¨™çµ„åˆåç¨±ï¼ˆæ ¼å¼èˆ‡åƒæ•¸é«˜åŸä¸€è‡´ï¼‰
        é€™æ˜¯æ›´æº–ç¢ºçš„æ–¹æ³•ï¼Œå› ç‚º param_info ä¸­åŒ…å«æ­£ç¢ºçš„åƒæ•¸éµä¿¡æ¯

        Args:
            param_info: build_3x3_matrix è¿”å›çš„åƒæ•¸ä¿¡æ¯å­—å…¸
            row: æ•¸æ“šè¡Œï¼ˆç”¨æ–¼ç²å– condition_pair_id ä½œç‚ºå¾Œå‚™ï¼‰

        Returns:
            str: æŒ‡æ¨™çµ„åˆåç¨±ï¼Œæ ¼å¼å¦‚ "Entry: BOLL2 | Exit: BOLL3"
        """
        try:
            if not param_info:
                condition_pair_id = row.get("condition_pair_id", 1)
                return f"ç­–ç•¥ {condition_pair_id}"
            
            param1_key = param_info.get("param1_key", "")
            param2_key = param_info.get("param2_key", "")
            
            # å¾åƒæ•¸éµä¸­æå–æŒ‡æ¨™åç¨±ï¼ˆæ ¼å¼ï¼š{indicator_name}_{param_name}ï¼‰
            # ä¾‹å¦‚ï¼šBOLL2_ma_length -> BOLL2
            entry_indicator = None
            exit_indicator = None
            
            # æå–æŒ‡æ¨™åç¨±
            if param1_key:
                match = re.match(r'^([A-Z]+\d+)_', param1_key)
                if match:
                    entry_indicator = match.group(1)  # param1 å°æ‡‰ Entryï¼ˆYè»¸ï¼Œè¡Œï¼‰
            
            if param2_key:
                match = re.match(r'^([A-Z]+\d+)_', param2_key)
                if match:
                    exit_indicator = match.group(1)  # param2 å°æ‡‰ Exitï¼ˆXè»¸ï¼Œåˆ—ï¼‰
            
            # å¦‚æœæ²’æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨èˆŠæ–¹æ³•ä½œç‚ºå¾Œå‚™
            if not entry_indicator and not exit_indicator:
                return self._extract_indicator_combination(row)
            
            # æ§‹å»ºé¡¯ç¤ºåç¨±ï¼ˆä½¿ç”¨ | åˆ†éš”å¤šå€‹æŒ‡æ¨™ï¼Œèˆ‡åƒæ•¸é«˜åŸæ ¼å¼ä¸€è‡´ï¼‰
            if entry_indicator and exit_indicator:
                return f"Entry: {entry_indicator} | Exit: {exit_indicator}"
            elif entry_indicator:
                return f"Entry: {entry_indicator}"
            elif exit_indicator:
                return f"Exit: {exit_indicator}"
            else:
                condition_pair_id = row.get("condition_pair_id", 1)
                return f"ç­–ç•¥ {condition_pair_id}"
                
        except Exception as e:
            self.logger.warning(f"å¾ param_info æå–æŒ‡æ¨™çµ„åˆå¤±æ•—: {e}")
            # ä½¿ç”¨èˆŠæ–¹æ³•ä½œç‚ºå¾Œå‚™
            return self._extract_indicator_combination(row)
    
    def build_3x3_matrix(
        self, window_data: pd.DataFrame
    ) -> Tuple[Optional[Dict[str, Any]], Optional[Dict[str, Any]]]:
        """
        æ§‹å»º 3x3 åƒæ•¸çŸ©é™£

        Args:
            window_data: å–®å€‹çª—å£çš„æ•¸æ“šï¼ˆæ‡‰åŒ…å« 9 è¡Œï¼Œå°æ‡‰ param_combination_id 1-9ï¼‰

        Returns:
            Tuple[Optional[Dict[str, Any]], Optional[Dict[str, Any]]]:
                - çŸ©é™£æ•¸æ“šå­—å…¸ {metric_name: 3x3 numpy array}
                - åƒæ•¸ä¿¡æ¯å­—å…¸ï¼ˆåŒ…å«åƒæ•¸åç¨±å’Œå€¼åˆ—è¡¨ï¼‰
        """
        try:
            # æª¢æŸ¥æ•¸æ“šæ˜¯å¦åŒ…å« 9 è¡Œ
            if len(window_data) != 9:
                self.logger.warning(
                    f"çª—å£æ•¸æ“šä¸åŒ…å« 9 è¡Œï¼Œå¯¦éš›æœ‰ {len(window_data)} è¡Œ"
                )
                return None, None

            # param_combination_id åˆ°çŸ©é™£ä½ç½®çš„æ˜ å°„ï¼ˆå›ºå®šä½ç½®ï¼‰ï¼š
            # 1: (0,0)  2: (0,1)  3: (0,2)
            # 4: (1,0)  5: (1,1)  6: (1,2)
            # 7: (2,0)  8: (2,1)  9: (2,2)
            position_map = {
                1: (0, 0), 2: (0, 1), 3: (0, 2),
                4: (1, 0), 5: (1, 1), 6: (1, 2),
                7: (2, 0), 8: (2, 1), 9: (2, 2),
            }

            # åˆå§‹åŒ– 3x3 çŸ©é™£ï¼ˆç”¨æ–¼å­˜å„²å„ç¨®æŒ‡æ¨™ï¼‰
            matrices = {
                "is_sharpe": np.full((3, 3), np.nan),
                "is_calmar": np.full((3, 3), np.nan),
                "is_sortino": np.full((3, 3), np.nan),
                "is_total_return": np.full((3, 3), np.nan),
                "is_mdd": np.full((3, 3), np.nan),
                "is_metric": np.full((3, 3), np.nan),
                "oos_sharpe": np.full((3, 3), np.nan),
                "oos_calmar": np.full((3, 3), np.nan),
                "oos_sortino": np.full((3, 3), np.nan),
                "oos_total_return": np.full((3, 3), np.nan),
                "oos_mdd": np.full((3, 3), np.nan),
            }

            # è§£ææ‰€æœ‰åƒæ•¸çµ„åˆçš„ optimal_paramsï¼Œç”¨æ–¼æå–åƒæ•¸ä¿¡æ¯
            param_dicts = []
            param_values_map = {}  # å­˜å„²æ¯å€‹ä½ç½®çš„åƒæ•¸å€¼

            for idx, row in window_data.iterrows():
                param_comb_id = int(row.get("param_combination_id"))
                if param_comb_id not in position_map:
                    continue

                row_idx, col_idx = position_map[param_comb_id]

                # è§£æåƒæ•¸
                params_str = row.get("optimal_params", "{}")
                param_dict = self.parse_optimal_params(params_str)
                param_dicts.append(param_dict)
                param_values_map[(row_idx, col_idx)] = param_dict

                # å¡«å……æŒ‡æ¨™å€¼åˆ°çŸ©é™£
                matrices["is_sharpe"][row_idx, col_idx] = row.get("is_sharpe")
                matrices["is_calmar"][row_idx, col_idx] = row.get("is_calmar")
                matrices["is_sortino"][row_idx, col_idx] = row.get("is_sortino")
                matrices["is_total_return"][row_idx, col_idx] = row.get("is_total_return")
                matrices["is_mdd"][row_idx, col_idx] = row.get("is_mdd")
                matrices["is_metric"][row_idx, col_idx] = row.get("is_metric")
                matrices["oos_sharpe"][row_idx, col_idx] = row.get("oos_sharpe")
                matrices["oos_calmar"][row_idx, col_idx] = row.get("oos_calmar")
                matrices["oos_sortino"][row_idx, col_idx] = row.get("oos_sortino")
                matrices["oos_total_return"][row_idx, col_idx] = row.get("oos_total_return")
                matrices["oos_mdd"][row_idx, col_idx] = row.get("oos_mdd")

            # æå–åƒæ•¸ä¿¡æ¯ï¼ˆç”¨æ–¼é¡¯ç¤ºè»¸æ¨™ç±¤ï¼‰
            if not param_dicts or not param_dicts[0]:
                self.logger.warning("ç„¡æ³•æå–åƒæ•¸ä¿¡æ¯")
                return None, None

            all_keys = list(param_dicts[0].keys())

            # æ‰¾å‡ºå¯è®Šåƒæ•¸ï¼ˆåœ¨ä¸åŒçµ„åˆä¸­æœ‰ä¸åŒå€¼çš„åƒæ•¸ï¼‰
            variable_params = []
            for key in all_keys:
                values = [d.get(key) for d in param_dicts if key in d]
                unique_values = sorted(set(values))
                if len(unique_values) > 1:
                    variable_params.append((key, unique_values))

            # å¦‚æœæ²’æœ‰æ‰¾åˆ°å¯è®Šåƒæ•¸æˆ–å¯è®Šåƒæ•¸è¶…é 2 å€‹ï¼Œä½¿ç”¨å‰å…©å€‹åƒæ•¸éµ
            if len(variable_params) == 0:
                if len(all_keys) >= 2:
                    variable_params = [
                        (all_keys[0], sorted(set([d.get(all_keys[0]) for d in param_dicts]))),
                        (all_keys[1], sorted(set([d.get(all_keys[1]) for d in param_dicts]))),
                    ]
                else:
                    self.logger.warning("ç„¡æ³•ç¢ºå®šå¯è®Šåƒæ•¸")
                    return None, None
            elif len(variable_params) > 2:
                variable_params = variable_params[:2]

            param1_key, param1_values = variable_params[0]
            param2_key, param2_values = variable_params[1] if len(variable_params) > 1 else (None, [])

            # æ ¹æ“šçŸ©é™£ä½ç½®æå–åƒæ•¸å€¼é †åº
            # è¡Œï¼ˆç¬¬ä¸€ç¶­ï¼‰ï¼šå¾ä½ç½® (0,0), (1,0), (2,0) æå– param1 çš„å€¼
            row_param_values = []
            for r in range(3):
                if (r, 0) in param_values_map:
                    val = param_values_map[(r, 0)].get(param1_key)
                    if val is not None:
                        row_param_values.append(val)

            # åˆ—ï¼ˆç¬¬äºŒç¶­ï¼‰ï¼šå¾ä½ç½® (0,0), (0,1), (0,2) æå– param2 çš„å€¼
            col_param_values = []
            if param2_key:
                for c in range(3):
                    if (0, c) in param_values_map:
                        val = param_values_map[(0, c)].get(param2_key)
                        if val is not None:
                            col_param_values.append(val)

            # åƒæ•¸ä¿¡æ¯
            param_info = {
                "param1_key": param1_key,
                "param1_values": row_param_values if row_param_values else sorted(param1_values),
                "param2_key": param2_key,
                "param2_values": col_param_values if col_param_values else (sorted(param2_values) if param2_key else []),
            }

            return matrices, param_info

        except Exception as e:
            self.logger.error(f"æ§‹å»º 3x3 çŸ©é™£å¤±æ•—: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            return None, None

    def load_wfa_file(self, file_path: str) -> Dict[str, Any]:
        """
        è¼‰å…¥å–®å€‹ WFA parquet æª”æ¡ˆ

        Args:
            file_path: parquet æª”æ¡ˆè·¯å¾‘

        Returns:
            Dict[str, Any]: è§£æå¾Œçš„æ•¸æ“šå­—å…¸ï¼ŒåŒ…å«ï¼š
                - "filename": æª”æ¡ˆåç¨±
                - "windows": çª—å£æ•¸æ“šå­—å…¸ {window_id: {...}}
                - "strategies": ç­–ç•¥åˆ—è¡¨
        """
        try:
            # è®€å– parquet æª”æ¡ˆ
            df = pd.read_parquet(file_path)
            
            # å˜—è©¦å¾ parquet metadata ä¸­è®€å– Entry/Exit é…ç½®
            try:
                import pyarrow.parquet as pq
                parquet_file = pq.ParquetFile(file_path)
                metadata = parquet_file.metadata.metadata
                if metadata:
                    # å˜—è©¦è§£æ metadata ä¸­çš„ Entry/Exit ä¿¡æ¯
                    # é€™è£¡å¯ä»¥æ ¹æ“šå¯¦éš›çš„ metadata æ ¼å¼ä¾†è§£æ
                    pass
            except Exception:
                # å¦‚æœç„¡æ³•è®€å– metadataï¼Œç¹¼çºŒä½¿ç”¨æ¨æ–·æ–¹æ³•
                pass

            # æå–æª”æ¡ˆåç¨±
            filename = os.path.basename(file_path)

            # æŒ‰ window_id å’Œ condition_pair_id åˆ†çµ„
            windows_data = {}
            strategies = set()
            strategy_names = {}  # å­˜å„²ç­–ç•¥åç¨±æ˜ å°„ {strategy_key: indicator_combination}

            for (window_id, condition_pair_id), group in df.groupby(["window_id", "condition_pair_id"]):
                strategy_key = f"strategy_{condition_pair_id}"
                strategies.add(strategy_key)
                
                # æ§‹å»º 3x3 çŸ©é™£ï¼ˆå…ˆæ§‹å»ºï¼Œä»¥ä¾¿å¾ param_info ä¸­ç²å–æ­£ç¢ºçš„ Entry/Exit ä¿¡æ¯ï¼‰
                matrices, param_info = self.build_3x3_matrix(group)
                
                # å¾ param_info ä¸­æå–æŒ‡æ¨™çµ„åˆä¿¡æ¯ï¼ˆé€™æ¨£èƒ½ç²å–æ­£ç¢ºçš„ Entry/Exitï¼‰
                if strategy_key not in strategy_names:
                    indicator_combination = self._extract_indicator_combination_from_param_info(param_info, group.iloc[0])
                    strategy_names[strategy_key] = indicator_combination

                if matrices is None:
                    self.logger.warning(
                        f"çª—å£ {window_id} ç­–ç•¥ {condition_pair_id} ç„¡æ³•æ§‹å»ºçŸ©é™£"
                    )
                    continue

                # ç²å–çª—å£çš„æ™‚é–“ä¿¡æ¯ï¼ˆå¾ç¬¬ä¸€è¡Œç²å–ï¼‰
                first_row = group.iloc[0]
                window_info = {
                    "window_id": window_id,
                    "condition_pair_id": condition_pair_id,
                    "train_start_date": first_row.get("train_start_date"),
                    "train_end_date": first_row.get("train_end_date"),
                    "test_start_date": first_row.get("test_start_date"),
                    "test_end_date": first_row.get("test_end_date"),
                    "matrices": matrices,
                    "param_info": param_info,
                }

                window_key = f"window_{window_id}_strategy_{condition_pair_id}"
                windows_data[window_key] = window_info

            return {
                "filename": filename,
                "file_path": file_path,
                "windows": windows_data,
                "strategies": sorted(list(strategies)),
                "strategy_names": strategy_names,  # ç­–ç•¥åç¨±æ˜ å°„
            }

        except Exception as e:
            self.logger.error(f"è¼‰å…¥ WFA æª”æ¡ˆå¤±æ•— {file_path}: {e}")
            import traceback
            self.logger.error(traceback.format_exc())
            raise

    def load_wfa_files_interactive(self) -> List[Dict[str, Any]]:
        """
        äº’å‹•å¼è¼‰å…¥ WFA parquet æª”æ¡ˆï¼ˆæ”¯æ´é¸æ“‡æª”æ¡ˆï¼‰

        Returns:
            List[Dict[str, Any]]: é¸ä¸­æª”æ¡ˆçš„è§£æçµæœåˆ—è¡¨
        """
        try:
            parquet_files = self.scan_wfa_parquet_files()
            if not parquet_files:
                self.logger.warning("æœªæ‰¾åˆ°ä»»ä½• WFA parquet æª”æ¡ˆ")
                return []

            # äº’å‹•å¼é¸å–®
            step_content = (
                "ğŸŸ¢ é¸æ“‡è¦è¼‰å…¥çš„ WFA æª”æ¡ˆ\n"
                "ğŸŸ¢ ç”Ÿæˆå¯è¦–åŒ–ä»‹é¢[è‡ªå‹•]\n"
                "\n"
                "[bold #dbac30]èªªæ˜[/bold #dbac30]\n"
                "æ­¤æ­¥é©Ÿç”¨æ–¼é¸æ“‡è¦è¼‰å…¥çš„ WFA parquet æª”æ¡ˆï¼Œæ”¯æ´å¤šæª”æ¡ˆåŒæ™‚è¼‰å…¥ã€‚\n"
                "æª”æ¡ˆåŒ…å« WFA åˆ†æçš„çª—å£æ•¸æ“šå’Œåƒæ•¸çµ„åˆçµæœã€‚\n\n"
                "[bold #dbac30]æª”æ¡ˆé¸æ“‡æ ¼å¼ï¼š[/bold #dbac30]\n"
                "â€¢ ä¸å°å…¥ï¼šè¼¸å…¥ 0\n"
                "â€¢ å–®ä¸€æª”æ¡ˆï¼šè¼¸å…¥æ•¸å­—ï¼ˆå¦‚ 1ï¼‰\n"
                "â€¢ å¤šæª”æ¡ˆï¼šç”¨é€—è™Ÿåˆ†éš”ï¼ˆå¦‚ 1,2,3ï¼‰\n"
                "â€¢ å…¨éƒ¨æª”æ¡ˆï¼šç›´æ¥æŒ‰ Enter\n\n"
                "[bold #dbac30]å¯é¸æ“‡çš„ WFA parquet æª”æ¡ˆï¼š[/bold #dbac30]"
            )

            # æº–å‚™æª”æ¡ˆåˆ—è¡¨ï¼ˆæ·»åŠ  0ï¼šä¸å°å…¥ é¸é …ï¼‰
            file_list = "  [bold #dbac30]0.[/bold #dbac30] è·³é\n"
            for i, f in enumerate(parquet_files, 1):
                file_list += (
                    f"  [bold #dbac30]{i}.[/bold #dbac30] {os.path.basename(f)}\n"
                )

            # çµ„åˆå®Œæ•´å…§å®¹ä¸¦é¡¯ç¤º
            complete_content = step_content + "\n" + file_list
            show_step_panel("PLOTTER", 1, ["æ•¸æ“šé¸æ“‡"], complete_content)

            # ç”¨æˆ¶è¼¸å…¥æç¤º
            self.console.print("[bold #dbac30]è¼¸å…¥ WFA æª”æ¡ˆè™Ÿç¢¼ï¼š[/bold #dbac30]")
            file_input = input().strip() or "all"

            # è™•ç†ã€Œ0ï¼šè·³éã€é¸é …
            if file_input == "0":
                return []

            if not file_input or file_input.lower() == "all":
                selected_files = parquet_files
            else:
                try:
                    # è§£æç”¨æˆ¶è¼¸å…¥çš„æª”æ¡ˆç·¨è™Ÿ
                    file_indices = [int(x.strip()) for x in file_input.split(",")]
                    selected_files = [
                        parquet_files[i - 1]
                        for i in file_indices
                        if 1 <= i <= len(parquet_files)
                    ]
                    if not selected_files:
                        show_warning("PLOTTER", "æ²’æœ‰é¸æ“‡æœ‰æ•ˆçš„æª”æ¡ˆï¼Œé è¨­è¼‰å…¥å…¨éƒ¨æª”æ¡ˆã€‚")
                        selected_files = parquet_files
                except (ValueError, IndexError):
                    show_info("PLOTTER", "ğŸ”” å·²è‡ªå‹•è¼‰å…¥å…¨éƒ¨æª”æ¡ˆã€‚")
                    selected_files = parquet_files

            # è¼‰å…¥é¸å®šçš„æª”æ¡ˆ
            all_data = []
            for file_path in selected_files:
                try:
                    file_data = self.load_wfa_file(file_path)
                    all_data.append(file_data)
                except Exception as e:
                    self.logger.error(f"è¼‰å…¥æª”æ¡ˆå¤±æ•— {file_path}: {e}")
                    continue

            return all_data

        except Exception as e:
            self.logger.error(f"è¼‰å…¥ WFA æª”æ¡ˆå¤±æ•—: {e}")
            raise

    def load_all_wfa_files(self) -> List[Dict[str, Any]]:
        """
        è¼‰å…¥æ‰€æœ‰ WFA parquet æª”æ¡ˆï¼ˆç„¡äº’å‹•é¸æ“‡ï¼‰

        Returns:
            List[Dict[str, Any]]: æ‰€æœ‰æª”æ¡ˆçš„è§£æçµæœåˆ—è¡¨
        """
        try:
            parquet_files = self.scan_wfa_parquet_files()
            if not parquet_files:
                return []

            all_data = []
            for file_path in parquet_files:
                try:
                    file_data = self.load_wfa_file(file_path)
                    all_data.append(file_data)
                except Exception as e:
                    self.logger.error(f"è¼‰å…¥æª”æ¡ˆå¤±æ•— {file_path}: {e}")
                    continue

            return all_data

        except Exception as e:
            self.logger.error(f"è¼‰å…¥æ‰€æœ‰ WFA æª”æ¡ˆå¤±æ•—: {e}")
            raise

