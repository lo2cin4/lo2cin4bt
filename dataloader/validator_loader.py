"""
validator_loader.py

ã€åŠŸèƒ½èªªæ˜ã€‘
------------------------------------------------------------
æœ¬æ¨¡çµ„ç‚º Lo2cin4BT æ•¸æ“šé©—è­‰æ¨¡çµ„ï¼Œè² è²¬å°è¡Œæƒ…æ•¸æ“šé€²è¡Œå®Œæ•´æ€§ã€å‹æ…‹ã€æ¬„ä½ã€ç¼ºå¤±å€¼ç­‰å¤šå±¤æ¬¡é©—è­‰èˆ‡æ¸…æ´—ï¼Œç¢ºä¿ä¸‹æ¸¸æµç¨‹æ•¸æ“šæ­£ç¢ºä¸”ä¸€è‡´ã€‚

ã€æµç¨‹èˆ‡æ•¸æ“šæµã€‘
------------------------------------------------------------
- ç”± DataLoaderã€DataImporter æˆ– BacktestEngine èª¿ç”¨ï¼Œå°åŸå§‹æˆ–è™•ç†å¾Œæ•¸æ“šé€²è¡Œé©—è­‰èˆ‡æ¸…æ´—
- é©—è­‰çµæœå‚³éçµ¦ Calculatorã€Predictorã€BacktestEngine ç­‰æ¨¡çµ„

```mermaid
flowchart TD
    A[DataLoader/DataImporter/BacktestEngine] -->|èª¿ç”¨| B(validator_loader)
    B -->|é©—è­‰/æ¸…æ´—| C[æ•¸æ“šDataFrame]
    C -->|å‚³é| D[Calculator/Predictor/BacktestEngine]
```

ã€ç¶­è­·èˆ‡æ“´å……é‡é»ã€‘
------------------------------------------------------------
- æ–°å¢/ä¿®æ”¹é©—è­‰è¦å‰‡ã€æ¬„ä½ã€ç¼ºå¤±å€¼è™•ç†æ–¹å¼æ™‚ï¼Œè«‹åŒæ­¥æ›´æ–°é ‚éƒ¨è¨»è§£èˆ‡ä¸‹æ¸¸æµç¨‹
- è‹¥é©—è­‰æµç¨‹ã€æ¬„ä½çµæ§‹æœ‰è®Šå‹•ï¼Œéœ€åŒæ­¥æ›´æ–°æœ¬æª”æ¡ˆèˆ‡ä¸‹æ¸¸æ¨¡çµ„
- ç¼ºå¤±å€¼è™•ç†ç­–ç•¥å¦‚æœ‰èª¿æ•´ï¼Œè«‹åŒæ­¥é€šçŸ¥å”ä½œè€…

ã€å¸¸è¦‹æ˜“éŒ¯é»ã€‘
------------------------------------------------------------
- æ¬„ä½åç¨±æ‹¼å¯«éŒ¯èª¤æˆ–å‹æ…‹ä¸ç¬¦æœƒå°è‡´é©—è­‰å¤±æ•—
- æ™‚é–“æ¬„ä½ç¼ºå¤±æˆ–æ ¼å¼éŒ¯èª¤æœƒå½±éŸ¿ä¸‹æ¸¸æµç¨‹
- ç¼ºå¤±å€¼è™•ç†ç­–ç•¥æœªåŒæ­¥æ›´æ–°æœƒå°è‡´è³‡æ–™ä¸ä¸€è‡´

ã€ç¯„ä¾‹ã€‘
------------------------------------------------------------
- validator = DataValidator(df)
  df = validator.validate_and_clean()

ã€èˆ‡å…¶ä»–æ¨¡çµ„çš„é—œè¯ã€‘
------------------------------------------------------------
- ç”± DataLoaderã€DataImporterã€BacktestEngine èª¿ç”¨ï¼Œæ•¸æ“šå‚³éçµ¦ Calculatorã€Predictorã€BacktestEngine
- éœ€èˆ‡ä¸‹æ¸¸æ¬„ä½çµæ§‹ä¿æŒä¸€è‡´

ã€åƒè€ƒã€‘
------------------------------------------------------------
- pandas å®˜æ–¹æ–‡ä»¶
- base_loader.pyã€calculator_loaderã€predictor_loader
- å°ˆæ¡ˆ README
"""

from typing import Optional

import pandas as pd
from rich.table import Table

from utils import show_error, show_info, show_success, show_warning, get_console

console = get_console()


def print_dataframe_table(df: pd.DataFrame, title: Optional[str] = None) -> None:
    table = Table(title=title, show_lines=True, border_style="#dbac30")
    for col in df.columns:
        table.add_column(str(col), style="bold white")
    for _, row in df.iterrows():
        table.add_row(
            *[
                (
                    f"[#1e90ff]{v}[/#1e90ff]"
                    if isinstance(v, (int, float, complex)) and not isinstance(v, bool)
                    else str(v)
                )
                for v in row
            ]
        )
    console.print(table)


class DataValidator:
    def __init__(self, data: pd.DataFrame) -> None:
        self.data = data.copy()

    def validate_and_clean(self) -> pd.DataFrame:
        """é©—è­‰å’Œæ¸…æ´—æ•¸æ“šï¼Œæ”¯æ´å‹•æ…‹æ¬„ä½"""
        if "Time" not in self.data.columns:
            show_warning("DATALOADER", "ç„¡ 'Time' æ¬„ä½ï¼Œå°‡ç”Ÿæˆåºåˆ—ç´¢å¼•")
            self.data["Time"] = pd.date_range(
                start="2020-01-01", periods=len(self.data)
            )

        # å‹•æ…‹è­˜åˆ¥æ•¸å€¼æ¬„ä½ï¼ˆæ’é™¤ Timeï¼‰
        numeric_cols = [col for col in self.data.columns if col != "Time"]
        missing_df = pd.DataFrame(
            {
                "æ¬„ä½": numeric_cols,
                "ç¼ºå¤±å€¼æ¯”ä¾‹": [
                    f"{self.data[col].isna().mean():.2%}" for col in numeric_cols
                ],
            }
        )
        print_dataframe_table(missing_df)

        self._handle_time_index()
        return self.data

    def _smart_convert_datetime(self, time_series: pd.Series) -> pd.Series:
        """
        æ™ºèƒ½æª¢æ¸¬ä¸¦è½‰æ›æ™‚é–“æ ¼å¼
        1. å…ˆæª¢æ¸¬æ˜¯å¦ç‚ºtimestampæ ¼å¼
        2. å†å˜—è©¦ä¸åŒçš„æ—¥æœŸå­—ç¬¦ä¸²æ ¼å¼
        """
        try:
            # 1. æª¢æ¸¬æ˜¯å¦ç‚ºtimestampæ ¼å¼
            if pd.api.types.is_numeric_dtype(time_series):
                sample_value = time_series.iloc[0]
                import numpy as np
                if isinstance(sample_value, (int, float, np.integer, np.floating)):
                    if sample_value > 1e10:  # æ¯«ç§’ç´štimestamp
                        show_info("DATALOADER", "æª¢æ¸¬åˆ°æ¯«ç§’ç´štimestampæ ¼å¼ï¼Œæ­£åœ¨è½‰æ›...")
                        return pd.to_datetime(time_series, unit="ms", errors="coerce")
                    else:  # ç§’ç´štimestamp
                        show_info("DATALOADER", "æª¢æ¸¬åˆ°ç§’ç´štimestampæ ¼å¼ï¼Œæ­£åœ¨è½‰æ›...")
                        return pd.to_datetime(time_series, unit="s", errors="coerce")
            else:
                # 2. å˜—è©¦å°‡å­—ç¬¦ä¸²è½‰æ›ç‚ºæ•¸å€¼å†åˆ¤æ–·timestamp
                try:
                    numeric_value = pd.to_numeric(time_series.iloc[0])
                    if numeric_value > 1e10:  # æ¯«ç§’ç´š
                        show_info("DATALOADER", "æª¢æ¸¬åˆ°æ¯«ç§’ç´štimestampæ ¼å¼ï¼Œæ­£åœ¨è½‰æ›...")
                        numeric_series = pd.to_numeric(time_series, errors="coerce")
                        return pd.to_datetime(numeric_series, unit="ms", errors="coerce")
                    else:  # ç§’ç´š
                        show_info("DATALOADER", "æª¢æ¸¬åˆ°ç§’ç´štimestampæ ¼å¼ï¼Œæ­£åœ¨è½‰æ›...")
                        numeric_series = pd.to_numeric(time_series, errors="coerce")
                        return pd.to_datetime(numeric_series, unit="s", errors="coerce")
                except (ValueError, TypeError):
                    # ä¸æ˜¯timestampï¼Œç¹¼çºŒå˜—è©¦æ—¥æœŸå­—ç¬¦ä¸²æ ¼å¼
                    pass
            
            # 3. å˜—è©¦ä¸åŒçš„æ—¥æœŸå­—ç¬¦ä¸²æ ¼å¼
            sample_dates = time_series.head(5).tolist()
            show_info("DATALOADER",
                f"ğŸ” æ™ºèƒ½æª¢æ¸¬æ—¥æœŸæ ¼å¼ï¼š\n"
                f"   æ¨£æœ¬æ—¥æœŸ: {sample_dates}\n"
                f"   å˜—è©¦è§£æç‚º DD/MM/YYYY æ ¼å¼..."
            )
            
            # å…ˆå˜—è©¦ DD/MM/YYYY æ ¼å¼ï¼ˆdayfirst=Trueï¼‰
            result = pd.to_datetime(time_series, dayfirst=True, errors="coerce")
            invalid_count = result.isna().sum()
            
            if invalid_count == 0:
                show_success("DATALOADER", "æˆåŠŸè§£æç‚º DD/MM/YYYY æ ¼å¼")
                return result
            else:
                # å¦‚æœ DD/MM/YYYY æ ¼å¼å¤±æ•—ï¼Œå˜—è©¦ MM/DD/YYYY æ ¼å¼
                show_warning("DATALOADER", f"DD/MM/YYYY æ ¼å¼è§£æå¤±æ•— {invalid_count} å€‹å€¼ï¼Œå˜—è©¦ MM/DD/YYYY æ ¼å¼...")
                result2 = pd.to_datetime(time_series, dayfirst=False, errors="coerce")
                invalid_count2 = result2.isna().sum()
                
                if invalid_count2 < invalid_count:
                    show_success("DATALOADER", "æˆåŠŸè§£æç‚º MM/DD/YYYY æ ¼å¼")
                    return result2
                else:
                    # å¦‚æœå…©ç¨®æ ¼å¼éƒ½å¤±æ•—ï¼Œä½¿ç”¨è‡ªå‹•æ¨æ–·
                    show_warning("DATALOADER", "å…©ç¨®æ ¼å¼éƒ½å¤±æ•—ï¼Œä½¿ç”¨è‡ªå‹•æ¨æ–·æ ¼å¼...")
                    return pd.to_datetime(time_series, errors="coerce")
                    
        except Exception as e:
            show_warning("DATALOADER", f"æ™ºèƒ½æ™‚é–“è½‰æ›å¤±æ•—ï¼š{e}ï¼Œä½¿ç”¨é è¨­æ ¼å¼")
            return pd.to_datetime(time_series, errors="coerce")

    def _handle_missing_values(self, col: str) -> None:
        """è™•ç†ç¼ºå¤±å€¼ï¼Œæ ¹æ“šç”¨æˆ¶é¸æ“‡å¡«å……"""
        show_warning("DATALOADER",
            f"{col} æ¬„ä½æœ‰ç¼ºå¤±å€¼ï¼Œè«‹é¸æ“‡è™•ç†æ–¹å¼ï¼š\n  Aï¼šå‰å‘å¡«å……\n  B,Nï¼šå‰ N æœŸå‡å€¼å¡«å……ï¼ˆä¾‹å¦‚ B,5ï¼‰\n  C,xï¼šå›ºå®šå€¼ x å¡«å……ï¼ˆä¾‹å¦‚ C,0ï¼‰"
        )
        while True:
            console.print("[bold #dbac30]è«‹è¼¸å…¥é¸æ“‡ï¼š[/bold #dbac30]")
            choice = input().strip().upper()
            try:
                if choice == "A":
                    self.data[col] = self.data[col].ffill()
                    show_info("DATALOADER", f"å·²é¸æ“‡å‰å‘å¡«å…… {col}")
                    break
                elif choice.startswith("B,"):
                    n = int(choice.split(",")[1])
                    if n <= 0:
                        raise ValueError("N å¿…é ˆç‚ºæ­£æ•´æ•¸")
                    self.data[col] = self.data[col].fillna(
                        self.data[col].rolling(window=n, min_periods=1).mean()
                    )
                    show_info("DATALOADER", f"å·²é¸æ“‡å‰ {n} æœŸå‡å€¼å¡«å…… {col}")
                    break
                elif choice.startswith("C,"):
                    x = float(choice.split(",")[1])
                    self.data[col] = self.data[col].fillna(x)
                    show_info("DATALOADER", f"å·²é¸æ“‡å›ºå®šå€¼ {x} å¡«å…… {col}")
                    break
                else:
                    show_error("DATALOADER", "éŒ¯èª¤ï¼šè«‹è¼¸å…¥ A, B,N æˆ– C,x")
            except ValueError as e:
                show_error("DATALOADER", f"éŒ¯èª¤ï¼š{e}")

        remaining_nans = self.data[col].isna().sum()
        if remaining_nans > 0:
            show_warning("DATALOADER", f"{col} ä»æœ‰ {remaining_nans} å€‹ç¼ºå¤±å€¼ï¼Œå°‡ç”¨ 0 å¡«å……")
            self.data[col] = self.data[col].fillna(0)

    def _handle_time_index(self) -> None:
        """è™•ç†æ™‚é–“ç´¢å¼•ï¼Œç¢ºä¿æ ¼å¼æ­£ç¢ºï¼Œä½†ä¿ç•™ Time æ¬„ä½"""
        try:
            # åªæœ‰ç•¶Timeæ¬„ä½ä¸æ˜¯datetimeæ ¼å¼æ™‚æ‰é€²è¡Œè½‰æ›
            # é¿å…å°å·²è½‰æ›çš„timestampé€²è¡ŒäºŒæ¬¡è™•ç†
            if not pd.api.types.is_datetime64_any_dtype(self.data["Time"]):
                # æ·»åŠ è©³ç´°çš„debugè¼¸å‡º
                show_info("DATALOADER",
                    f"ğŸ” æ™‚é–“è½‰æ›å‰æª¢æŸ¥ï¼š\n"
                    f"   Timeæ¬„ä½é¡å‹: {self.data['Time'].dtype}\n"
                    f"   å‰5å€‹å€¼: {self.data['Time'].head().tolist()}\n"
                    f"   å¾Œ5å€‹å€¼: {self.data['Time'].tail().tolist()}\n"
                    f"   å”¯ä¸€å€¼æ•¸é‡: {self.data['Time'].nunique()}\n"
                    f"   ç¸½è¡Œæ•¸: {len(self.data)}"
                )
                
                # æ™ºèƒ½æª¢æ¸¬æ™‚é–“æ ¼å¼
                original_time = self.data["Time"].copy()
                self.data["Time"] = self._smart_convert_datetime(self.data["Time"])
                
                # æ‰¾å‡ºç„¡æ•ˆçš„æ™‚é–“å€¼
                invalid_mask = self.data["Time"].isna()
                if invalid_mask.any():
                    invalid_indices = invalid_mask[invalid_mask].index.tolist()
                    invalid_values = original_time[invalid_mask].tolist()
                    
                    show_error("DATALOADER",
                        f"ç™¼ç¾ç„¡æ•ˆæ™‚é–“å€¼ï¼š\n"
                        f"   ç„¡æ•ˆå€¼æ•¸é‡: {len(invalid_values)}\n"
                        f"   ç„¡æ•ˆå€¼ç´¢å¼•: {invalid_indices[:10]}{'...' if len(invalid_indices) > 10 else ''}\n"
                        f"   ç„¡æ•ˆå€¼æ¨£æœ¬: {invalid_values[:10]}{'...' if len(invalid_values) > 10 else ''}\n"
                        f"   åŸå§‹å€¼é¡å‹: {[type(v) for v in invalid_values[:5]]}"
                    )
            
            if self.data["Time"].isna().sum() > 0:
                show_warning("DATALOADER", f"{self.data['Time'].isna().sum()} å€‹æ™‚é–“å€¼ç„¡æ•ˆï¼Œå°‡ç§»é™¤")
                self.data = self.data.dropna(subset=["Time"])

            if self.data["Time"].duplicated().any():
                show_warning("DATALOADER", "'Time' æ¬„ä½æœ‰é‡è¤‡å€¼ï¼Œå°‡æŒ‰ Time èšåˆï¼ˆå–å¹³å‡å€¼ï¼‰")
                self.data = (
                    self.data.groupby("Time").mean(numeric_only=True).reset_index()
                )

            # è¨­ç½®ç´¢å¼•ä½†ä¿ç•™ Time æ¬„ä½
            self.data = self.data.reset_index(drop=True)  # ç¢ºä¿ Time ç‚ºæ™®é€šæ¬„ä½
            self.data = self.data.infer_objects()  # æ¶ˆé™¤ dtype inference è­¦å‘Š
            self.data = self.data.sort_values("Time")

        except Exception as e:
            show_error("DATALOADER", f"è™•ç†æ™‚é–“ç´¢å¼•æ™‚å‡ºéŒ¯ï¼š{e}")
            self.data["Time"] = pd.date_range(
                start="2020-01-01", periods=len(self.data)
            )
            self.data = self.data.reset_index(drop=True)
            self.data = self.data.infer_objects()  # æ¶ˆé™¤ dtype inference è­¦å‘Š
