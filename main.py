"""
main.py

ã€åŠŸèƒ½èªªæ˜ã€‘
------------------------------------------------------------
æœ¬æª”æ¡ˆç‚º Lo2cin4BT é‡åŒ–å›æ¸¬æ¡†æ¶çš„ä¸»å…¥å£ï¼Œè² è²¬åˆå§‹åŒ–ç’°å¢ƒã€æä¾›ä¸»é¸å–®ã€å”èª¿æ•¸æ“šè¼‰å…¥ã€çµ±è¨ˆåˆ†æã€å›æ¸¬åŸ·è¡Œã€äº¤æ˜“åˆ†æã€å¯è¦–åŒ–å¹³å°ç­‰å„å€‹åŠŸèƒ½æ¨¡çµ„ã€‚
- æä¾› 6 å€‹ä¸»è¦åŠŸèƒ½é¸é …ï¼šå…¨é¢å›æ¸¬ã€å›æ¸¬äº¤æ˜“ã€äº¤æ˜“åˆ†æã€è‡ªå‹•åŒ–å›æ¸¬ã€æ»¾å‹•å‰å‘åˆ†æ(WFA)ã€å¯è¦–åŒ–å¹³å°
- å”èª¿å„å€‹æ¨¡çµ„çš„åŸ·è¡Œé †åºèˆ‡æ•¸æ“šæµ

ã€æµç¨‹èˆ‡æ•¸æ“šæµã€‘
------------------------------------------------------------
- ä¸»æµç¨‹ï¼šåˆå§‹åŒ– â†’ é¡¯ç¤ºä¸»é¸å–® â†’ æ ¹æ“šé¸æ“‡åŸ·è¡Œå°æ‡‰åŠŸèƒ½æ¨¡çµ„
- å„æ¨¡çµ„é–“æ•¸æ“šæµæ˜ç¢ºï¼Œæµç¨‹å¦‚ä¸‹ï¼š

```mermaid
flowchart TD
    A[main.py] -->|é¸é …1: å…¨é¢å›æ¸¬| B(BaseDataLoader)
    A -->|é¸é …2: å›æ¸¬äº¤æ˜“| C(BaseDataLoader)
    A -->|é¸é …3: äº¤æ˜“åˆ†æ| D(BaseMetricTracker)
    A -->|é¸é …4: è‡ªå‹•åŒ–å›æ¸¬| E(BaseAutorunner)
    A -->|é¸é …5: æ»¾å‹•å‰å‘åˆ†æ| F(BaseWFAAnalyser)
    A -->|é¸é …6: å¯è¦–åŒ–å¹³å°| G(BasePlotter)

    B -->|æ•¸æ“šè¼‰å…¥| H[Data]
    C -->|æ•¸æ“šè¼‰å…¥| H
    H -->|çµ±è¨ˆåˆ†æå¯é¸| I[BaseStatAnalyser]
    H -->|å›æ¸¬åŸ·è¡Œ| J[BaseBacktester]
    J -->|äº¤æ˜“åˆ†æ| D
    D -->|å¯è¦–åŒ–| G

    E -->|è‡ªå‹•åŒ–æµç¨‹| K[Autorunner Modules]
    F -->|WFAæµç¨‹| L[WFAnalyser Modules]
    K -->|çµæœ| J
    L -->|çµæœ| J
```

ã€ç¶­è­·èˆ‡æ“´å……é‡é»ã€‘
------------------------------------------------------------
- æ–°å¢ä¸»é¸å–®é¸é …æ™‚ï¼Œè«‹åŒæ­¥æ›´æ–°é ‚éƒ¨è¨»è§£èˆ‡é¸å–®å…§å®¹
- è‹¥åŠŸèƒ½æ¨¡çµ„ä»‹é¢æœ‰è®Šå‹•ï¼Œéœ€åŒæ­¥æ›´æ–°å°æ‡‰çš„èª¿ç”¨é‚è¼¯
- æ–°å¢/ä¿®æ”¹ä¸»é¸å–®é¸é …ã€åŠŸèƒ½æµç¨‹æ™‚ï¼Œå‹™å¿…åŒæ­¥æ›´æ–°æœ¬æª”æ¡ˆèˆ‡æ‰€æœ‰ä¾è³´æ¨¡çµ„

ã€å¸¸è¦‹æ˜“éŒ¯é»ã€‘
------------------------------------------------------------
- ä¸»æµç¨‹èˆ‡å„æ¨¡çµ„æµç¨‹ä¸åŒæ­¥ï¼Œå°è‡´åƒæ•¸éºæ¼æˆ–çµæœé¡¯ç¤ºéŒ¯èª¤
- åˆå§‹åŒ–ç’°å¢ƒæœªæ­£ç¢ºè¨­ç½®ï¼Œå°è‡´ä¸‹æ¸¸æ¨¡çµ„å ±éŒ¯
- å¤šé€²ç¨‹å›æ¸¬æ™‚æ—¥èªŒç³»çµ±è¡çª

ã€éŒ¯èª¤è™•ç†ã€‘
------------------------------------------------------------
- æ¨¡çµ„å°å…¥å¤±æ•—æ™‚æä¾›è©³ç´°éŒ¯èª¤è¨Šæ¯å’Œæ¨¡çµ„è·¯å¾‘æª¢æŸ¥
- æ•¸æ“šè¼‰å…¥å¤±æ•—æ™‚æä¾›è¨ºæ–·å»ºè­°
- æ—¥èªŒç³»çµ±åˆå§‹åŒ–å¤±æ•—æ™‚æä¾›å‚™ç”¨æ–¹æ¡ˆ
- å¤šé€²ç¨‹å›æ¸¬æ™‚æ—¥èªŒç³»çµ±è¡çªæ™‚æä¾›è§£æ±ºæ–¹æ¡ˆ

ã€ç¯„ä¾‹ã€‘
------------------------------------------------------------
- åŸ·è¡Œä¸»ç¨‹å¼ï¼špython main.py
- é¸æ“‡é¸é … 1ï¼šå…¨é¢å›æ¸¬ï¼ˆè¼‰å…¥æ•¸æ“šâ†’çµ±è¨ˆåˆ†æâ†’å›æ¸¬äº¤æ˜“â†’äº¤æ˜“åˆ†æâ†’å¯è¦–åŒ–å¹³å°ï¼‰
- é¸æ“‡é¸é … 2ï¼šå›æ¸¬äº¤æ˜“ï¼ˆè¼‰å…¥æ•¸æ“šâ†’å›æ¸¬äº¤æ˜“â†’äº¤æ˜“åˆ†æâ†’å¯è¦–åŒ–å¹³å°ï¼‰
- é¸æ“‡é¸é … 3ï¼šäº¤æ˜“åˆ†æï¼ˆäº¤æ˜“åˆ†æâ†’å¯è¦–åŒ–å¹³å°ï¼‰
- é¸æ“‡é¸é … 4ï¼šè‡ªå‹•åŒ–å›æ¸¬ï¼ˆé…ç½®æ–‡ä»¶é©…å‹•ï¼Œæ”¯æ´å¤šé…ç½®æ‰¹æ¬¡åŸ·è¡Œï¼‰
- é¸æ“‡é¸é … 5ï¼šæ»¾å‹•å‰å‘åˆ†æï¼ˆWFAï¼Œé…ç½®æ–‡ä»¶é©…å‹•ï¼Œæ”¯æ´å¤šé…ç½®æ‰¹æ¬¡åŸ·è¡Œï¼‰
- é¸æ“‡é¸é … 6ï¼šå¯è¦–åŒ–å¹³å°ï¼ˆéœ€å·²é€²è¡Œå›æ¸¬äº¤æ˜“æˆ–å‰å‘åˆ†æï¼‰

ã€èˆ‡å…¶ä»–æ¨¡çµ„çš„é—œè¯ã€‘
------------------------------------------------------------
- é¸é … 1-3ï¼šèª¿ç”¨ BaseDataLoaderã€BaseBacktesterã€BaseMetricTrackerã€BasePlotter
- é¸é … 4ï¼šèª¿ç”¨ BaseAutorunnerï¼ˆè‡ªå‹•åŒ–å›æ¸¬ï¼‰
- é¸é … 5ï¼šèª¿ç”¨ BaseWFAAnalyserï¼ˆæ»¾å‹•å‰å‘åˆ†æï¼‰
- é¸é … 6ï¼šèª¿ç”¨ BasePlotterï¼ˆå¯è¦–åŒ–å¹³å°ï¼ŒåŒ…å«å›æ¸¬èˆ‡ WFA å¯è¦–åŒ–ï¼‰

ã€ç‰ˆæœ¬èˆ‡è®Šæ›´è¨˜éŒ„ã€‘
------------------------------------------------------------
- v1.0: åˆå§‹ç‰ˆæœ¬ï¼Œå®šç¾©åŸºæœ¬ä¸»é¸å–®å’Œæµç¨‹
- v1.1: æ–°å¢çµ±è¨ˆåˆ†ææ¨¡çµ„æ•´åˆ
- v1.2: æ–°å¢è‡ªå‹•åŒ–å›æ¸¬å’Œæ»¾å‹•å‰å‘åˆ†æé¸é …
- v1.3: æ–°å¢ Rich Panel é¡¯ç¤ºå’Œæ—¥èªŒç³»çµ±å„ªåŒ–

ã€åƒè€ƒã€‘
------------------------------------------------------------
- è©³ç´°æµç¨‹è¦ç¯„å¦‚æœ‰è®Šå‹•ï¼Œè«‹åŒæ­¥æ›´æ–°æœ¬è¨»è§£èˆ‡ README
- å…¶ä»–æ¨¡çµ„å¦‚æœ‰ä¾è³´æœ¬æª”æ¡ˆçš„è¡Œç‚ºï¼Œè«‹æ–¼å°æ‡‰æ¨¡çµ„é ‚éƒ¨è¨»è§£æ¨™æ˜
- BacktestEngine çš„åƒæ•¸çµ„åˆç”Ÿæˆèˆ‡å¤šé€²ç¨‹åŸ·è¡Œé‚è¼¯è«‹åƒè€ƒå°æ‡‰æ¨¡çµ„
"""

import glob
import logging
import multiprocessing
import os
from logging.handlers import QueueHandler, QueueListener, RotatingFileHandler

import numpy as np
import pandas as pd

# å¯è¦–åŒ–å¹³å°é…ç½®
PLOTTER_HOST = "localhost"  # å¯è¦–åŒ–å¹³å°ä¸»æ©Ÿåœ°å€ï¼ˆå¯æ”¹ç‚º "127.0.0.1" æˆ–å…¶ä»–ï¼‰
PLOTTER_PORT = 8050  # å¯è¦–åŒ–å¹³å°ç«¯å£è™Ÿï¼ˆå¯ä¿®æ”¹ï¼Œä¾‹å¦‚æ”¹ç‚º 8080ã€9000 ç­‰ï¼‰
PLOTTER_BASE_PATH = "/lo2cin4bt/"  # URL è·¯å¾‘å‰ç¶´ï¼ˆä¾‹å¦‚ "/lo2cin4bt/" æœƒè®“ URL è®Šæˆ http://localhost:8050/lo2cin4bt/ï¼‰
PLOTTER_DEBUG = False  # æ˜¯å¦é–‹å•Ÿèª¿è©¦æ¨¡å¼

from backtester.Base_backtester import BaseBacktester
from metricstracker.Base_metricstracker import BaseMetricTracker
from statanalyser.AutocorrelationTest_statanalyser import AutocorrelationTest
from statanalyser.Base_statanalyser import BaseStatAnalyser
from statanalyser.CorrelationTest_statanalyser import CorrelationTest
from statanalyser.DistributionTest_statanalyser import DistributionTest
from statanalyser.ReportGenerator_statanalyser import ReportGenerator
from statanalyser.SeasonalAnalysis_statanalyser import SeasonalAnalysis
from statanalyser.StationarityTest_statanalyser import StationarityTest
from utils import (
    show_error as ui_show_error,
    show_info as ui_show_info,
    show_success as ui_show_success,
    show_menu as ui_show_menu,
    show_welcome as ui_show_welcome,
    show_warning as ui_show_warning,
    get_console,
)

# å¾åŸºé¡åŒ¯å…¥ select_predictor_factor æ–¹æ³•
select_predictor_factor = BaseStatAnalyser.select_predictor_factor

# ç‚ºäº†å‘å¾Œå…¼å®¹ï¼Œä¿ç•™ console è®Šæ•¸
console = get_console()


# === åˆªé™¤æ‰€æœ‰plotguyç›¸é—œimportèˆ‡ä»£ç¢¼ ===

pd.set_option("display.max_columns", None)
pd.set_option("display.width", 1000)
pd.set_option("display.max_colwidth", 20)
os.environ["DASH_ASSETS_FOLDER"] = os.path.join(os.path.dirname(__file__), "assets")
listener = None
log_queue = None


def setup_logging(log_queue=None):
    """
    åƒ…ä¸»é€²ç¨‹è¨­ç½® QueueListener+RotatingFileHandlerï¼Œ
    å­é€²ç¨‹åƒ…è¨­ç½® QueueHandlerï¼Œæ‰€æœ‰ log ç¶“ queue å¯«å…¥ï¼Œé¿å…å¤šé€²ç¨‹å¯«æª”è¡çªã€‚
    """
    global listener
    log_dir = os.path.join(os.path.dirname(__file__), "logs")
    os.makedirs(log_dir, exist_ok=True)
    log_file = os.path.join(log_dir, "backtest_errors.log")

    # é—œé–‰HTTPè«‹æ±‚æ—¥èªŒï¼Œè®“æ§åˆ¶å°æ›´ç°¡æ½”
    logging.getLogger("werkzeug").setLevel(logging.ERROR)
    logging.getLogger("dash").setLevel(logging.ERROR)

    # ä¸»é€²ç¨‹å‰µå»º log_queue
    if multiprocessing.current_process().name == "MainProcess":
        if log_queue is None:
            from multiprocessing import Manager

            log_queue = Manager().Queue(-1)
        handler = RotatingFileHandler(
            log_file, maxBytes=5 * 1024 * 1024, backupCount=5, encoding="utf-8"
        )
        formatter = logging.Formatter(
            "[%(asctime)s] [%(levelname)s] [%(name)s]: %(message)s"
        )
        handler.setFormatter(formatter)
        listener = QueueListener(log_queue, handler)
        listener.start()
        root_logger = logging.getLogger("lo2cin4bt")
        root_logger.setLevel(logging.DEBUG)
        root_logger.handlers = []
        root_logger.addHandler(QueueHandler(log_queue))

        # è¨˜éŒ„ç¨‹å¼å•Ÿå‹•
        root_logger.info("=== ç¨‹å¼å•Ÿå‹• ===")
    else:
        # å­é€²ç¨‹åªè¨­ç½® QueueHandlerï¼Œlog_queue å¿…é ˆç”±ä¸»é€²ç¨‹å‚³å…¥
        root_logger = logging.getLogger("lo2cin4bt")
        root_logger.setLevel(logging.DEBUG)
        root_logger.handlers = []
        if log_queue is not None:
            root_logger.addHandler(QueueHandler(log_queue))
    return listener, log_queue


def _smart_convert_datetime_for_stats(time_series):
    """
    æ™ºèƒ½æª¢æ¸¬ä¸¦è½‰æ›æ™‚é–“æ ¼å¼ï¼ˆç”¨æ–¼çµ±è¨ˆåˆ†æï¼‰
    1. å…ˆæª¢æ¸¬æ˜¯å¦ç‚ºtimestampæ ¼å¼
    2. å†å˜—è©¦ä¸åŒçš„æ—¥æœŸå­—ç¬¦ä¸²æ ¼å¼
    """
    try:
        # 1. æª¢æ¸¬æ˜¯å¦ç‚ºtimestampæ ¼å¼
        if pd.api.types.is_numeric_dtype(time_series):
            sample_value = time_series.iloc[0]
            import numpy as np
            if isinstance(sample_value, (int, float, np.integer, np.floating)):
                if sample_value > 1e10:  # æ¯«ç§’ç´štimestamp
                    ui_show_info("DATALOADER", "æª¢æ¸¬åˆ°æ¯«ç§’ç´štimestampæ ¼å¼ï¼Œæ­£åœ¨è½‰æ›...")
                    return pd.to_datetime(time_series, unit="ms", errors="coerce")
                else:  # ç§’ç´štimestamp
                    ui_show_info("DATALOADER", "æª¢æ¸¬åˆ°ç§’ç´štimestampæ ¼å¼ï¼Œæ­£åœ¨è½‰æ›...")
                    return pd.to_datetime(time_series, unit="s", errors="coerce")
        else:
            # 2. å˜—è©¦å°‡å­—ç¬¦ä¸²è½‰æ›ç‚ºæ•¸å€¼å†åˆ¤æ–·timestamp
            try:
                numeric_value = pd.to_numeric(time_series.iloc[0])
                if numeric_value > 1e10:  # æ¯«ç§’ç´š
                    ui_show_info("DATALOADER", "æª¢æ¸¬åˆ°æ¯«ç§’ç´štimestampæ ¼å¼ï¼Œæ­£åœ¨è½‰æ›...")
                    numeric_series = pd.to_numeric(time_series, errors="coerce")
                    return pd.to_datetime(numeric_series, unit="ms", errors="coerce")
                else:  # ç§’ç´š
                    ui_show_info("DATALOADER", "æª¢æ¸¬åˆ°ç§’ç´štimestampæ ¼å¼ï¼Œæ­£åœ¨è½‰æ›...")
                    numeric_series = pd.to_numeric(time_series, errors="coerce")
                    return pd.to_datetime(numeric_series, unit="s", errors="coerce")
            except (ValueError, TypeError):
                # ä¸æ˜¯timestampï¼Œç¹¼çºŒå˜—è©¦æ—¥æœŸå­—ç¬¦ä¸²æ ¼å¼
                pass
        
        # 3. å˜—è©¦ä¸åŒçš„æ—¥æœŸå­—ç¬¦ä¸²æ ¼å¼
        sample_dates = time_series.head(5).tolist()
        ui_show_info("DATALOADER", f"ğŸ” çµ±è¨ˆåˆ†ææ™ºèƒ½æª¢æ¸¬æ—¥æœŸæ ¼å¼ï¼š\n   æ¨£æœ¬æ—¥æœŸ: {sample_dates}\n   å˜—è©¦è§£æç‚º DD/MM/YYYY æ ¼å¼...")
        
        # å…ˆå˜—è©¦ DD/MM/YYYY æ ¼å¼ï¼ˆdayfirst=Trueï¼‰
        result = pd.to_datetime(time_series, dayfirst=True, errors="coerce")
        invalid_count = result.isna().sum()
        
        if invalid_count == 0:
            ui_show_success("DATALOADER", "æˆåŠŸè§£æç‚º DD/MM/YYYY æ ¼å¼")
            return result
        else:
            # å¦‚æœ DD/MM/YYYY æ ¼å¼å¤±æ•—ï¼Œå˜—è©¦ MM/DD/YYYY æ ¼å¼
            ui_show_warning("DATALOADER", f"DD/MM/YYYY æ ¼å¼è§£æå¤±æ•— {invalid_count} å€‹å€¼ï¼Œå˜—è©¦ MM/DD/YYYY æ ¼å¼...")
            result2 = pd.to_datetime(time_series, dayfirst=False, errors="coerce")
            invalid_count2 = result2.isna().sum()
            
            if invalid_count2 < invalid_count:
                ui_show_success("DATALOADER", "æˆåŠŸè§£æç‚º MM/DD/YYYY æ ¼å¼")
                return result2
            else:
                # å¦‚æœå…©ç¨®æ ¼å¼éƒ½å¤±æ•—ï¼Œä½¿ç”¨è‡ªå‹•æ¨æ–·
                ui_show_warning("DATALOADER", "å…©ç¨®æ ¼å¼éƒ½å¤±æ•—ï¼Œä½¿ç”¨è‡ªå‹•æ¨æ–·æ ¼å¼...")
                return pd.to_datetime(time_series, errors="coerce")
                
    except Exception as e:
        ui_show_error("DATALOADER", f"æ™ºèƒ½æ™‚é–“è½‰æ›å¤±æ•—ï¼š{e}ï¼Œä½¿ç”¨é è¨­æ ¼å¼")
        return pd.to_datetime(time_series, errors="coerce")


def standardize_data_for_stats(data):
    """å°‡æ•¸æ“šæ¨™æº–åŒ–ç‚ºçµ±è¨ˆåˆ†æå™¨æœŸæœ›çš„æ ¼å¼"""
    df = data.copy()

    # ç¢ºä¿ Time æ¬„ä½å­˜åœ¨ä¸”æ ¼å¼æ­£ç¢º
    if "Time" not in df.columns:
        if "time" in df.columns:
            df["Time"] = df["time"]
        else:
            raise ValueError("æ•¸æ“šä¸­ç¼ºå°‘ Time æ¬„ä½")

    # å°‡æ¬„ä½åç¨±è½‰æ›ç‚ºå°å¯«ï¼ˆé™¤äº† Time å’Œé æ¸¬å› å­ç›¸é—œæ¬„ä½ï¼‰
    # ä¿ç•™é æ¸¬å› å­æ¬„ä½çš„åŸå§‹å¤§å°å¯«
    new_columns = []
    for col in df.columns:
        if col == "Time":
            new_columns.append("Time")
        elif col.lower() in ["open", "high", "low", "close", "volume"]:
            new_columns.append(col.lower())
        elif col.endswith(("_return", "_logreturn")):
            new_columns.append(col.lower())
        else:
            # ä¿ç•™é æ¸¬å› å­æ¬„ä½çš„åŸå§‹å¤§å°å¯«
            new_columns.append(col)

    df.columns = new_columns

    # ç¢ºä¿ Time æ¬„ä½ç‚º datetime æ ¼å¼
    # æ·»åŠ debugè¼¸å‡º
    ui_show_info("DATALOADER", 
        f"ğŸ” çµ±è¨ˆåˆ†ææ™‚é–“è½‰æ›å‰æª¢æŸ¥ï¼š\n"
        f"   Timeæ¬„ä½é¡å‹: {df['Time'].dtype}\n"
        f"   å‰5å€‹å€¼: {df['Time'].head().tolist()}\n"
        f"   å¾Œ5å€‹å€¼: {df['Time'].tail().tolist()}\n"
        f"   å”¯ä¸€å€¼æ•¸é‡: {df['Time'].nunique()}\n"
        f"   ç¸½è¡Œæ•¸: {len(df)}"
    )
    
    # ä½¿ç”¨æ™ºèƒ½æ™‚é–“è½‰æ›
    original_time = df["Time"].copy()
    df["Time"] = _smart_convert_datetime_for_stats(df["Time"])
    
    # æª¢æŸ¥è½‰æ›çµæœ
    invalid_mask = df["Time"].isna()
    if invalid_mask.any():
        invalid_indices = invalid_mask[invalid_mask].index.tolist()
        invalid_values = original_time[invalid_mask].tolist()
        
        ui_show_error("DATALOADER",
            f"çµ±è¨ˆåˆ†æç™¼ç¾ç„¡æ•ˆæ™‚é–“å€¼ï¼š\n"
            f"   ç„¡æ•ˆå€¼æ•¸é‡: {len(invalid_values)}\n"
            f"   ç„¡æ•ˆå€¼ç´¢å¼•: {invalid_indices[:10]}{'...' if len(invalid_indices) > 10 else ''}\n"
            f"   ç„¡æ•ˆå€¼æ¨£æœ¬: {invalid_values[:10]}{'...' if len(invalid_values) > 10 else ''}\n"
            f"   åŸå§‹å€¼é¡å‹: {[type(v) for v in invalid_values[:5]]}"
        )
        
        # ç§»é™¤ç„¡æ•ˆæ™‚é–“å€¼
        df = df.dropna(subset=["Time"])
        ui_show_warning("DATALOADER", f"å·²ç§»é™¤ {len(invalid_values)} å€‹ç„¡æ•ˆæ™‚é–“å€¼ï¼Œå‰©é¤˜ {len(df)} è¡Œæ•¸æ“š")

    # å¦‚æœæ²’æœ‰æ”¶ç›Šç‡æ¬„ä½ï¼Œéœ€è¦è¨ˆç®—
    if "close_return" not in df.columns:
        if "close" in df.columns:
            # è¨ˆç®—æ”¶ç›Šç‡
            df["close_return"] = df["close"].pct_change()
            df["close_logreturn"] = np.log(df["close"] / df["close"].shift(1))
            df["open_return"] = df["open"].pct_change()
            df["open_logreturn"] = np.log(df["open"] / df["open"].shift(1))
            # è™•ç†ç„¡é™å€¼å’Œ NaN
            for col in [
                "close_return",
                "close_logreturn",
                "open_return",
                "open_logreturn",
            ]:
                df[col] = df[col].replace([np.inf, -np.inf], np.nan).fillna(0)
        else:
            ui_show_warning("DATALOADER", "ç¼ºå°‘ close æ¬„ä½ï¼Œç„¡æ³•è¨ˆç®—æ”¶ç›Šç‡")

    return df


def select_parquet_file(parquet_dir):
    parquet_files = sorted(glob.glob(os.path.join(parquet_dir, "*.parquet")))
    if not parquet_files:
        print(f"[ä¸»æµç¨‹][ERROR] è³‡æ–™å¤¾ {parquet_dir} ä¸‹æ‰¾ä¸åˆ° parquet æª”æ¡ˆï¼")
        return None
    print("[ä¸»æµç¨‹] å¯é¸æ“‡çš„ parquet æª”æ¡ˆï¼š")
    for i, f in enumerate(parquet_files, 1):
        print(f"  {i}. {os.path.basename(f)}")
    file_input = input("è«‹è¼¸å…¥è¦è®€å–çš„æª”æ¡ˆç·¨è™Ÿï¼ˆé è¨­1ï¼‰ï¼š").strip() or "1"
    try:
        idx = int(file_input) - 1
        assert 0 <= idx < len(parquet_files)
    except Exception:
        print("[ä¸»æµç¨‹][ERROR] è¼¸å…¥ç„¡æ•ˆï¼Œé è¨­é¸æ“‡ç¬¬ä¸€å€‹æª”æ¡ˆã€‚")
        idx = 0
    return parquet_files[idx]


def _run_statistical_analysis(data, diff_cols, logger):
    """
    åŸ·è¡Œçµ±è¨ˆåˆ†ææµç¨‹
    
    Args:
        data: æ•¸æ“šDataFrame
        diff_cols: å·®åˆ†æ¬„ä½åˆ—è¡¨
        logger: æ—¥èªŒè¨˜éŒ„å™¨
        
    Returns:
        updated_data: æ›´æ–°å¾Œçš„æ•¸æ“š
    """
    selected_col = select_predictor_factor(
        data, default_factor=diff_cols[0] if diff_cols else None
    )
    used_series = data[selected_col]
    stats_data = standardize_data_for_stats(data)
    updated_data = stats_data.copy()
    updated_data[selected_col] = used_series

    def infer_data_freq(df):
        import pandas as pd

        if not isinstance(df.index, pd.DatetimeIndex):
            if "Time" in df.columns:
                df["Time"] = pd.to_datetime(df["Time"])
                df = df.set_index("Time")
            else:
                raise ValueError("è³‡æ–™å¿…é ˆæœ‰ DatetimeIndex æˆ– 'Time' æ¬„ä½")
        freq = pd.infer_freq(df.index)
        if freq is None:
            freq = "D"
            print("âš ï¸ ç„¡æ³•è‡ªå‹•åˆ¤æ–·é »ç‡ï¼Œå·²é è¨­ç‚ºæ—¥ç·šï¼ˆDï¼‰")
        return freq[0].upper()  # åªå–ç¬¬ä¸€å€‹å­—æ¯ D/H/T

    freq = infer_data_freq(updated_data)
    analyzers = [
        CorrelationTest(updated_data, selected_col, "close_return"),
        StationarityTest(updated_data, selected_col, "close_return"),
        AutocorrelationTest(
            updated_data, selected_col, "close_return", freq=freq
        ),
        DistributionTest(updated_data, selected_col, "close_return"),
        SeasonalAnalysis(updated_data, selected_col, "close_return"),
    ]
    results = {}
    for analyzer in analyzers:
        test_name = (
            f"{analyzer.__class__.__name__}_{analyzer.predictor_col}"
        )
        try:
            analyzer.analyze()
            results[test_name] = (
                analyzer.results if hasattr(analyzer, "results") else None
            )
        except Exception as e:
            ui_show_error("STATANALYSER", f"Error in {test_name}: {e}")
            logger.error(f"çµ±è¨ˆåˆ†æå¤±æ•— {test_name}: {e}")
            results[test_name] = {"error": str(e)}

    reporter = ReportGenerator()
    reporter.save_report(results)
    reporter.save_data(updated_data, format="csv")
    logger.info("çµ±è¨ˆåˆ†æå®Œæˆ")
    
    return updated_data


def _run_backtest_and_analysis(data, frequency, data_loader, logger):
    """
    åŸ·è¡Œå›æ¸¬ã€äº¤æ˜“åˆ†æå’Œå¯è¦–åŒ–å¹³å°çš„çµ±ä¸€æµç¨‹
    
    Args:
        data: æ•¸æ“šDataFrame
        frequency: æ•¸æ“šé »ç‡
        data_loader: BaseDataLoaderå¯¦ä¾‹
        logger: æ—¥èªŒè¨˜éŒ„å™¨
    """
    predictor_file_name = getattr(data_loader, "predictor_file_name", None)
    symbol = getattr(data_loader, "symbol", "X")
    
    # åŸ·è¡Œå›æ¸¬
    backtester = BaseBacktester(data, frequency, logger, predictor_file_name, symbol)
    backtester.run()
    logger.info("å›æ¸¬å®Œæˆ")
    ui_show_success("BACKTESTER", "å›æ¸¬å®Œæˆï¼")

    # äº¤æ˜“åˆ†æ
    metric_tracker = BaseMetricTracker()
    metric_tracker.run_analysis()
    
    # è©¢å•æ˜¯å¦å•Ÿå‹•å¯è¦–åŒ–å¹³å°
    console.print(
        "[bold #dbac30]æ˜¯å¦å•Ÿå‹•å›æ¸¬èˆ‡ WFA å¯è¦–åŒ–å¹³å°ï¼Ÿ(y/nï¼Œé è¨­yï¼‰ï¼š[/bold #dbac30]"
    )
    run_plotter = input().strip().lower() or "y"
    if run_plotter == "y":
        try:
            from plotter.Base_plotter import BasePlotter

            plotter = BasePlotter(logger=logger, url_base_pathname=PLOTTER_BASE_PATH)
            plotter.run(host=PLOTTER_HOST, port=PLOTTER_PORT, debug=PLOTTER_DEBUG)
        except Exception as e:
            print(f"âŒ å›æ¸¬èˆ‡ WFA å¯è¦–åŒ–å¹³å°å•Ÿå‹•å¤±æ•—: {e}")


def main():
    global listener, log_queue

    # è¨­å®šç¬¬ä¸‰æ–¹åº«çš„æ—¥èªŒç´šåˆ¥ï¼Œé¿å… DEBUG è¨Šæ¯
    logging.getLogger("urllib3").setLevel(logging.WARNING)
    logging.getLogger("asyncio").setLevel(logging.WARNING)
    logging.getLogger("requests").setLevel(logging.WARNING)

    # åƒ…ä¸»é€²ç¨‹è¨­ç½® loggingï¼Œä¸¦å°‡ log_queue å‚³çµ¦ Base_backtester
    listener, log_queue = setup_logging()
    logger = logging.getLogger("lo2cin4bt")

    logger.info("ç¨‹å¼é–‹å§‹åŸ·è¡Œ")

    # æ­¡è¿è¨Šæ¯
    welcome_content = (
        "[bold #dbac30]ğŸš€ lo2cin4bt[/bold #dbac30]\n"
        "[white]The best backtest engine for non-coders and quant beginners (probably).[/white]\n\n"
        "ğŸŒ Github: https://github.com/lo2cin4/lo2cin4bt\n"
        "ğŸŒ Website: https://lo2cin4.com\n"
        "ğŸ’ Quant Lifetime Membership: https://lo2cin4.com/membership\n"
        "ğŸ’¬ Discord: https://discord.gg/6HgJC2dUvg\n"
        "âœˆï¸ Telegram: https://t.me/lo2cin4group"
    )
    ui_show_welcome("lo2cin4bt", welcome_content)

    # ä¸»é¸å–®å…§å®¹
    menu_items = [
        "[bold #dbac30]æ•¸æ“šçµ±è¨ˆèˆ‡å›æ¸¬äº¤æ˜“[/bold #dbac30]",
        "[bold white]1. å…¨é¢å›æ¸¬ (è¼‰å…¥æ•¸æ“šâ†’çµ±è¨ˆåˆ†æâ†’å›æ¸¬äº¤æ˜“â†’äº¤æ˜“åˆ†æâ†’å›æ¸¬èˆ‡ WFA å¯è¦–åŒ–å¹³å°)\n"
        "2. å›æ¸¬äº¤æ˜“ (è¼‰å…¥æ•¸æ“šâ†’å›æ¸¬äº¤æ˜“â†’äº¤æ˜“åˆ†æâ†’å›æ¸¬èˆ‡ WFA å¯è¦–åŒ–å¹³å°)\n"
        "3. äº¤æ˜“åˆ†æ (äº¤æ˜“åˆ†æâ†’å›æ¸¬èˆ‡ WFA å¯è¦–åŒ–å¹³å°)\n"
        "4. è‡ªå‹•åŒ–å›æ¸¬ Autorunner (é…ç½®æ–‡ä»¶é©…å‹•ï¼Œæ”¯æ´å¤šé…ç½®æ‰¹æ¬¡åŸ·è¡Œ)[/bold white]",
        "",
        "[bold #dbac30]æ»¾å‹•å‰å‘åˆ†æ (WFA) [/bold #dbac30]",
        "[bold white]5. æ»¾å‹•å‰å‘åˆ†æ Autorunner (é…ç½®æ–‡ä»¶é©…å‹•ï¼Œæ”¯æ´å¤šé…ç½®æ‰¹æ¬¡åŸ·è¡Œ)[/bold white]",
        "",
        "[bold #dbac30]å¯è¦–åŒ–å¹³å°[/bold #dbac30]",
        "[bold white]6. å›æ¸¬èˆ‡ WFA å¯è¦–åŒ–å¹³å° (éœ€å·²é€²è¡Œå›æ¸¬äº¤æ˜“æˆ–å‰å‘åˆ†æ)[/bold white]",
    ]
    
    def display_main_menu():
        """é¡¯ç¤ºä¸»é¸å–®"""
        ui_show_menu("ğŸ ä¸»é¸å–®", menu_items)
        console = get_console()
        console.print(
            "[bold #dbac30]è«‹é¸æ“‡è¦åŸ·è¡Œçš„åŠŸèƒ½ï¼ˆ1, 2, 3, 4, 5, 6ï¼Œé è¨­1ï¼‰ï¼š[/bold #dbac30]"
        )
    
    display_main_menu()
    console = get_console()
    while True:
        choice = input().strip() or "1"
        if choice in ["1", "2", "3", "4", "5", "6"]:
            break
        ui_show_error("", "ç„¡æ•ˆé¸æ“‡ï¼Œè«‹é‡æ–°è¼¸å…¥ 1~6ã€‚")
        # é‡æ–°å°å‡ºä¸»é¸å–®
        display_main_menu()

    try:
        if choice == "1":
            # å…¨é¢å›æ¸¬ï¼Œä½¿ç”¨ BaseDataLoader è™•ç†æ‰€æœ‰æ•¸æ“šä¾†æºäº’å‹•
            from dataloader.base_loader import BaseDataLoader

            data_loader = BaseDataLoader(logger=logger)
            data = data_loader.run()

            if data is None:
                ui_show_error("DATALOADER", "æ•¸æ“šè¼‰å…¥å¤±æ•—ï¼Œç¨‹å¼çµ‚æ­¢")
                logger.error("æ•¸æ“šè¼‰å…¥å¤±æ•—")
                return

            # è™•ç†ç‰¹æ®Šæƒ…æ³ï¼šè·³éçµ±è¨ˆåˆ†æ
            if isinstance(data, str) and data == "__SKIP_STATANALYSER__":
                print("æœªè¼¸å…¥é æ¸¬å› å­æª”æ¡ˆï¼Œå°‡è·³éçµ±è¨ˆåˆ†æï¼Œåƒ…ä½¿ç”¨åƒ¹æ ¼æ•¸æ“šã€‚")
                data = data_loader.data
                frequency = data_loader.frequency
                _run_backtest_and_analysis(data, frequency, data_loader, logger)
                return

            # ç¢ºä¿ frequency è¢«å®šç¾©
            frequency = data_loader.frequency

            # è™•ç†å·®åˆ†æ­¥é©Ÿ
            data, diff_cols, used_series = data_loader.process_difference(data)
            if diff_cols:
                logger.info(f"å·®åˆ†è™•ç†å®Œæˆï¼Œå·®åˆ†æ¬„ä½ï¼š{diff_cols}")

            # æª¢æŸ¥æ˜¯å¦é¸æ“‡äº†priceï¼ˆè·³éçµ±è¨ˆåˆ†æï¼‰
            if hasattr(data_loader, 'skip_statanalyser') and data_loader.skip_statanalyser:
                # ç”¨æˆ¶é¸æ“‡äº†priceï¼Œè·³éçµ±è¨ˆåˆ†æ
                ui_show_info("DATALOADER", "å·²é¸æ“‡åƒ…ä½¿ç”¨åƒ¹æ ¼æ•¸æ“šï¼Œè·³éçµ±è¨ˆåˆ†æã€‚")
                logger.info("ç”¨æˆ¶é¸æ“‡priceï¼Œè·³éçµ±è¨ˆåˆ†æ")
                # ç›´æ¥é€²è¡Œå›æ¸¬ï¼Œä¸é€²è¡Œçµ±è¨ˆåˆ†æ
                _run_backtest_and_analysis(data, frequency, data_loader, logger)
                return
            else:
                # é€²è¡Œçµ±è¨ˆåˆ†æ
                updated_data = _run_statistical_analysis(data, diff_cols, logger)
                # ä½¿ç”¨æ›´æ–°å¾Œçš„æ•¸æ“šé€²è¡Œå›æ¸¬
                _run_backtest_and_analysis(updated_data, frequency, data_loader, logger)
                return
        elif choice == "2":
            # å›æ¸¬äº¤æ˜“
            logger.info("[ä¸»é¸å–®] å›æ¸¬äº¤æ˜“")

            # ä½¿ç”¨æ–°çš„ BaseDataLoader
            from dataloader.base_loader import BaseDataLoader

            data_loader = BaseDataLoader(logger=logger)
            data = data_loader.run()

            if data is None:
                ui_show_error("DATALOADER", "æ•¸æ“šè¼‰å…¥å¤±æ•—ï¼Œç¨‹å¼çµ‚æ­¢")
                logger.error("æ•¸æ“šè¼‰å…¥å¤±æ•—")
                return
            
            # ç¢ºä¿ frequency è¢«å®šç¾©
            frequency = data_loader.frequency

            # è™•ç†å·®åˆ†æ­¥é©Ÿ
            data, diff_cols, used_series = data_loader.process_difference(data)
            if diff_cols:
                logger.info(f"å·®åˆ†è™•ç†å®Œæˆï¼Œå·®åˆ†æ¬„ä½ï¼š{diff_cols}")

            # æª¢æŸ¥æ˜¯å¦é¸æ“‡äº†priceï¼ˆè·³éçµ±è¨ˆåˆ†æï¼‰
            if hasattr(data_loader, 'skip_statanalyser') and data_loader.skip_statanalyser:
                # ç”¨æˆ¶é¸æ“‡äº†priceï¼Œè·³éçµ±è¨ˆåˆ†æ
                ui_show_info("DATALOADER", "å·²é¸æ“‡åƒ…ä½¿ç”¨åƒ¹æ ¼æ•¸æ“šï¼Œè·³éçµ±è¨ˆåˆ†æã€‚")
                logger.info("ç”¨æˆ¶é¸æ“‡priceï¼Œè·³éçµ±è¨ˆåˆ†æ")

            # åŸ·è¡Œå›æ¸¬ã€äº¤æ˜“åˆ†æå’Œå¯è¦–åŒ–
            _run_backtest_and_analysis(data, frequency, data_loader, logger)
            return
        elif choice == "3":
            # äº¤æ˜“åˆ†æï¼ˆmetricstracker + å›æ¸¬èˆ‡ WFA å¯è¦–åŒ–å¹³å°ï¼‰
            logger.info("[ä¸»é¸å–®] äº¤æ˜“åˆ†æï¼ˆmetricstrackerâ†’å›æ¸¬èˆ‡ WFA å¯è¦–åŒ–å¹³å°ï¼‰")
            metric_tracker = BaseMetricTracker()
            metric_tracker.run_analysis()
            console.print(
                "[bold #dbac30]æ˜¯å¦å•Ÿå‹•å›æ¸¬èˆ‡ WFA å¯è¦–åŒ–å¹³å°ï¼Ÿ(y/nï¼Œé è¨­y)ï¼š[/bold #dbac30]"
            )
            run_plotter = input().strip().lower() or "y"
            if run_plotter == "y":
                try:
                    from plotter.Base_plotter import BasePlotter

                    plotter = BasePlotter(logger=logger, url_base_pathname=PLOTTER_BASE_PATH)
                    plotter.run(host=PLOTTER_HOST, port=PLOTTER_PORT, debug=PLOTTER_DEBUG)
                except Exception as e:
                    print(f"âŒ å›æ¸¬èˆ‡ WFA å¯è¦–åŒ–å¹³å°å•Ÿå‹•å¤±æ•—: {e}")
        elif choice == "4":
            # Autorunner è‡ªå‹•åŒ–å›æ¸¬
            logger.info("[ä¸»é¸å–®] é€²å…¥ Autorunner è‡ªå‹•åŒ–å›æ¸¬æ¨¡å¼")

            try:
                # å°å…¥ autorunner æ¨¡çµ„
                from autorunner.Base_autorunner import BaseAutorunner

                # å‰µå»º autorunner å¯¦ä¾‹
                autorunner = BaseAutorunner(logger=logger)

                # åŸ·è¡Œ autorunner
                autorunner.run()

            except ImportError as e:
                print(f"âŒ [ERROR] å°å…¥ autorunner æ¨¡çµ„å¤±æ•—: {e}")
                logger.error(f"å°å…¥ autorunner æ¨¡çµ„å¤±æ•—: {e}")
                ui_show_error("", f"å°å…¥ autorunner æ¨¡çµ„å¤±æ•—: {e}\n\nè«‹ç¢ºä¿ autorunner æ¨¡çµ„å·²æ­£ç¢ºå®‰è£ã€‚")
            except Exception as e:
                print(f"âŒ [ERROR] autorunner åŸ·è¡Œå¤±æ•—: {e}")
                logger.error(f"autorunner åŸ·è¡Œå¤±æ•—: {e}")
                ui_show_error("", f"autorunner åŸ·è¡Œå¤±æ•—: {e}")
                import traceback

                traceback.print_exc()
        elif choice == "5":
            # WFA è‡ªå‹•åŒ–æ¨¡å¼ï¼ˆJSON é…ç½®ï¼‰
            logger.info("[ä¸»é¸å–®] é€²å…¥ WFA è‡ªå‹•åŒ–æ¨¡å¼ï¼ˆJSON é…ç½®ï¼‰")

            try:
                # å°å…¥ wfanalyser æ¨¡çµ„
                from wfanalyser.Base_wfanalyser import BaseWFAAnalyser

                # å‰µå»º WFA å¯¦ä¾‹
                wfa_analyser = BaseWFAAnalyser(logger=logger)

                # åŸ·è¡Œ WFAï¼ˆJSON æ¨¡å¼ï¼‰
                wfa_analyser.run_json_mode()

            except ImportError as e:
                print(f"âŒ [ERROR] å°å…¥ wfanalyser æ¨¡çµ„å¤±æ•—: {e}")
                logger.error(f"å°å…¥ wfanalyser æ¨¡çµ„å¤±æ•—: {e}")
                ui_show_error("", f"å°å…¥ wfanalyser æ¨¡çµ„å¤±æ•—: {e}\n\nè«‹ç¢ºä¿ wfanalyser æ¨¡çµ„å·²æ­£ç¢ºå®‰è£ã€‚")
            except Exception as e:
                print(f"âŒ [ERROR] WFA åŸ·è¡Œå¤±æ•—: {e}")
                logger.error(f"WFA åŸ·è¡Œå¤±æ•—: {e}")
                ui_show_error("", f"WFA åŸ·è¡Œå¤±æ•—: {e}")
                import traceback

                traceback.print_exc()
        elif choice == "6":
            # å›æ¸¬èˆ‡å‰å‘åˆ†æå¯è¦–åŒ–å¹³å°
            logger.info("[ä¸»é¸å–®] å›æ¸¬èˆ‡å‰å‘åˆ†æå¯è¦–åŒ–å¹³å°")
            try:
                from plotter.Base_plotter import BasePlotter

                plotter = BasePlotter(logger=logger, url_base_pathname=PLOTTER_BASE_PATH)
                plotter.run(host=PLOTTER_HOST, port=PLOTTER_PORT, debug=PLOTTER_DEBUG)
            except ImportError as e:
                print(f"âŒ å°å…¥ plotter æ¨¡çµ„å¤±æ•—: {e}")
                logger.error(f"å°å…¥ plotter æ¨¡çµ„å¤±æ•—: {e}")
                print("è«‹ç¢ºä¿å·²å®‰è£æ‰€éœ€çš„ä¾è³´å¥—ä»¶ï¼š")
                print("pip install dash dash-bootstrap-components plotly")
            except Exception as e:
                print(f"âŒ å›æ¸¬èˆ‡ WFA å¯è¦–åŒ–å¹³å°å•Ÿå‹•å¤±æ•—: {e}")
                logger.error(f"å›æ¸¬èˆ‡ WFA å¯è¦–åŒ–å¹³å°å•Ÿå‹•å¤±æ•—: {e}")
        else:
            pass
    except Exception as e:
        ui_show_error("", f"ç¨‹å¼åŸ·è¡Œéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        logger.error(f"ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤ï¼š{e}", exc_info=True)
    finally:
        if listener:
            listener.stop()
            ui_show_info("", "æ—¥èªŒç³»çµ±å·²åœæ­¢")
            logger.info("ç¨‹å¼çµæŸ")


# ç§»é™¤ _run_trade_analysis å‡½æ•¸

if __name__ == "__main__":
    main()
