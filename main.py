"""
main.py

ã€åŠŸèƒ½èªªæ˜ã€‘
------------------------------------------------------------
æœ¬æª”æ¡ˆç‚º Lo2cin4BT é‡åŒ–å›æ¸¬æ¡†æ¶çš„ä¸»å…¥å£ï¼Œè² è²¬åˆå§‹åŒ–ç’°å¢ƒã€èª¿ç”¨å›æ¸¬ä¸»æµç¨‹ã€å”èª¿æ•¸æ“šè¼‰å…¥ã€çµ±è¨ˆåˆ†æã€ç”¨æˆ¶äº’å‹•ã€å›æ¸¬åŸ·è¡Œã€çµæœå°å‡ºç­‰ã€‚

ã€é—œè¯æµç¨‹èˆ‡æ•¸æ“šæµã€‘
------------------------------------------------------------
- ä¸»æµç¨‹ï¼šåˆå§‹åŒ– â†’ æ•¸æ“šè¼‰å…¥ â†’ é æ¸¬å› å­é¸æ“‡ â†’ çµ±è¨ˆåˆ†æ(å¯é¸) â†’ ç”¨æˆ¶äº’å‹• â†’ å›æ¸¬åŸ·è¡Œ â†’ çµæœå°å‡º
- å„æ¨¡çµ„é–“æ•¸æ“šæµæ˜ç¢ºï¼Œæµç¨‹å¦‚ä¸‹ï¼š

```mermaid
flowchart TD
    A[main.py] -->|èª¿ç”¨| B(BaseBacktester)
    B -->|è¼‰å…¥æ•¸æ“š| C[DataImporter]
    B -->|é¸æ“‡é æ¸¬å› å­| D[PredictorLoader]
    B -->|çµ±è¨ˆåˆ†æ| E[BaseStatAnalyser]
    B -->|ç”¨æˆ¶äº’å‹•| F[UserInterface]
    B -->|åŸ·è¡Œå›æ¸¬| G[BacktestEngine]
    G -->|ç”¢ç”Ÿä¿¡è™Ÿ| H[Indicators]
    G -->|æ¨¡æ“¬äº¤æ˜“| I[TradeSimulator]
    G -->|è¨˜éŒ„äº¤æ˜“| J[TradeRecorder]
    B -->|å°å‡ºçµæœ| K[TradeRecordExporter]
```

ã€ä¸»æµç¨‹æ­¥é©Ÿèˆ‡åƒæ•¸å‚³éç´°ç¯€ã€‘
------------------------------------------------------------
- ç”± main.py å•Ÿå‹•ï¼Œä¾åºèª¿ç”¨æ•¸æ“šè¼‰å…¥ã€é æ¸¬å› å­è™•ç†ã€çµ±è¨ˆåˆ†æã€å›æ¸¬åŸ·è¡Œ
- BacktestEngine è² è²¬åƒæ•¸çµ„åˆç”Ÿæˆã€å¤šé€²ç¨‹å›æ¸¬åŸ·è¡Œã€ä¿¡è™Ÿåˆä½µã€äº¤æ˜“æ¨¡æ“¬
- **æ¯æ¬¡æ–°å¢/ä¿®æ”¹ä¸»æµç¨‹ã€åƒæ•¸çµæ§‹ã€çµæœæ ¼å¼æ™‚ï¼Œå¿…é ˆåŒæ­¥æª¢æŸ¥æœ¬æª”æ¡ˆèˆ‡æ‰€æœ‰ä¾è³´æ¨¡çµ„**

ã€ç¶­è­·èˆ‡æ“´å……æé†’ã€‘
------------------------------------------------------------
- æ–°å¢ä¸»æµç¨‹æ­¥é©Ÿã€åƒæ•¸ã€çµæœæ¬„ä½æ™‚ï¼Œè«‹åŒæ­¥æ›´æ–°é ‚éƒ¨è¨»è§£èˆ‡å°æ‡‰æ¨¡çµ„
- è‹¥åƒæ•¸çµæ§‹æœ‰è®Šå‹•ï¼Œéœ€åŒæ­¥æ›´æ–° BaseBacktesterã€BacktestEngineã€IndicatorParamsã€TradeRecordExporter ç­‰ä¾è³´æ¨¡çµ„

ã€å¸¸è¦‹æ˜“éŒ¯é»ã€‘
------------------------------------------------------------
- ä¸»æµç¨‹èˆ‡å„æ¨¡çµ„æµç¨‹ä¸åŒæ­¥ï¼Œå°è‡´åƒæ•¸éºæ¼æˆ–çµæœé¡¯ç¤ºéŒ¯èª¤
- åˆå§‹åŒ–ç’°å¢ƒæœªæ­£ç¢ºè¨­ç½®ï¼Œå°è‡´ä¸‹æ¸¸æ¨¡çµ„å ±éŒ¯
- å¤šé€²ç¨‹å›æ¸¬æ™‚æ—¥èªŒç³»çµ±è¡çª

ã€ç¯„ä¾‹ã€‘
------------------------------------------------------------
- åŸ·è¡Œå®Œæ•´å›æ¸¬æµç¨‹ï¼špython main.py
- è‡ªè¨‚åƒæ•¸å•Ÿå‹•ï¼špython main.py --config config.json

ã€èˆ‡å…¶ä»–æ¨¡çµ„çš„é—œè¯ã€‘
------------------------------------------------------------
- èª¿ç”¨ BaseBacktesterï¼Œå”èª¿ DataImporterã€PredictorLoaderã€BaseStatAnalyserã€UserInterfaceã€BacktestEngineã€TradeRecordExporter
- åƒæ•¸çµæ§‹ä¾è³´ IndicatorParams
- BacktestEngine è² è²¬å¤šé€²ç¨‹å›æ¸¬åŸ·è¡Œèˆ‡ä¿¡è™Ÿåˆä½µ

ã€ç¶­è­·é‡é»ã€‘
------------------------------------------------------------
- æ–°å¢/ä¿®æ”¹ä¸»æµç¨‹ã€åƒæ•¸çµæ§‹ã€çµæœæ ¼å¼æ™‚ï¼Œå‹™å¿…åŒæ­¥æ›´æ–°æœ¬æª”æ¡ˆèˆ‡æ‰€æœ‰ä¾è³´æ¨¡çµ„
- BacktestEngine çš„ä¿¡è™Ÿåˆä½µé‚è¼¯èˆ‡å¤šé€²ç¨‹åŸ·è¡Œæ©Ÿåˆ¶éœ€è¦ç‰¹åˆ¥æ³¨æ„

ã€åƒè€ƒã€‘
------------------------------------------------------------
- è©³ç´°æµç¨‹è¦ç¯„å¦‚æœ‰è®Šå‹•ï¼Œè«‹åŒæ­¥æ›´æ–°æœ¬è¨»è§£èˆ‡ README
- å…¶ä»–æ¨¡çµ„å¦‚æœ‰ä¾è³´æœ¬æª”æ¡ˆçš„è¡Œç‚ºï¼Œè«‹æ–¼å°æ‡‰æ¨¡çµ„é ‚éƒ¨è¨»è§£æ¨™æ˜
- BacktestEngine çš„åƒæ•¸çµ„åˆç”Ÿæˆèˆ‡å¤šé€²ç¨‹åŸ·è¡Œé‚è¼¯è«‹åƒè€ƒå°æ‡‰æ¨¡çµ„
"""

import sys
import os
import logging
from logging.handlers import RotatingFileHandler, QueueListener, QueueHandler
import pandas as pd
from dataloader.Base_loader import DataLoader
from dataloader.DataExporter_loader import DataExporter
from backtester.Base_backtester import BaseBacktester
from backtester.DataImporter_backtester import DataImporter
from statanalyser.Base_statanalyser import BaseStatAnalyser
from statanalyser.CorrelationTest_statanalyser import CorrelationTest
from statanalyser.StationarityTest_statanalyser import StationarityTest
from statanalyser.AutocorrelationTest_statanalyser import AutocorrelationTest
from statanalyser.DistributionTest_statanalyser import DistributionTest
from statanalyser.SeasonalAnalysis_statanalyser import SeasonalAnalysis
from statanalyser.ReportGenerator_statanalyser import ReportGenerator
from dataloader.Predictor_loader import PredictorLoader
from metricstracker.MetricsCalculator_metricstracker import MetricsCalculatorMetricTracker
from metricstracker.Base_metricstracker import BaseMetricTracker
from metricstracker.MetricsExporter_metricstracker import MetricsExporter

# å¾åŸºé¡åŒ¯å…¥ select_predictor_factor æ–¹æ³•
select_predictor_factor = BaseStatAnalyser.select_predictor_factor

import openpyxl
import multiprocessing
import numpy as np
from datetime import datetime
import glob

# === åˆªé™¤æ‰€æœ‰plotguyç›¸é—œimportèˆ‡ä»£ç¢¼ ===

pd.set_option('display.max_columns', None)
pd.set_option('display.width', 1000)
pd.set_option('display.max_colwidth', 20)
os.environ['DASH_ASSETS_FOLDER'] = os.path.join(os.path.dirname(__file__), 'assets')
listener = None
log_queue = None

def setup_logging(log_queue=None):
    """
    åƒ…ä¸»é€²ç¨‹è¨­ç½® QueueListener+RotatingFileHandlerï¼Œ
    å­é€²ç¨‹åƒ…è¨­ç½® QueueHandlerï¼Œæ‰€æœ‰ log ç¶“ queue å¯«å…¥ï¼Œé¿å…å¤šé€²ç¨‹å¯«æª”è¡çªã€‚
    """
    global listener
    log_dir = os.path.join(os.path.dirname(__file__), "logs")
    os.makedirs(log_dir, exist_ok=True)
    log_file = os.path.join(log_dir, "backtest_errors.log")

    # ä¸»é€²ç¨‹å‰µå»º log_queue
    if multiprocessing.current_process().name == "MainProcess":
        if log_queue is None:
            from multiprocessing import Manager
            log_queue = Manager().Queue(-1)
        handler = RotatingFileHandler(log_file, maxBytes=5*1024*1024, backupCount=5, encoding='utf-8')
        formatter = logging.Formatter("[%(asctime)s] [%(levelname)s] [%(name)s]: %(message)s")
        handler.setFormatter(formatter)
        listener = QueueListener(log_queue, handler)
        listener.start()
        root_logger = logging.getLogger("lo2cin4bt")
        root_logger.setLevel(logging.DEBUG)
        root_logger.handlers = []
        root_logger.addHandler(QueueHandler(log_queue))
        
        # æ·»åŠ æ§åˆ¶å°è¼¸å‡º
        # console_handler = logging.StreamHandler()
        # console_handler.setLevel(logging.INFO)
        # console_formatter = logging.Formatter("[%(asctime)s] [%(levelname)s] [%(name)s]: %(message)s")
        # console_handler.setFormatter(console_formatter)
        # root_logger.addHandler(console_handler)
        
        # è¨˜éŒ„ç¨‹å¼å•Ÿå‹•
        root_logger.info("=== ç¨‹å¼å•Ÿå‹• ===")
        # print("[DEBUG] æ—¥èªŒç³»çµ±å·²åˆå§‹åŒ–")
    else:
        # å­é€²ç¨‹åªè¨­ç½® QueueHandlerï¼Œlog_queue å¿…é ˆç”±ä¸»é€²ç¨‹å‚³å…¥
        root_logger = logging.getLogger("lo2cin4bt")
        root_logger.setLevel(logging.DEBUG)
        root_logger.handlers = []
        if log_queue is not None:
            root_logger.addHandler(QueueHandler(log_queue))
    return listener, log_queue

def standardize_data_for_stats(data):
    """å°‡æ•¸æ“šæ¨™æº–åŒ–ç‚ºçµ±è¨ˆåˆ†æå™¨æœŸæœ›çš„æ ¼å¼"""
    df = data.copy()
    
    # ç¢ºä¿ Time æ¬„ä½å­˜åœ¨ä¸”æ ¼å¼æ­£ç¢º
    if 'Time' not in df.columns:
        if 'time' in df.columns:
            df['Time'] = df['time']
        else:
            raise ValueError("æ•¸æ“šä¸­ç¼ºå°‘ Time æ¬„ä½")
    
    # å°‡æ¬„ä½åç¨±è½‰æ›ç‚ºå°å¯«ï¼ˆé™¤äº† Time å’Œé æ¸¬å› å­ç›¸é—œæ¬„ä½ï¼‰
    # ä¿ç•™é æ¸¬å› å­æ¬„ä½çš„åŸå§‹å¤§å°å¯«
    new_columns = []
    for col in df.columns:
        if col == 'Time':
            new_columns.append('Time')
        elif col.lower() in ['open', 'high', 'low', 'close', 'volume']:
            new_columns.append(col.lower())
        elif col.endswith(('_return', '_logreturn')):
            new_columns.append(col.lower())
        else:
            # ä¿ç•™é æ¸¬å› å­æ¬„ä½çš„åŸå§‹å¤§å°å¯«
            new_columns.append(col)
    
    df.columns = new_columns
    
    # ç¢ºä¿ Time æ¬„ä½ç‚º datetime æ ¼å¼
    df['Time'] = pd.to_datetime(df['Time'])
    
    # å¦‚æœæ²’æœ‰æ”¶ç›Šç‡æ¬„ä½ï¼Œéœ€è¦è¨ˆç®—
    if 'close_return' not in df.columns:
        if 'close' in df.columns:
            # è¨ˆç®—æ”¶ç›Šç‡
            df['close_return'] = df['close'].pct_change()
            df['close_logreturn'] = np.log(df['close'] / df['close'].shift(1))
            df['open_return'] = df['open'].pct_change()
            df['open_logreturn'] = np.log(df['open'] / df['open'].shift(1))
            # è™•ç†ç„¡é™å€¼å’Œ NaN
            for col in ['close_return', 'close_logreturn', 'open_return', 'open_logreturn']:
                df[col] = df[col].replace([np.inf, -np.inf], np.nan).fillna(0)
        else:
            print("[DEBUG] è­¦å‘Šï¼šç¼ºå°‘ close æ¬„ä½ï¼Œç„¡æ³•è¨ˆç®—æ”¶ç›Šç‡")
    
    return df

def select_parquet_file(parquet_dir):
    parquet_files = sorted(glob.glob(os.path.join(parquet_dir, '*.parquet')))
    if not parquet_files:
        print(f"[ä¸»æµç¨‹][ERROR] è³‡æ–™å¤¾ {parquet_dir} ä¸‹æ‰¾ä¸åˆ° parquet æª”æ¡ˆï¼")
        return None
    print("[ä¸»æµç¨‹] å¯é¸æ“‡çš„ parquet æª”æ¡ˆï¼š")
    for i, f in enumerate(parquet_files, 1):
        print(f"  {i}. {os.path.basename(f)}")
    file_input = input("è«‹è¼¸å…¥è¦è®€å–çš„æª”æ¡ˆç·¨è™Ÿï¼ˆé è¨­1ï¼‰ï¼š").strip() or '1'
    try:
        idx = int(file_input) - 1
        assert 0 <= idx < len(parquet_files)
    except Exception:
        print("[ä¸»æµç¨‹][ERROR] è¼¸å…¥ç„¡æ•ˆï¼Œé è¨­é¸æ“‡ç¬¬ä¸€å€‹æª”æ¡ˆã€‚")
        idx = 0
    return parquet_files[idx]

from rich.console import Console
from rich.panel import Panel
console = Console()

def main():
    global listener, log_queue
    
    # è¨­å®šç¬¬ä¸‰æ–¹åº«çš„æ—¥èªŒç´šåˆ¥ï¼Œé¿å… DEBUG è¨Šæ¯
    logging.getLogger('urllib3').setLevel(logging.WARNING)
    logging.getLogger('asyncio').setLevel(logging.WARNING)
    logging.getLogger('requests').setLevel(logging.WARNING)
    
    # åƒ…ä¸»é€²ç¨‹è¨­ç½® loggingï¼Œä¸¦å°‡ log_queue å‚³çµ¦ Base_backtester
    listener, log_queue = setup_logging()
    logger = logging.getLogger("lo2cin4bt")
    
    logger.info("ç¨‹å¼é–‹å§‹åŸ·è¡Œ")

    console.print(
        Panel(
            "[bold #dbac30]ğŸš€ lo2cin4bt[/bold #dbac30]\n[white]The best backtest engine for non-coders and quant beginners (probably).[/white]",
            title="[bold #8f1511]Welcome![/bold #8f1511]",
            border_style="#dbac30",
            padding=(1, 4),
        )
    )
    # ä¸»é¸å–®
    console.print(
        Panel(
            "[bold white]1. å…¨é¢å›æ¸¬ (è¼‰å…¥æ•¸æ“šâ†’çµ±è¨ˆåˆ†æâ†’å›æ¸¬äº¤æ˜“â†’äº¤æ˜“åˆ†æâ†’å¯è¦–åŒ–å¹³å°)\n"
            "2. çµ±è¨ˆåˆ†æ (è¼‰å…¥æ•¸æ“šâ†’çµ±è¨ˆåˆ†æ)\n"
            "3. å›æ¸¬äº¤æ˜“ (è¼‰å…¥æ•¸æ“šâ†’å›æ¸¬äº¤æ˜“â†’äº¤æ˜“åˆ†æâ†’å¯è¦–åŒ–å¹³å°)\n"
            "4. äº¤æ˜“åˆ†æ (åˆ†æç¾æœ‰å›æ¸¬çµæœâ†’ç¸¾æ•ˆåˆ†æâ†’å¯è¦–åŒ–å¹³å°)\n"
            "5. å¯è¦–åŒ–å¹³å° (åƒ…è®€å– metricstracker æ•¸æ“šä¸¦é¡¯ç¤º)[/bold white]",
            title="[bold #8f1511]ğŸ ä¸»é¸å–®[/bold #8f1511]",
            border_style="#dbac30"
        )
    )
    console.print("[bold #dbac30]è«‹é¸æ“‡è¦åŸ·è¡Œçš„åŠŸèƒ½ï¼ˆ1, 2, 3, 4, 5ï¼Œé è¨­1ï¼‰ï¼š[/bold #dbac30]")
    choice = input().strip() or "1"

    try:
        if choice == "1":
            # å…¨é¢å›æ¸¬ï¼Œç›´æ¥å‘¼å« DataImporter è™•ç†æ‰€æœ‰æ•¸æ“šä¾†æºäº’å‹•
            importer = DataImporter()
            data, frequency = importer.load_and_standardize_data()
            if data is None:
                print("[DEBUG] æ•¸æ“šè¼‰å…¥å¤±æ•—ï¼Œç¨‹å¼çµ‚æ­¢")
                logger.error("æ•¸æ“šè¼‰å…¥å¤±æ•—")
                return
            if isinstance(data, str) and data == "__SKIP_STATANALYSER__":
                if choice == "1":
                    print("æœªè¼¸å…¥é æ¸¬å› å­æª”æ¡ˆï¼Œå°‡è·³éçµ±è¨ˆåˆ†æï¼Œåƒ…ä½¿ç”¨åƒ¹æ ¼æ•¸æ“šã€‚")
                data = importer.data  # é€™è£¡ç”¨ DataFrame
                frequency = importer.frequency  # é€™è£¡ä¹Ÿè¦è¨­æ­£ç¢º
                backtester = BaseBacktester(data, frequency, logger)
                backtester.run()
                analyze_backtest = 'y'
                if analyze_backtest == 'y':
                    # çµ±ä¸€é€²å…¥å¤šé¸ parquet åˆ†æäº’å‹•
                    from metricstracker.DataImporter_metricstracker import list_parquet_files, show_parquet_files, select_files
                    import pandas as pd
                    directory = os.path.join(os.path.dirname(__file__), 'records', 'backtester')
                    directory = os.path.abspath(directory)
                    files = list_parquet_files(directory)
                    if not files:
                        print(f"âŒ æ‰¾ä¸åˆ°ä»»ä½•parquetæª”æ¡ˆæ–¼ {directory}")
                        return
                    show_parquet_files(files)
                    user_input = input("è«‹è¼¸å…¥è¦åˆ†æçš„æª”æ¡ˆç·¨è™Ÿï¼ˆå¯ç”¨é€—è™Ÿåˆ†éš”å¤šé¸ï¼Œæˆ–è¼¸å…¥al/allå…¨é¸ï¼‰ï¼š").strip() or '1'
                    selected_files = select_files(files, user_input)
                    if not selected_files:
                        print("æœªé¸æ“‡ä»»ä½•æª”æ¡ˆï¼Œè¿”å›ä¸»é¸å–®ã€‚")
                        return
                    print("\n=== å·²é¸æ“‡æª”æ¡ˆ ===")
                    for f in selected_files:
                        print(f)
                    for orig_parquet_path in selected_files:
                        print(f"\nå·²é¸æ“‡æª”æ¡ˆ: {orig_parquet_path}")
                        df = pd.read_parquet(orig_parquet_path)
                        time_unit = input("è«‹è¼¸å…¥å¹´åŒ–æ™‚é–“å–®ä½ï¼ˆå¦‚æ—¥ç·šè‚¡ç¥¨252ï¼Œæ—¥ç·šå¹£365ï¼Œé è¨­ç‚º252ï¼‰ï¼š").strip()
                        if time_unit == "":
                            time_unit = 252
                        else:
                            time_unit = int(time_unit)
                        risk_free_rate = input("è«‹è¼¸å…¥ç„¡é¢¨éšªåˆ©ç‡ï¼ˆ%ï¼‰ï¼ˆè¼¸å…¥nä»£è¡¨n% ï¼Œé è¨­ç‚º2ï¼‰ï¼š").strip()
                        if risk_free_rate == "":
                            risk_free_rate = 2.0 / 100
                        else:
                            risk_free_rate = float(risk_free_rate) / 100
                        MetricsExporter.export(df, orig_parquet_path, time_unit, risk_free_rate)
                run_plotter = input("æ˜¯å¦å•Ÿå‹•å¯è¦–åŒ–å¹³å°ï¼Ÿ(y/nï¼Œé è¨­y)ï¼š").strip().lower() or 'y'
                if run_plotter == 'y':
                    try:
                        from plotter.Base_plotter import BasePlotter
                        plotter = BasePlotter(logger=logger)
                        plotter.run(host='127.0.0.1', port=8050, debug=False)
                    except Exception as e:
                        print(f"âŒ å¯è¦–åŒ–å¹³å°å•Ÿå‹•å¤±æ•—: {e}")
                return
            # åªæœ‰åœ¨ä¸æ˜¯ __SKIP_STATANALYSER__ æ™‚æ‰å‘¼å« select_predictor_factor
            logger.info(f"æ•¸æ“šè¼‰å…¥æˆåŠŸï¼Œå½¢ç‹€ï¼š{data.shape}ï¼Œé »ç‡ï¼š{frequency}")
            predictor_col = select_predictor_factor(data)
            predictor_loader = PredictorLoader(data)
            data, diff_cols, used_series = predictor_loader.process_difference(data, predictor_col)
            logger.info(f"å·®åˆ†è™•ç†å®Œæˆï¼Œå·®åˆ†æ¬„ä½ï¼š{diff_cols}")
            # çµ±è¨ˆåˆ†æ
            run_stats = 'y'
            if run_stats == 'y':
                selected_col = select_predictor_factor(data, default_factor=diff_cols[0] if diff_cols else None)
                used_series = data[selected_col]
                stats_data = standardize_data_for_stats(data)
                updated_data = stats_data.copy()
                updated_data[predictor_col] = used_series
                freq = input("\nè«‹è¼¸å…¥æ•¸æ“šé »ç‡ä»¥è¨ˆç®—è‡ªç›¸é—œæ€§ï¼ˆD=æ—¥ï¼ŒH=å°æ™‚ï¼ŒT=åˆ†é˜ï¼Œé è¨­Dï¼‰ï¼š").strip().upper() or 'D'
                if freq not in ['D', 'H', 'T']:
                    print("è¼¸å…¥éŒ¯èª¤ï¼Œè‡ªå‹•è¨­ç‚ºDï¼ˆæ—¥ï¼‰")
                    freq = 'D'
                analyzers = [
                    CorrelationTest(updated_data, predictor_col, "close_return"),
                    StationarityTest(updated_data, predictor_col, "close_return"),
                    AutocorrelationTest(updated_data, predictor_col, "close_return", freq=freq),
                    DistributionTest(updated_data, predictor_col, "close_return"),
                    SeasonalAnalysis(updated_data, predictor_col, "close_return"),
                ]
                results = {}
                for analyzer in analyzers:
                    test_name = f"{analyzer.__class__.__name__}_{analyzer.predictor_col}"
                    try:
                        analyzer.analyze()
                        results[test_name] = analyzer.results if hasattr(analyzer, 'results') else None
                    except Exception as e:
                        print(f"[DEBUG] Error in {test_name}: {e}")
                        logger.error(f"çµ±è¨ˆåˆ†æå¤±æ•— {test_name}: {e}")
                        results[test_name] = {"error": str(e)}
                reporter = ReportGenerator()
                reporter.save_report(results)
                reporter.save_data(updated_data, format="csv")
                print("çµ±è¨ˆåˆ†æå®Œæˆ")
                logger.info("çµ±è¨ˆåˆ†æå®Œæˆ")
            # å›æ¸¬
            run_backtest = 'y'
            if run_backtest == 'y':
                print("é–‹å§‹å›æ¸¬...")
                backtester = BaseBacktester(data, frequency, logger)
                backtester.run()
                print("å›æ¸¬å®Œæˆ")
                logger.info("å›æ¸¬å®Œæˆ")
            # äº¤æ˜“åˆ†æ
            analyze_backtest = 'y'
            if analyze_backtest == 'y':
                # çµ±ä¸€é€²å…¥å¤šé¸ parquet åˆ†æäº’å‹•
                from metricstracker.DataImporter_metricstracker import list_parquet_files, show_parquet_files, select_files
                import pandas as pd
                directory = os.path.join(os.path.dirname(__file__), 'records', 'backtester')
                directory = os.path.abspath(directory)
                files = list_parquet_files(directory)
                if not files:
                    print(f"âŒ æ‰¾ä¸åˆ°ä»»ä½•parquetæª”æ¡ˆæ–¼ {directory}")
                    return
                show_parquet_files(files)
                user_input = input("è«‹è¼¸å…¥è¦åˆ†æçš„æª”æ¡ˆç·¨è™Ÿï¼ˆå¯ç”¨é€—è™Ÿåˆ†éš”å¤šé¸ï¼Œæˆ–è¼¸å…¥al/allå…¨é¸ï¼‰ï¼š").strip() or '1'
                selected_files = select_files(files, user_input)
                if not selected_files:
                    print("æœªé¸æ“‡ä»»ä½•æª”æ¡ˆï¼Œè¿”å›ä¸»é¸å–®ã€‚")
                    return
                print("\n=== å·²é¸æ“‡æª”æ¡ˆ ===")
                for f in selected_files:
                    print(f)
                for orig_parquet_path in selected_files:
                    print(f"\nå·²é¸æ“‡æª”æ¡ˆ: {orig_parquet_path}")
                    df = pd.read_parquet(orig_parquet_path)
                    time_unit = input("è«‹è¼¸å…¥å¹´åŒ–æ™‚é–“å–®ä½ï¼ˆå¦‚æ—¥ç·šè‚¡ç¥¨252ï¼Œæ—¥ç·šå¹£365ï¼Œé è¨­ç‚º252ï¼‰ï¼š").strip()
                    if time_unit == "":
                        time_unit = 252
                    else:
                        time_unit = int(time_unit)
                    risk_free_rate = input("è«‹è¼¸å…¥ç„¡é¢¨éšªåˆ©ç‡ï¼ˆ%ï¼‰ï¼ˆè¼¸å…¥nä»£è¡¨n% ï¼Œé è¨­ç‚º2ï¼‰ï¼š").strip()
                    if risk_free_rate == "":
                        risk_free_rate = 2.0 / 100
                    else:
                        risk_free_rate = float(risk_free_rate) / 100
                    MetricsExporter.export(df, orig_parquet_path, time_unit, risk_free_rate)
                run_plotter = input("æ˜¯å¦å•Ÿå‹•å¯è¦–åŒ–å¹³å°ï¼Ÿ(y/nï¼Œé è¨­y)ï¼š").strip().lower() or 'y'
                if run_plotter == 'y':
                    try:
                        from plotter.Base_plotter import BasePlotter
                        plotter = BasePlotter(logger=logger)
                        plotter.run(host='127.0.0.1', port=8050, debug=False)
                    except Exception as e:
                        print(f"âŒ å¯è¦–åŒ–å¹³å°å•Ÿå‹•å¤±æ•—: {e}")
        elif choice == "2":
            # çµ±è¨ˆåˆ†æ
            logger.info("[ä¸»é¸å–®] çµ±è¨ˆåˆ†æ")
            importer = DataImporter()
            data, frequency = importer.load_and_standardize_data()
            if data is None:
                print("[DEBUG] æ•¸æ“šè¼‰å…¥å¤±æ•—ï¼Œç¨‹å¼çµ‚æ­¢")
                logger.error("æ•¸æ“šè¼‰å…¥å¤±æ•—")
                return
            if isinstance(data, str) and data == "__SKIP_STATANALYSER__":
                return
            logger.info(f"æ•¸æ“šè¼‰å…¥æˆåŠŸï¼Œå½¢ç‹€ï¼š{data.shape}ï¼Œé »ç‡ï¼š{frequency}")
            predictor_col = select_predictor_factor(data)
            predictor_loader = PredictorLoader(data)
            data, diff_cols, used_series = predictor_loader.process_difference(data, predictor_col)
            logger.info(f"å·®åˆ†è™•ç†å®Œæˆï¼Œå·®åˆ†æ¬„ä½ï¼š{diff_cols}")
            selected_col = select_predictor_factor(data, default_factor=diff_cols[0] if diff_cols else None)
            used_series = data[selected_col]
            stats_data = standardize_data_for_stats(data)
            updated_data = stats_data.copy()
            updated_data[predictor_col] = used_series
            freq = input("\nè«‹è¼¸å…¥æ•¸æ“šé »ç‡ä»¥è¨ˆç®—è‡ªç›¸é—œæ€§ï¼ˆD=æ—¥ï¼ŒH=å°æ™‚ï¼ŒT=åˆ†é˜ï¼Œé è¨­Dï¼‰ï¼š").strip().upper() or 'D'
            if freq not in ['D', 'H', 'T']:
                print("è¼¸å…¥éŒ¯èª¤ï¼Œè‡ªå‹•è¨­ç‚ºDï¼ˆæ—¥ï¼‰")
                freq = 'D'
            analyzers = [
                CorrelationTest(updated_data, predictor_col, "close_return"),
                StationarityTest(updated_data, predictor_col, "close_return"),
                AutocorrelationTest(updated_data, predictor_col, "close_return", freq=freq),
                DistributionTest(updated_data, predictor_col, "close_return"),
                SeasonalAnalysis(updated_data, predictor_col, "close_return"),
            ]
            results = {}
            for analyzer in analyzers:
                test_name = f"{analyzer.__class__.__name__}_{analyzer.predictor_col}"
                try:
                    analyzer.analyze()
                    results[test_name] = analyzer.results if hasattr(analyzer, 'results') else None
                except Exception as e:
                    print(f"[DEBUG] Error in {test_name}: {e}")
                    logger.error(f"çµ±è¨ˆåˆ†æå¤±æ•— {test_name}: {e}")
                    results[test_name] = {"error": str(e)}
            reporter = ReportGenerator()
            reporter.save_report(results)
            reporter.save_data(updated_data, format="csv")
            print("çµ±è¨ˆåˆ†æå®Œæˆ")
            logger.info("çµ±è¨ˆåˆ†æå®Œæˆ")
        elif choice == "3":
            # å›æ¸¬äº¤æ˜“
            logger.info("[ä¸»é¸å–®] å›æ¸¬äº¤æ˜“")
            importer = DataImporter()
            data, frequency = importer.load_and_standardize_data()
            if data is None:
                print("æ•¸æ“šè¼‰å…¥å¤±æ•—ï¼Œç¨‹å¼çµ‚æ­¢")
                logger.error("æ•¸æ“šè¼‰å…¥å¤±æ•—")
                return
            if isinstance(data, str) and data == "__SKIP_STATANALYSER__":
                backtester = BaseBacktester(importer.data, frequency, logger)
                backtester.run()
                print("å›æ¸¬å®Œæˆ")
                logger.info("å›æ¸¬å®Œæˆ")
                # çµ±ä¸€é€²å…¥å¤šé¸ parquet åˆ†æäº’å‹•
                from metricstracker.DataImporter_metricstracker import list_parquet_files, show_parquet_files, select_files
                import pandas as pd
                directory = os.path.join(os.path.dirname(__file__), 'records', 'backtester')
                directory = os.path.abspath(directory)
                files = list_parquet_files(directory)
                if not files:
                    print(f"âŒ æ‰¾ä¸åˆ°ä»»ä½•parquetæª”æ¡ˆæ–¼ {directory}")
                    return
                show_parquet_files(files)
                user_input = input("è«‹è¼¸å…¥è¦åˆ†æçš„æª”æ¡ˆç·¨è™Ÿï¼ˆå¯ç”¨é€—è™Ÿåˆ†éš”å¤šé¸ï¼Œæˆ–è¼¸å…¥al/allå…¨é¸ï¼‰ï¼š").strip() or '1'
                selected_files = select_files(files, user_input)
                if not selected_files:
                    print("æœªé¸æ“‡ä»»ä½•æª”æ¡ˆï¼Œè¿”å›ä¸»é¸å–®ã€‚")
                    return
                print("\n=== å·²é¸æ“‡æª”æ¡ˆ ===")
                for f in selected_files:
                    print(f)
                for orig_parquet_path in selected_files:
                    print(f"\nå·²é¸æ“‡æª”æ¡ˆ: {orig_parquet_path}")
                    df = pd.read_parquet(orig_parquet_path)
                    time_unit = input("è«‹è¼¸å…¥å¹´åŒ–æ™‚é–“å–®ä½ï¼ˆå¦‚æ—¥ç·šè‚¡ç¥¨252ï¼Œæ—¥ç·šå¹£365ï¼Œé è¨­ç‚º252ï¼‰ï¼š").strip()
                    if time_unit == "":
                        time_unit = 252
                    else:
                        time_unit = int(time_unit)
                    risk_free_rate = input("è«‹è¼¸å…¥ç„¡é¢¨éšªåˆ©ç‡ï¼ˆ%ï¼‰ï¼ˆè¼¸å…¥nä»£è¡¨n% ï¼Œé è¨­ç‚º2ï¼‰ï¼š").strip()
                    if risk_free_rate == "":
                        risk_free_rate = 2.0 / 100
                    else:
                        risk_free_rate = float(risk_free_rate) / 100
                    MetricsExporter.export(df, orig_parquet_path, time_unit, risk_free_rate)
                run_plotter = input("æ˜¯å¦å•Ÿå‹•å¯è¦–åŒ–å¹³å°ï¼Ÿ(y/nï¼Œé è¨­y)ï¼š").strip().lower() or 'y'
                if run_plotter == 'y':
                    try:
                        from plotter.Base_plotter import BasePlotter
                        plotter = BasePlotter(logger=logger)
                        plotter.run(host='127.0.0.1', port=8050, debug=False)
                    except Exception as e:
                        print(f"âŒ å¯è¦–åŒ–å¹³å°å•Ÿå‹•å¤±æ•—: {e}")
                return
            logger.info(f"æ•¸æ“šè¼‰å…¥æˆåŠŸï¼Œå½¢ç‹€ï¼š{data.shape}ï¼Œé »ç‡ï¼š{frequency}")
            predictor_col = select_predictor_factor(data)
            predictor_loader = PredictorLoader(data)
            data, diff_cols, used_series = predictor_loader.process_difference(data, predictor_col)
            logger.info(f"å·®åˆ†è™•ç†å®Œæˆï¼Œå·®åˆ†æ¬„ä½ï¼š{diff_cols}")
            # å›æ¸¬
            print("é–‹å§‹å›æ¸¬...")
            backtester = BaseBacktester(data, frequency, logger)
            backtester.run()
            print("å›æ¸¬å®Œæˆ")
            logger.info("å›æ¸¬å®Œæˆ")
            # äº¤æ˜“åˆ†æ
            # çµ±ä¸€é€²å…¥å¤šé¸ parquet åˆ†æäº’å‹•
            from metricstracker.DataImporter_metricstracker import list_parquet_files, show_parquet_files, select_files
            import pandas as pd
            directory = os.path.join(os.path.dirname(__file__), 'records', 'backtester')
            directory = os.path.abspath(directory)
            files = list_parquet_files(directory)
            if not files:
                print(f"âŒ æ‰¾ä¸åˆ°ä»»ä½•parquetæª”æ¡ˆæ–¼ {directory}")
                return
            show_parquet_files(files)
            user_input = input("è«‹è¼¸å…¥è¦åˆ†æçš„æª”æ¡ˆç·¨è™Ÿï¼ˆå¯ç”¨é€—è™Ÿåˆ†éš”å¤šé¸ï¼Œæˆ–è¼¸å…¥al/allå…¨é¸ï¼‰ï¼š").strip() or '1'
            selected_files = select_files(files, user_input)
            if not selected_files:
                print("æœªé¸æ“‡ä»»ä½•æª”æ¡ˆï¼Œè¿”å›ä¸»é¸å–®ã€‚")
                return
            print("\n=== å·²é¸æ“‡æª”æ¡ˆ ===")
            for f in selected_files:
                print(f)
            for orig_parquet_path in selected_files:
                print(f"\nå·²é¸æ“‡æª”æ¡ˆ: {orig_parquet_path}")
                df = pd.read_parquet(orig_parquet_path)
                time_unit = input("è«‹è¼¸å…¥å¹´åŒ–æ™‚é–“å–®ä½ï¼ˆå¦‚æ—¥ç·šè‚¡ç¥¨252ï¼Œæ—¥ç·šå¹£365ï¼Œé è¨­ç‚º252ï¼‰ï¼š").strip()
                if time_unit == "":
                    time_unit = 252
                else:
                    time_unit = int(time_unit)
                risk_free_rate = input("è«‹è¼¸å…¥ç„¡é¢¨éšªåˆ©ç‡ï¼ˆ%ï¼‰ï¼ˆè¼¸å…¥nä»£è¡¨n% ï¼Œé è¨­ç‚º2ï¼‰ï¼š").strip()
                if risk_free_rate == "":
                    risk_free_rate = 2.0 / 100
                else:
                    risk_free_rate = float(risk_free_rate) / 100
                MetricsExporter.export(df, orig_parquet_path, time_unit, risk_free_rate)
            run_plotter = input("æ˜¯å¦å•Ÿå‹•å¯è¦–åŒ–å¹³å°ï¼Ÿ(y/nï¼Œé è¨­y)ï¼š").strip().lower() or 'y'
            if run_plotter == 'y':
                try:
                    from plotter.Base_plotter import BasePlotter
                    plotter = BasePlotter(logger=logger)
                    plotter.run(host='127.0.0.1', port=8050, debug=False)
                except Exception as e:
                    print(f"âŒ å¯è¦–åŒ–å¹³å°å•Ÿå‹•å¤±æ•—: {e}")
        elif choice == "4":
            # ä¸»é¸å–®4æµç¨‹ä¸è®Šï¼Œç›´æ¥ç”¨å¤šé¸ parquet äº’å‹•
            print("[DEBUG] é¸æ“‡å¯è¦–åŒ–å¹³å°")
            logger.info("[ä¸»é¸å–®] å¯è¦–åŒ–å¹³å°")
            try:
                from plotter.Base_plotter import BasePlotter
                plotter = BasePlotter(logger=logger)
                plotter.run(host='127.0.0.1', port=8050, debug=False)
            except ImportError as e:
                print(f"âŒ å°å…¥ plotter æ¨¡çµ„å¤±æ•—: {e}")
                logger.error(f"å°å…¥ plotter æ¨¡çµ„å¤±æ•—: {e}")
                print("è«‹ç¢ºä¿å·²å®‰è£æ‰€éœ€çš„ä¾è³´å¥—ä»¶ï¼š")
                print("pip install dash dash-bootstrap-components plotly")
            except Exception as e:
                print(f"âŒ å¯è¦–åŒ–å¹³å°å•Ÿå‹•å¤±æ•—: {e}")
                logger.error(f"å¯è¦–åŒ–å¹³å°å•Ÿå‹•å¤±æ•—: {e}")
        else:
            print("ç„¡æ•ˆé¸æ“‡ï¼Œè«‹é‡æ–°å•Ÿå‹•ç¨‹å¼ã€‚")
            logger.error("ç„¡æ•ˆé¸æ“‡ï¼Œç¨‹å¼çµ‚æ­¢")
    except Exception as e:
        print(f"[DEBUG] ç¨‹å¼åŸ·è¡Œéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        logger.error(f"ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤ï¼š{e}")
        import traceback
        traceback.print_exc()
    finally:
        if listener:
            listener.stop()
            print("[DEBUG] æ—¥èªŒç³»çµ±å·²åœæ­¢")
            logger.info("ç¨‹å¼çµæŸ")

# ç§»é™¤ _run_trade_analysis å‡½æ•¸

if __name__ == "__main__":
    main()