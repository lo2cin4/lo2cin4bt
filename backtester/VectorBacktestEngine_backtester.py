"""
VectorBacktestEngine_backtester.py

ã€åŠŸèƒ½èªªæ˜ã€‘
------------------------------------------------------------
æœ¬æ¨¡çµ„ç‚º Lo2cin4BT å›æ¸¬æ¡†æ¶çš„ã€Œå‘é‡åŒ–å›æ¸¬å¼•æ“ã€ï¼Œä½¿ç”¨çŸ©é™£é‹ç®—æ›¿ä»£é€å€‹ä»»å‹™è™•ç†ï¼Œ
å¤§å¹…æå‡å›æ¸¬é€Ÿåº¦ã€‚å®Œå…¨å…¼å®¹åŸæœ‰ BacktestEngine æ¥å£ï¼Œæ”¯æ´å¤šç­–ç•¥ä¸¦è¡Œè™•ç†ã€‚
- å‘é‡åŒ–æŒ‡æ¨™è¨ˆç®—ï¼šæ‰¹é‡è¨ˆç®—æ‰€æœ‰åƒæ•¸çµ„åˆçš„æŒ‡æ¨™
- çŸ©é™£åŒ–ä¿¡è™Ÿç”Ÿæˆï¼šä¸€æ¬¡æ€§è™•ç†å¤šçµ„ç­–ç•¥ä¿¡è™Ÿ
- å‘é‡åŒ–äº¤æ˜“æ¨¡æ“¬ï¼šä¸¦è¡Œæ¨¡æ“¬å¤šçµ„äº¤æ˜“ç­–ç•¥
- æ™ºèƒ½è¨˜æ†¶é«”ç®¡ç†ï¼šåˆ†å¡Šè™•ç†é¿å…è¨˜æ†¶é«”æº¢å‡º
- é€²åº¦ç›£æ§èˆ‡æ€§èƒ½å„ªåŒ–ï¼šå¯¦æ™‚é¡¯ç¤ºè™•ç†é€²åº¦èˆ‡ç³»çµ±è³‡æºä½¿ç”¨

ã€æµç¨‹èˆ‡æ•¸æ“šæµã€‘
------------------------------------------------------------
- ç”± BaseBacktester èª¿ç”¨ï¼Œæ¥æ”¶ç›¸åŒçš„åƒæ•¸å’Œæ•¸æ“š
- ä½¿ç”¨çŸ©é™£é‹ç®—ä¸€æ¬¡æ€§è™•ç†æ‰€æœ‰åƒæ•¸çµ„åˆ
- ç”¢ç”Ÿèˆ‡åŸæœ‰å¼•æ“ç›¸åŒæ ¼å¼çš„çµæœ

```mermaid
flowchart TD
    A[BaseBacktester] -->|èª¿ç”¨| B[VectorBacktestEngine]
    B -->|æ‰¹é‡åƒæ•¸çµ„åˆ| C[generate_parameter_combinations]
    B -->|å‘é‡åŒ–ä¿¡è™Ÿç”Ÿæˆ| D[_generate_all_signals_vectorized]
    B -->|å‘é‡åŒ–äº¤æ˜“æ¨¡æ“¬| E[_simulate_all_trades_vectorized]
    B -->|çµæœç”Ÿæˆ| F[_generate_all_results_vectorized]
    F -->|è¿”å›çµæœ| G[BaseBacktester]
```

ã€å‘é‡åŒ–å„ªåŒ–ã€‘
------------------------------------------------------------
- æŒ‡æ¨™è¨ˆç®—ï¼šæ‰¹é‡è¨ˆç®—æ‰€æœ‰åƒæ•¸çµ„åˆçš„æŒ‡æ¨™ï¼Œä½¿ç”¨ Numba JIT ç·¨è­¯åŠ é€Ÿ
- ä¿¡è™Ÿç”Ÿæˆï¼šçŸ©é™£åŒ–ä¿¡è™Ÿç”Ÿæˆé‚è¼¯ï¼Œæ”¯æ´å¤šæŒ‡æ¨™çµ„åˆ
- äº¤æ˜“æ¨¡æ“¬ï¼šå‘é‡åŒ–äº¤æ˜“é‚è¼¯ï¼Œä¸¦è¡Œè™•ç†å¤šçµ„ç­–ç•¥
- è¨˜æ†¶é«”ç®¡ç†ï¼šåˆ†å¡Šè™•ç†é¿å…è¨˜æ†¶é«”æº¢å‡ºï¼Œæ™ºèƒ½åƒåœ¾å›æ”¶
- ä¸¦è¡Œè™•ç†ï¼šæ”¯æ´å¤šé€²ç¨‹ä¸¦è¡Œè¨ˆç®—ï¼Œå……åˆ†åˆ©ç”¨å¤šæ ¸ CPU

ã€ç¶­è­·èˆ‡æ“´å……é‡é»ã€‘
------------------------------------------------------------
- ä¿æŒèˆ‡åŸæœ‰ BacktestEngine å®Œå…¨ç›¸åŒçš„æ¥å£
- ç¢ºä¿çµæœæ ¼å¼å’Œå…§å®¹å®Œå…¨ä¸€è‡´
- å‘é‡åŒ–é‚è¼¯éœ€è¦èˆ‡åŸæœ‰é‚è¼¯ä¿æŒä¸€è‡´
- è¨˜æ†¶é«”ä½¿ç”¨éœ€è¦æ§åˆ¶åœ¨å®‰å…¨ç¯„åœå…§
- ä¸¦è¡Œè™•ç†åƒæ•¸éœ€è¦æ ¹æ“šç³»çµ±é…ç½®å‹•æ…‹èª¿æ•´
- æ–°å¢æŒ‡æ¨™æ™‚éœ€è¦åŒæ­¥æ›´æ–°å‘é‡åŒ–è¨ˆç®—é‚è¼¯

ã€å¸¸è¦‹æ˜“éŒ¯é»ã€‘
------------------------------------------------------------
- çŸ©é™£ç¶­åº¦ä¸åŒ¹é…å°è‡´è¨ˆç®—éŒ¯èª¤
- è¨˜æ†¶é«”ä½¿ç”¨éå¤§å°è‡´ç³»çµ±å´©æ½°
- çµæœæ ¼å¼ä¸ä¸€è‡´å½±éŸ¿ä¸‹æ¸¸è™•ç†
- ä¸¦è¡Œè™•ç†åƒæ•¸è¨­ç½®ä¸ç•¶å½±éŸ¿æ€§èƒ½
- å‘é‡åŒ–é‚è¼¯èˆ‡åŸæœ‰é‚è¼¯ä¸ä¸€è‡´

ã€éŒ¯èª¤è™•ç†ã€‘
------------------------------------------------------------
- è¨˜æ†¶é«”ä¸è¶³æ™‚è‡ªå‹•èª¿æ•´æ‰¹æ¬¡å¤§å°
- ä¸¦è¡Œè™•ç†å¤±æ•—æ™‚è‡ªå‹•é™ç´šç‚ºä¸²è¡Œè™•ç†
- è¨ˆç®—éŒ¯èª¤æ™‚æä¾›è©³ç´°è¨ºæ–·ä¿¡æ¯
- ç³»çµ±è³‡æºä¸è¶³æ™‚æä¾›å„ªåŒ–å»ºè­°

ã€ç¯„ä¾‹ã€‘
------------------------------------------------------------
- åŸ·è¡Œå‘é‡åŒ–å›æ¸¬ï¼šVectorBacktestEngine(data, frequency).run_backtests(config)
- æ‰¹é‡åƒæ•¸çµ„åˆï¼šgenerate_parameter_combinations(config)
- å‘é‡åŒ–ä¿¡è™Ÿç”Ÿæˆï¼š_generate_all_signals_vectorized(all_tasks, condition_pairs)

ã€èˆ‡å…¶ä»–æ¨¡çµ„çš„é—œè¯ã€‘
------------------------------------------------------------
- å®Œå…¨æ›¿ä»£ BacktestEngineï¼Œä½¿ç”¨ç›¸åŒæ¥å£
- èª¿ç”¨ç›¸åŒçš„ Indicatorsã€TradeSimulator ç­‰æ¨¡çµ„
- ä¾è³´ SpecMonitor é€²è¡Œç³»çµ±è³‡æºç›£æ§
- èˆ‡ TradeRecordExporter é…åˆå°å‡ºçµæœ

ã€ç‰ˆæœ¬èˆ‡è®Šæ›´è¨˜éŒ„ã€‘
------------------------------------------------------------
- v1.0: åˆå§‹ç‰ˆæœ¬ï¼ŒåŸºæœ¬å‘é‡åŒ–åŠŸèƒ½
- v1.1: æ–°å¢ Numba JIT ç·¨è­¯å„ªåŒ–
- v1.2: å®Œå–„è¨˜æ†¶é«”ç®¡ç†èˆ‡åˆ†å¡Šè™•ç†
- v2.0: æ–°å¢å¤šé€²ç¨‹ä¸¦è¡Œè™•ç†
- v2.1: æ•´åˆé€²åº¦ç›£æ§èˆ‡æ€§èƒ½å„ªåŒ–
- v2.2: å®Œå–„éŒ¯èª¤è™•ç†èˆ‡ç³»çµ±é©é…

ã€åƒè€ƒã€‘
------------------------------------------------------------
- Numba å®˜æ–¹æ–‡æª”ï¼šhttps://numba.pydata.org/
- å‘é‡åŒ–è¨ˆç®—æœ€ä½³å¯¦è¸
- è¨˜æ†¶é«”ç®¡ç†èˆ‡æ€§èƒ½å„ªåŒ–æŒ‡å—
- ä¸¦è¡Œè™•ç†èˆ‡å¤šé€²ç¨‹ç·¨ç¨‹
"""

import gc
import itertools
import logging
import time
import uuid
from concurrent.futures import ProcessPoolExecutor
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
from rich.console import Console
from rich.panel import Panel
from rich.text import Text

from .BollingerBand_Indicator_backtester import BollingerBandIndicator
from .HL_Indicator_backtester import HLIndicator
from .Indicators_backtester import IndicatorsBacktester
from .SpecMonitor_backtester import SpecMonitor
from .TradeSimulator_backtester import (
    TradeSimulator_backtester,
    _vectorized_trade_simulation_njit,
)
from .VALUE_Indicator_backtester import VALUEIndicator

# å˜—è©¦å°å…¥ Numba
try:
    from numba import njit

    NUMBA_AVAILABLE = True
except ImportError:
    NUMBA_AVAILABLE = False


class ProgressMonitor:
    """ç¨ç«‹çš„é€²åº¦ç›£æ§å™¨ - ç°¡åŒ–ç‰ˆæœ¬ï¼Œå°ˆé–€é‡å°æ‰¹æ¬¡è™•ç†å„ªåŒ–"""

    def __init__(self, progress: Any, task: Any, total_backtests: int, total_batches: int):  # pylint: disable=unused-argument
        self.progress = progress
        self.task = task
        self.total_backtests = total_backtests
        self.total_batches = total_batches
        self.completed_batches = 0
        self.completed_tasks = 0
        self.batch_sizes: List[int] = []  # è¨˜éŒ„æ¯å€‹æ‰¹æ¬¡çš„å¤§å°
        self.start_time = time.time()

    def set_batch_sizes(self, batch_sizes: List[int]) -> None:  # pylint: disable=unused-argument
        """è¨­ç½®æ¯å€‹æ‰¹æ¬¡çš„å¤§å°"""
        self.batch_sizes = batch_sizes

    def batch_completed(
        self, batch_idx: Optional[int] = None, completed_tasks_in_batch: Optional[int] = None
    ) -> None:  # pylint: disable=unused-argument
        """é€šçŸ¥ä¸€å€‹æ‰¹æ¬¡å®Œæˆ"""
        self.completed_batches += 1
        if completed_tasks_in_batch is not None:
            self.completed_tasks += completed_tasks_in_batch
        elif batch_idx is not None and batch_idx < len(self.batch_sizes):
            self.completed_tasks += self.batch_sizes[batch_idx]

        # ç«‹å³æ›´æ–°é€²åº¦æ¢
        if self.progress is not None and self.task is not None:
            self.progress.update(self.task, completed=self.completed_tasks)

            # æ›´æ–°æè¿°
            description = (
                f"ğŸ“Š [3/3] ç”Ÿæˆå›æ¸¬çµæœ ({self.completed_batches}/{self.total_batches} æ‰¹æ¬¡, "
                f"{self.completed_tasks}/{self.total_backtests} ä»»å‹™)"
            )
            self.progress.update(self.task, description=description)

    def finish(self) -> None:
        """å®Œæˆé€²åº¦ç›£æ§"""
        if self.progress is not None and self.task is not None:
            self.progress.update(self.task, completed=self.total_backtests)
            self.progress.update(
                self.task,
                description=(
                    f"ğŸ“Š [3/3] ç”Ÿæˆå›æ¸¬çµæœ ({self.total_batches}/{self.total_batches} æ‰¹æ¬¡, "
                    f"{self.total_backtests}/{self.total_backtests} ä»»å‹™)"
                ),
            )


# å‘é‡åŒ– Numba å‡½æ•¸
if NUMBA_AVAILABLE:

    @njit(fastmath=True, cache=True)
    def _vectorized_combine_signals_njit(signals_matrix: np.ndarray, is_exit_signals: bool) -> np.ndarray:
        """
        å‘é‡åŒ–ä¿¡è™Ÿåˆä½µ
        signals_matrix: [æ™‚é–“é», ç­–ç•¥æ•¸, æŒ‡æ¨™æ•¸]
        is_exit_signals: æ˜¯å¦ç‚ºå¹³å€‰ä¿¡è™Ÿ
        è¿”å›: [æ™‚é–“é», ç­–ç•¥æ•¸]
        """
        n_time, n_strategies, n_indicators = signals_matrix.shape
        result = np.zeros((n_time, n_strategies))

        for t in range(n_time):
            for s in range(n_strategies):
                # æª¢æŸ¥æ‰€æœ‰æŒ‡æ¨™æ˜¯å¦éƒ½ç‚º1æˆ–-1
                all_long = True
                all_short = True

                for i in range(n_indicators):
                    if signals_matrix[t, s, i] != 1.0:
                        all_long = False
                    if signals_matrix[t, s, i] != -1.0:
                        all_short = False

                if is_exit_signals:
                    # å¹³å€‰ä¿¡è™Ÿï¼š1 = å¹³å¤šï¼Œ-1 = å¹³ç©º
                    if all_long:  # æ‰€æœ‰ä¿¡è™Ÿéƒ½æ˜¯1
                        result[t, s] = 1.0  # å¹³å¤š
                    elif all_short:  # æ‰€æœ‰ä¿¡è™Ÿéƒ½æ˜¯-1
                        result[t, s] = -1.0  # å¹³ç©º
                else:
                    # é–‹å€‰ä¿¡è™Ÿï¼š1 = é–‹å¤šï¼Œ-1 = é–‹ç©º
                    if all_long:  # æ‰€æœ‰ä¿¡è™Ÿéƒ½æ˜¯1
                        result[t, s] = 1.0  # é–‹å¤š
                    elif all_short:  # æ‰€æœ‰ä¿¡è™Ÿéƒ½æ˜¯-1
                        result[t, s] = -1.0  # é–‹ç©º

        return result

    # å‘é‡åŒ–äº¤æ˜“æ¨¡æ“¬å‡½æ•¸å·²ç§»æ¤åˆ° TradeSimulator ä¸­


class VectorBacktestEngine:
    """çœŸæ­£çš„å‘é‡åŒ–å›æ¸¬å¼•æ“ï¼Œå®Œå…¨å…¼å®¹åŸæœ‰ BacktestEngine æ¥å£"""

    def __init__(self, data: pd.DataFrame, frequency: str, logger: Optional[logging.Logger] = None, symbol: Optional[str] = None):
        self.data = data
        self.frequency = frequency
        self.symbol = symbol or "X"
        self.logger = logger or logging.getLogger("VectorBacktestEngine")
        self.indicators = IndicatorsBacktester(logger=self.logger)
        self.results: List[Dict[str, Any]] = []

        # å‘é‡åŒ–é…ç½®
        self.max_memory_mb = 1000  # æœ€å¤§è¨˜æ†¶é«”ä½¿ç”¨é‡ï¼ˆMBï¼‰

        # å…¨å±€ç·©å­˜
        self._ma_cache: Dict[str, Any] = {}
        self._boll_cache: Dict[str, Any] = {}
        self._hl_cache: Dict[str, Any] = {}
        self._value_cache: Dict[str, Any] = {}
        self._price_cache: Dict[str, Any] = {}

        # é è¨ˆç®—å¸¸ç”¨æ•¸æ“š
        self._precompute_data()

    def _precompute_data(self) -> None:
        """é è¨ˆç®—å¸¸ç”¨æ•¸æ“šï¼Œé¿å…é‡è¤‡è¨ˆç®—"""
        # é è¨ˆç®—åƒ¹æ ¼æ•¸æ“š
        for col in self.data.columns:
            if col in ["Open", "High", "Low", "Close", "Volume"]:
                self._price_cache[col] = self.data[col].values.astype(np.float64)

        # é è¨ˆç®—æ”¶ç›Šç‡
        self._price_cache["returns"] = np.zeros(len(self.data))
        if len(self._price_cache["Close"]) > 1:
            self._price_cache["returns"][1:] = (
                np.diff(self._price_cache["Close"]) / self._price_cache["Close"][:-1]
            )

    def generate_parameter_combinations(self, config: Dict) -> List[Tuple]:
        """
        ç”Ÿæˆåƒæ•¸çµ„åˆ - èˆ‡åŸæœ‰å¼•æ“å®Œå…¨ç›¸åŒ

        Args:
            config (Dict): å›æ¸¬é…ç½®ï¼ŒåŒ…å«æ¢ä»¶é…å°ã€æŒ‡æ¨™åƒæ•¸ã€é æ¸¬å› å­ç­‰

        Returns:
            List[Tuple]: æ‰€æœ‰åƒæ•¸çµ„åˆçš„åˆ—è¡¨
        """
        condition_pairs = config["condition_pairs"]
        indicator_params = config["indicator_params"]
        config["predictors"]


        all_combinations = []

        # ç‚ºæ¯å€‹æ¢ä»¶é…å°ç”Ÿæˆåƒæ•¸çµ„åˆ
        for i, pair in enumerate(condition_pairs):
            strategy_entry_params = []
            strategy_exit_params = []

            # è™•ç†é–‹å€‰æŒ‡æ¨™åƒæ•¸
            for entry_indicator in pair["entry"]:
                strategy_alias = f"{entry_indicator}_strategy_{i + 1}"
                if strategy_alias in indicator_params:
                    params = indicator_params[strategy_alias]
                    strategy_entry_params.append(params)
                else:
                    strategy_entry_params.append([])

            # è™•ç†å¹³å€‰æŒ‡æ¨™åƒæ•¸
            for exit_indicator in pair["exit"]:
                strategy_alias = f"{exit_indicator}_strategy_{i + 1}"
                if strategy_alias in indicator_params:
                    params = indicator_params[strategy_alias]
                    strategy_exit_params.append(params)
                else:
                    strategy_exit_params.append([])

            entry_combinations = self._generate_indicator_combinations(
                pair["entry"], strategy_entry_params
            )
            exit_combinations = self._generate_indicator_combinations(
                pair["exit"], strategy_exit_params
            )
            

            # çµ„åˆé–‹å€‰å’Œå¹³å€‰åƒæ•¸
            for entry_combo in entry_combinations:
                for exit_combo in exit_combinations:
                    strategy_combo = entry_combo + exit_combo
                    strategy_combo = strategy_combo + (f"strategy_{i + 1}",)
                    all_combinations.append(strategy_combo)

        return all_combinations

    def _generate_indicator_combinations(
        self, indicators: List[str], param_lists: List[List]
    ) -> List[Tuple]:
        """
        ç‚ºæŒ‡æ¨™åˆ—è¡¨ç”Ÿæˆåƒæ•¸çµ„åˆ - èˆ‡åŸæœ‰å¼•æ“å®Œå…¨ç›¸åŒ

        Args:
            indicators (List[str]): æŒ‡æ¨™åˆ—è¡¨
            param_lists (List[List]): å°æ‡‰çš„åƒæ•¸åˆ—è¡¨

        Returns:
            List[Tuple]: æŒ‡æ¨™åƒæ•¸çµ„åˆåˆ—è¡¨
        """
        if not indicators:
            return [()]

        combinations = []
        for combo in itertools.product(*param_lists):
            combinations.append(combo)

        return combinations

    def run_backtests(self, config: Dict) -> List[Dict]:  # pylint: disable=too-complex
        """
        åŸ·è¡ŒçœŸæ­£çš„å‘é‡åŒ–å›æ¸¬ - ä¸€æ¬¡æ€§è™•ç†æ‰€æœ‰ä»»å‹™

        Args:
            config (Dict): å›æ¸¬é…ç½®ï¼ŒåŒ…å«æ¢ä»¶é…å°ã€æŒ‡æ¨™åƒæ•¸ã€é æ¸¬å› å­ã€äº¤æ˜“åƒæ•¸ç­‰

        Returns:
            List[Dict]: å›æ¸¬çµæœåˆ—è¡¨ï¼Œæ¯å€‹å…ƒç´ åŒ…å«ä¸€å€‹ç­–ç•¥çš„å›æ¸¬çµæœ
        """
        all_combinations = self.generate_parameter_combinations(config)
        condition_pairs = config["condition_pairs"]
        predictors = config["predictors"]
        trading_params = config["trading_params"]

        total_backtests = len(all_combinations) * len(predictors)

        console = Console()

        console.print(
            Panel(
                (
                    f"å°‡åŸ·è¡Œå‘é‡åŒ–å›æ¸¬ï¼š{len(all_combinations)} ç¨®åƒæ•¸çµ„åˆ x "
                    f"{len(predictors)} å€‹é æ¸¬å› å­ = {total_backtests} æ¬¡å›æ¸¬\n"
                    f"äº¤æ˜“åƒæ•¸ï¼š{trading_params}"
                ),
                title="[bold #8f1511]ğŸš€ å‘é‡åŒ–å›æ¸¬å¼•æ“[/bold #8f1511]",
                border_style="#dbac30",
            )
        )

        # è‡ªå‹•åŒ–æ¨¡å¼ï¼šç›´æ¥ç¹¼çºŒï¼Œä¸è©¢å•ç”¨æˆ¶
        # é€™å€‹ç¢ºèªæ­¥é©Ÿåªåœ¨ CLI æ¨¡å¼ä¸‹éœ€è¦ï¼Œautorunner æ¨¡å¼ä¸‹æ‡‰è©²è‡ªå‹•ç¹¼çºŒ

        # é–‹å§‹å‘é‡åŒ–å›æ¸¬
        start_time = time.time()
        initial_memory = SpecMonitor.get_memory_usage()

        # é å…ˆæ”¶é›†é…ç½®ä¿¡æ¯
        config_info = SpecMonitor.collect_config_info(
            len(all_combinations) * len(predictors)
        )


        # é¡¯ç¤ºé…ç½®ä¿¡æ¯ - ä½¿ç”¨ SpecMonitor çš„çµ±ä¸€æ–¹æ³•
        if config_info:
            SpecMonitor.display_config_info(config_info, console)

        # å‘é‡åŒ–è™•ç† - ä¸€æ¬¡æ€§è™•ç†æ‰€æœ‰ä»»å‹™
        all_results = self._true_vectorized_backtest(
            all_combinations, condition_pairs, predictors, trading_params
        )

        # è¨˜æ†¶é«”ç®¡ç† - ä½¿ç”¨å‹•æ…‹é–¾å€¼
        current_memory = SpecMonitor.get_memory_usage()
        memory_used = current_memory - initial_memory

        # ç²å–å‹•æ…‹è¨˜æ†¶é«”é–¾å€¼
        memory_thresholds = SpecMonitor.get_memory_thresholds()
        warning_threshold = memory_thresholds["warning"]

        if memory_used > warning_threshold:
            memory_percent = (
                (memory_used / (memory_thresholds["total_memory_gb"] * 1024)) * 100
                if memory_thresholds["total_memory_gb"] > 0
                else 0
            )
            console.print(
                Panel(
                    (
                        f"âš ï¸ è¨˜æ†¶é«”ä½¿ç”¨éé«˜: {memory_used:.1f} MB "
                        f"({memory_percent:.1f}% of "
                        f"{memory_thresholds['total_memory_gb']:.1f}GB)ï¼Œå¼·åˆ¶åƒåœ¾å›æ”¶"
                    ),
                    title="[bold #dbac30]ğŸ’¾ è¨˜æ†¶é«”ç®¡ç†[/bold #dbac30]",
                    border_style="#dbac30",
                )
            )
            gc.collect()

        # ç§»é™¤ç¬¬äºŒæ¬¡é¡¯ç¤ºï¼Œé¿å…é‡è¤‡å’Œå­—ç¬¦è™•ç†å•é¡Œ

        # æœ€çµ‚çµ±è¨ˆ
        total_time = time.time() - start_time
        final_memory = SpecMonitor.get_memory_usage()
        memory_used = final_memory - initial_memory

        # ä¿®å¾©çµ±è¨ˆé‚è¼¯ï¼Œç¢ºä¿èˆ‡ç‹€æ…‹é¡¯ç¤ºä¸€è‡´
        # æˆåŠŸï¼šç„¡éŒ¯èª¤ä¸”æœ‰å¯¦éš›é–‹å€‰äº¤æ˜“
        success_count = len(
            [
                r
                for r in all_results
                if r.get("error") is None
                and "records" in r
                and isinstance(r.get("records"), pd.DataFrame)
                and not r.get("records").empty
                and (r.get("records")["Trade_action"] == 1).sum() > 0
            ]
        )
        # å¤±æ•—ï¼šæœ‰éŒ¯èª¤
        error_count = len([r for r in all_results if r.get("error") is not None])

        # æ›´æº–ç¢ºçš„ç„¡äº¤æ˜“çµ±è¨ˆï¼šæª¢æŸ¥æ˜¯å¦æœ‰å¯¦éš›äº¤æ˜“è¨˜éŒ„
        zero_trade_count = 0

        for r in all_results:
            if r.get("error") is None:
                records = r.get("records", pd.DataFrame())
                # æª¢æŸ¥æ˜¯å¦æœ‰é–‹å€‰äº¤æ˜“ï¼ˆTrade_action == 1ï¼‰
                if len(records) == 0 or (records["Trade_action"] == 1).sum() == 0:
                    zero_trade_count += 1

        # æ·»åŠ è¨ºæ–·ä¿¡æ¯
        diagnostic_info = ""
        if zero_trade_count > 0:
            # åˆ†æç„¡äº¤æ˜“çš„åŸå› 
            sample_no_trade = None
            for r in all_results:
                if r.get("error") is None:
                    records = r.get("records", pd.DataFrame())
                    if len(records) == 0 or (
                        len(records) > 0 and (records["Trade_action"] == 1).sum() == 0
                    ):
                        sample_no_trade = r
                        break

            if sample_no_trade:
                entry_signal = sample_no_trade.get("entry_signal", None)
                exit_signal = sample_no_trade.get("exit_signal", None)
                if entry_signal is not None and exit_signal is not None:
                    entry_counts = np.unique(entry_signal, return_counts=True)
                    exit_counts = np.unique(exit_signal, return_counts=True)
                    diagnostic_info = (
                        f"\nğŸ” è¨ºæ–·ä¿¡æ¯ï¼š\n"
                        f"â€¢ é–‹å€‰ä¿¡è™Ÿåˆ†å¸ƒï¼š{dict(zip(entry_counts[0], entry_counts[1]))}\n"
                        f"â€¢ å¹³å€‰ä¿¡è™Ÿåˆ†å¸ƒï¼š{dict(zip(exit_counts[0], exit_counts[1]))}"
                    )


        summary_text = f"""
âœ… å‘é‡åŒ–å›æ¸¬å®Œæˆï¼

ğŸ“Š æœ€çµ‚çµ±è¨ˆï¼š
â€¢ ç¸½ä»»å‹™æ•¸ï¼š{total_backtests}
â€¢ æˆåŠŸï¼š{success_count} ({success_count / total_backtests * 100:.1f}%)
â€¢ å¤±æ•—ï¼š{error_count} ({error_count / total_backtests * 100:.1f}%)
â€¢ ç„¡äº¤æ˜“ï¼š{zero_trade_count} ({zero_trade_count / total_backtests * 100:.1f}%)
â€¢ ç¸½è€—æ™‚ï¼š{total_time:.1f}ç§’
â€¢ è¨˜æ†¶é«”ä½¿ç”¨ï¼š{memory_used:.1f} MB
â€¢ å¹³å‡é€Ÿåº¦ï¼š{total_backtests / total_time:.0f} ä»»å‹™/ç§’{diagnostic_info}
"""

        console.print(
            Panel(
                summary_text,
                title="[bold #dbac30]ğŸ¯ å‘é‡åŒ–å›æ¸¬çµæœ[/bold #dbac30]",
                border_style="#dbac30",
            )
        )

        self.results = all_results
        return all_results

    def _true_vectorized_backtest(
        self,
        all_combinations: List[Tuple],
        condition_pairs: List[Dict],
        predictors: List[str],
        trading_params: Dict,
    ) -> List[Dict]:
        """å‘é‡åŒ–å›æ¸¬ - ä¸€æ¬¡æ€§è™•ç†æ‰€æœ‰ä»»å‹™"""
        total_backtests = len(all_combinations) * len(predictors)

        # å‰µå»ºä¸¦è¡Œè™•ç†é€²åº¦æ¢
        from rich.progress import (
            BarColumn,
            Progress,
            SpinnerColumn,
            TaskProgressColumn,
            TextColumn,
            TimeElapsedColumn,
            TimeRemainingColumn,
        )

        console = Console()
        parallel_progress = Progress(
            SpinnerColumn(),
            TextColumn("[bold green]{task.description}"),
            BarColumn(
                bar_width=40, complete_style="green", finished_style="bright_green"
            ),
            TaskProgressColumn(),
            TextColumn("({task.completed}/{task.total})"),
            TimeElapsedColumn(),
            TextColumn("â€¢"),
            TimeRemainingColumn(),
            console=console,
        )

        # å…ˆåŸ·è¡Œä¸éœ€è¦é€²åº¦æ¢çš„æ­¥é©Ÿ
        # æ­¥é©Ÿ1: ç”Ÿæˆä»»å‹™çŸ©é™£
        all_tasks = self._generate_all_tasks_matrix(all_combinations, predictors)

        # æ­¥é©Ÿ2: å‘é‡åŒ–ä¿¡è™Ÿç”Ÿæˆ
        all_signals = self._generate_all_signals_vectorized(
            all_tasks, condition_pairs
        )

        # æ­¥é©Ÿ3: å‘é‡åŒ–äº¤æ˜“æ¨¡æ“¬
        all_trade_results = self._simulate_all_trades_vectorized(
            all_signals, trading_params
        )

        # åœ¨å‰µå»ºé€²åº¦æ¢ä¹‹å‰é¡¯ç¤ºé…ç½®ä¿¡æ¯
        n_tasks = len(all_tasks["combinations"])
        n_cores, _ = SpecMonitor.get_optimal_core_count()
        
        # ç¢ºèªä¸¦è¡Œè™•ç†æ¨¡å¼
        console.print(
            Panel(
                f"ğŸ”§ ä¸¦è¡Œè™•ç†æ¨¡å¼: {n_tasks} å€‹ä»»å‹™, {n_cores} æ ¸å¿ƒ",
                title=Text("ğŸ‘¨â€ğŸ’» äº¤æ˜“å›æ¸¬ Backtester", style="bold #8f1511"),
                border_style="#dbac30",
            )
        )

        # å‹•æ…‹è¨ˆç®—æ‰¹æ¬¡å¤§å°
        if n_tasks <= 100:
            batch_size = max(20, n_tasks // 2)
        elif n_tasks <= 1000:
            batch_size = max(50, n_tasks // (n_cores * 2))
        elif n_tasks <= 10000:
            batch_size = max(200, n_tasks // (n_cores * 2))
        else:
            batch_size = max(400, n_tasks // (n_cores * 3))

        # è¨ˆç®—æ‰¹æ¬¡æ•¸é‡
        n_batches = (n_tasks + batch_size - 1) // batch_size

        # é¡¯ç¤ºæ‰¹æ¬¡é…ç½®
        if n_batches == 1:
            console.print(
                Panel(
                    f"ğŸ”§ å–®é€²ç¨‹è™•ç†: {n_tasks} å€‹ä»»å‹™",
                    title=Text("ğŸ‘¨â€ğŸ’» äº¤æ˜“å›æ¸¬ Backtester", style="bold #8f1511"),
                    border_style="#dbac30",
                )
            )
        else:
            console.print(
                Panel(
                    f"ğŸ”§ æ‰¹æ¬¡é…ç½®: {n_batches} å€‹æ‰¹æ¬¡, æ¯æ‰¹æ¬¡ç´„ {batch_size} å€‹ä»»å‹™",
                    title=Text("ğŸ‘¨â€ğŸ’» äº¤æ˜“å›æ¸¬ Backtester", style="bold #8f1511"),
                    border_style="#dbac30",
                )
            )

        # æ­¥é©Ÿ4: ä¸¦è¡Œçµæœç”Ÿæˆï¼ˆå¸¶é€²åº¦æ¢ï¼‰
        with parallel_progress:
            # å‰µå»ºé€²åº¦æ¢ä»»å‹™
            progress_task = parallel_progress.add_task(
                "ğŸ“Š [3/3] ç”Ÿæˆå›æ¸¬çµæœ", total=total_backtests
            )
            
            all_results = self._generate_all_results_vectorized(
                all_tasks,
                all_trade_results,
                all_signals,
                condition_pairs,
                trading_params,  # æ·»åŠ  trading_params åƒæ•¸
                parallel_progress,
                progress_task,
                total_backtests,
            )

        return all_results

    def _generate_all_tasks_matrix(
        self, all_combinations: List[Tuple], predictors: List[str]
    ) -> Dict:
        """ä¸€æ¬¡æ€§ç”Ÿæˆæ‰€æœ‰ä»»å‹™çŸ©é™£"""
        all_tasks: Dict[str, List[Any]] = {
            "combinations": [],
            "predictors": [],
            "backtest_ids": [],
            "strategy_ids": [],
            "entry_params_list": [],
            "exit_params_list": [],
        }

        for combo in all_combinations:
            for predictor in predictors:
                backtest_id = str(uuid.uuid4())[:16]
                strategy_id = combo[-1]  # æœ€å¾Œä¸€å€‹å…ƒç´ æ˜¯strategy_id

                all_tasks["combinations"].append(combo)
                all_tasks["predictors"].append(predictor)
                all_tasks["backtest_ids"].append(backtest_id)
                all_tasks["strategy_ids"].append(strategy_id)

                # åˆå§‹åŒ– entry_params_list å’Œ exit_params_listï¼ˆå°‡åœ¨åˆ†çµ„è™•ç†ä¸­å¡«å……ï¼‰
                all_tasks["entry_params_list"].append([])
                all_tasks["exit_params_list"].append([])

        return all_tasks

    def _generate_all_signals_vectorized(
        self, all_tasks: Dict, condition_pairs: List[Dict]
    ) -> Dict:
        """çœŸæ­£çš„å‘é‡åŒ–ä¿¡è™Ÿç”Ÿæˆ - ä½¿ç”¨åˆ†çµ„è™•ç†ç­–ç•¥ï¼Œè§£æ±ºç¶­åº¦è¡çªå•é¡Œ"""

        n_tasks = len(all_tasks["combinations"])
        n_time = len(self.data)

        # åˆå§‹åŒ–ä¿¡è™ŸçŸ©é™£
        entry_signals = np.zeros((n_time, n_tasks))
        exit_signals = np.zeros((n_time, n_tasks))

        from rich.console import Console
        from rich.progress import (
            BarColumn,
            Progress,
            SpinnerColumn,
            TaskProgressColumn,
            TextColumn,
            TimeElapsedColumn,
            TimeRemainingColumn,
        )

        console = Console()
        
        # å‰µå»ºä¿¡è™Ÿç”Ÿæˆé€²åº¦æ¢
        signal_progress = Progress(
            SpinnerColumn(),
            TextColumn("[bold cyan]{task.description}"),
            BarColumn(bar_width=40, complete_style="cyan", finished_style="bright_cyan"),
            TaskProgressColumn(),
            TextColumn("({task.completed}/{task.total})"),
            TimeElapsedColumn(),
            TextColumn("â€¢"),
            TimeRemainingColumn(),
            console=console,
        )

        with signal_progress:
            # æ­¥é©Ÿ1: æŒ‰æŒ‡æ¨™æ•¸é‡åˆ†çµ„ç­–ç•¥
            strategy_groups = self._group_strategies_by_indicator_count(all_tasks, condition_pairs)
            
            # ä½¿ç”¨åˆ†çµ„è™•ç†ç­–ç•¥ï¼Œè§£æ±ºç¶­åº¦è¡çªå•é¡Œ
            # total = 1 (åˆ†çµ„) + len(strategy_groups) (è™•ç†æ¯å€‹åˆ†çµ„)
            signal_task = signal_progress.add_task(
                "ğŸš€ ä¿¡è™Ÿç”Ÿæˆ (åˆ†çµ„è™•ç†)", total=1 + len(strategy_groups)
            )
            
            # å®Œæˆåˆ†çµ„æ­¥é©Ÿ
            signal_progress.update(signal_task, completed=1, description=f"ğŸš€ [1/{1 + len(strategy_groups)}] ä¿¡è™Ÿç”Ÿæˆ - å·²åˆ†çµ„ {len(strategy_groups)} å€‹ç­–ç•¥çµ„")

            # æ­¥é©Ÿ2: è™•ç†æ¯å€‹ç­–ç•¥åˆ†çµ„
            completed_groups = 0
            for group in strategy_groups:
                try:
                    # è™•ç†å–®å€‹ç­–ç•¥åˆ†çµ„
                    group_result = self._process_strategy_group(group)
                    
                    # å°‡åˆ†çµ„çµæœåˆ†é…åˆ°å°æ‡‰ä½ç½®
                    for task_info in group["tasks"]:
                        task_idx = task_info["task_idx"]
                        local_idx = group["tasks"].index(task_info)
                        
                        entry_signals[:, task_idx] = group_result["entry_signals"][:, local_idx]
                        exit_signals[:, task_idx] = group_result["exit_signals"][:, local_idx]
                        
                except Exception as e:
                    self.logger.warning(f"ç­–ç•¥åˆ†çµ„è™•ç†å¤±æ•—: {e}")
                    # ç‚ºå¤±æ•—çš„åˆ†çµ„è¨­ç½®é›¶ä¿¡è™Ÿ
                    for task_info in group["tasks"]:
                        task_idx = task_info["task_idx"]
                        entry_signals[:, task_idx] = 0
                        exit_signals[:, task_idx] = 0
                
                # æ›´æ–°é€²åº¦æ¢
                completed_groups += 1
                current_step = 1 + completed_groups
                total_steps = 1 + len(strategy_groups)
                signal_progress.update(
                    signal_task, 
                    completed=current_step, 
                    description=f"ğŸš€ [{current_step}/{total_steps}] ä¿¡è™Ÿç”Ÿæˆ - å·²è™•ç† {completed_groups}/{len(strategy_groups)} å€‹ç­–ç•¥åˆ†çµ„"
                )

        # è¿”å›å–®å€‹numpyæ•¸çµ„ï¼Œèˆ‡åŸç‰ˆæ ¼å¼ä¸€è‡´
        return {
            "entry_signals": entry_signals,
            "exit_signals": exit_signals,
            "all_signals_matrix": [],  # ç©ºåˆ—è¡¨ï¼Œä¿æŒå…¼å®¹æ€§
        }

    def _group_strategies_by_indicator_count(
        self, all_tasks: Dict, condition_pairs: List[Dict]
    ) -> List[Dict]:
        """æŒ‰æŒ‡æ¨™æ•¸é‡åˆ†çµ„ç­–ç•¥"""
        groups: Dict[str, Any] = {}

        for task_idx, combo in enumerate(all_tasks["combinations"]):
            strategy_id = combo[-1]
            strategy_idx = int(strategy_id.split("_")[-1]) - 1

            if strategy_idx < len(condition_pairs):
                condition_pair = condition_pairs[strategy_idx]
                entry_count = len(condition_pair["entry"])
                exit_count = len(condition_pair["exit"])

                # å‰µå»ºåˆ†çµ„éµï¼šé–‹å€‰æŒ‡æ¨™æ•¸ + å¹³å€‰æŒ‡æ¨™æ•¸
                group_key = f"entry_{entry_count}_exit_{exit_count}"

                if group_key not in groups:
                    groups[group_key] = {
                        "entry_count": entry_count,
                        "exit_count": exit_count,
                        "tasks": [],
                        "condition_pairs": [],
                    }

                groups[group_key]["tasks"].append(
                    {
                        "task_idx": task_idx,
                        "combo": combo,
                        "strategy_idx": strategy_idx,
                        "predictor": all_tasks["predictors"][task_idx],
                    }
                )
                groups[group_key]["condition_pairs"].append(condition_pair)

        return list(groups.values())

    def _process_strategy_group(self, group: Dict) -> Dict:
        """è™•ç†å–®å€‹ç­–ç•¥åˆ†çµ„"""
        entry_count = group["entry_count"]
        exit_count = group["exit_count"]
        tasks = group["tasks"]

        # æå–è©²åˆ†çµ„çš„åƒæ•¸
        entry_params_list = []
        exit_params_list = []
        predictors_list = []

        for task_info in tasks:
            combo = task_info["combo"]
            _ = task_info["strategy_idx"]  # ä¿ç•™ä»¥ä¾›æœªä¾†ä½¿ç”¨
            # condition_pairæœªä½¿ç”¨,å·²è¨»é‡‹
            # condition_pair = group["condition_pairs"][0]  # åŒçµ„å…§æ¢ä»¶ç›¸åŒ

            # è§£æåƒæ•¸
            entry_params = list(combo[:entry_count])
            exit_params = list(combo[entry_count : entry_count + exit_count])

            entry_params_list.append(entry_params)
            exit_params_list.append(exit_params)
            predictors_list.append(task_info["predictor"])

        # ç”Ÿæˆä¿¡è™Ÿï¼ˆéœé»˜æ¨¡å¼ï¼Œé¿å…èˆ‡å¤–å±¤é€²åº¦æ¢è¡çªï¼‰
        entry_signals_matrix = self._vectorized_generate_signals(
            entry_params_list, predictors_list
        )
        exit_signals_matrix = self._vectorized_generate_signals(
            exit_params_list, predictors_list
        )

        # åˆä½µä¿¡è™Ÿ
        combined_entry_signals = self._vectorized_combine_signals(
            entry_signals_matrix, is_exit_signals=False
        )
        combined_exit_signals = self._vectorized_combine_signals(
            exit_signals_matrix, is_exit_signals=True
        )

        return {
            "entry_signals": combined_entry_signals,
            "exit_signals": combined_exit_signals,
            "all_signals_matrix": entry_signals_matrix,
        }

    def _simulate_all_trades_vectorized(
        self, all_signals: Dict, trading_params: Dict
    ) -> Dict:
        """å‘é‡åŒ–äº¤æ˜“æ¨¡æ“¬ - è™•ç†å–®å€‹numpyæ•¸çµ„æ ¼å¼çš„ä¿¡è™Ÿï¼Œå¸¶é€²åº¦æ¢"""

        from rich.console import Console
        from rich.progress import (
            BarColumn,
            Progress,
            SpinnerColumn,
            TaskProgressColumn,
            TextColumn,
            TimeElapsedColumn,
            TimeRemainingColumn,
        )

        console = Console()
        
        # å‰µå»ºäº¤æ˜“æ¨¡æ“¬é€²åº¦æ¢
        trade_progress = Progress(
            SpinnerColumn(),
            TextColumn("[bold yellow]{task.description}"),
            BarColumn(bar_width=40, complete_style="yellow", finished_style="bright_yellow"),
            TaskProgressColumn(),
            TextColumn("({task.completed}/{task.total})"),
            TimeElapsedColumn(),
            TextColumn("â€¢"),
            TimeRemainingColumn(),
            console=console,
        )

        # ç›´æ¥ä½¿ç”¨å–®å€‹numpyæ•¸çµ„æ ¼å¼çš„ä¿¡è™Ÿ
        entry_signals = all_signals["entry_signals"]
        exit_signals = all_signals["exit_signals"]
        n_strategies = entry_signals.shape[1]

        with trade_progress:
            trade_task = trade_progress.add_task(
                f"ğŸ“ˆ [2/3] äº¤æ˜“æ¨¡æ“¬ - {n_strategies} å€‹ç­–ç•¥", total=2
            )
            
            # å‰µå»º TradeSimulator å¯¦ä¾‹
            simulator = TradeSimulator_backtester(
                self.data,
                (
                    pd.Series(entry_signals[:, 0])
                    if entry_signals.shape[1] > 0
                    else pd.Series(0, index=self.data.index)
                ),  # ä½¿ç”¨ç¬¬ä¸€å€‹ç­–ç•¥çš„ä¿¡è™Ÿä½œç‚ºç¤ºä¾‹
                (
                    pd.Series(exit_signals[:, 0])
                    if exit_signals.shape[1] > 0
                    else pd.Series(0, index=self.data.index)
                ),
                trading_params.get("transaction_cost", 0.001),
                trading_params.get("slippage", 0.0005),
                trading_params.get("trade_delay", 0),
                trading_params.get("trade_price", "close"),
                None,  # Backtest_id
                None,  # parameter_set_id
                None,  # predictor
                1.0,  # initial_equity
                None,  # indicators
                self.symbol,  # trading_instrument
            )
            
            trade_progress.update(trade_task, completed=1, description="ğŸ“ˆ [2/3] äº¤æ˜“æ¨¡æ“¬ - æº–å‚™å®Œæˆ")

            # èª¿ç”¨ TradeSimulator çš„å‘é‡åŒ–æ–¹æ³•
            trade_results = simulator.simulate_trades_vectorized(
                entry_signals, exit_signals, trading_params
            )
            
            trade_progress.update(trade_task, completed=2, description=f"ğŸ“ˆ [2/3] äº¤æ˜“æ¨¡æ“¬ - å®Œæˆ {n_strategies} å€‹ç­–ç•¥")

        return trade_results

    # èˆŠçš„æ‰¹æ¬¡è™•ç†å‡½æ•¸å·²è¢« _process_batch_results_optimized å–ä»£

    def _generate_all_results_vectorized(  # pylint: disable=too-complex
        self,
        all_tasks: Dict[str, Any],
        all_trade_results: Dict[str, Any],
        all_signals: Dict[str, Any],
        condition_pairs: List[Dict[str, Any]],
        trading_params: Dict[str, Any],  # æ·»åŠ  trading_params åƒæ•¸
        progress: Optional[Any] = None,
        task: Optional[Any] = None,
        total_backtests: Optional[int] = None,
    ) -> List[Dict]:
        """ä¸€æ¬¡æ€§ç”Ÿæˆæ‰€æœ‰çµæœï¼ˆå„ªåŒ–ä¸¦è¡Œç‰ˆæœ¬ï¼‰- æ”¹é€²é€²åº¦è¿½è¹¤"""
        n_tasks = len(all_tasks["combinations"])

        # è¨˜éŒ„åˆå§‹è¨˜æ†¶é«”ä½¿ç”¨é‡
        initial_memory = SpecMonitor.get_memory_usage()

        # ç²å–å‹•æ…‹è¨˜æ†¶é«”é–¾å€¼
        memory_thresholds = SpecMonitor.get_memory_thresholds()
        warning_threshold = memory_thresholds["warning"]

        # æ™ºèƒ½CPUé…ç½®æª¢æ¸¬
        n_cores, core_info = SpecMonitor.get_optimal_core_count()

        # å‹•æ…‹è¨ˆç®—æ‰¹æ¬¡å¤§å° - åŸºæ–¼æ ¸å¿ƒæ•¸å„ªåŒ–
        if n_tasks <= 100:
            # å°ä»»å‹™æ•¸ä¹Ÿåˆ†æ‰¹è™•ç†ï¼Œé¿å…å–®æ‰¹æ¬¡é–‹éŠ·
            batch_size = max(20, n_tasks // 2)
        elif n_tasks <= 1000:
            # ä¸­ç­‰ä»»å‹™æ•¸ï¼ŒåŸºæ–¼æ ¸å¿ƒæ•¸è¨ˆç®—
            batch_size = max(50, n_tasks // (n_cores * 2))
        elif n_tasks <= 10000:
            batch_size = max(200, n_tasks // (n_cores * 2))  # åŸºæ–¼æ ¸å¿ƒæ•¸è¨ˆç®—
        else:
            batch_size = max(400, n_tasks // (n_cores * 3))  # åŸºæ–¼æ ¸å¿ƒæ•¸è¨ˆç®—

        # æº–å‚™æ‰¹æ¬¡ç´¢å¼•
        batch_indices = []
        batch_sizes = []  # è¨˜éŒ„æ¯å€‹æ‰¹æ¬¡çš„å¤§å°
        for i in range(0, n_tasks, batch_size):
            end_idx = min(i + batch_size, n_tasks)
            batch_indices.append(list(range(i, end_idx)))
            batch_sizes.append(end_idx - i)

        # å‰µå»ºæ”¹é€²çš„é€²åº¦ç›£æ§å™¨
        from rich.console import Console

        console = Console()
        progress_monitor = None
        if progress is not None and task is not None:
            progress_monitor = ProgressMonitor(
                progress, task, total_backtests, len(batch_indices)
            )
            progress_monitor.set_batch_sizes(batch_sizes)

        # è™•ç†é‚è¼¯
        if len(batch_indices) == 1:

            batch_data = self._prepare_batch_data(
                batch_indices[0],
                all_tasks,
                all_trade_results,
                all_signals,
                condition_pairs,
                trading_params,  # å‚³å…¥ trading_params
            )
            results = self._process_batch_results_optimized(batch_data)

            # é€šçŸ¥é€²åº¦ç›£æ§å™¨æ‰¹æ¬¡å®Œæˆ
            if progress_monitor is not None:
                progress_monitor.batch_completed(
                    batch_idx=0, completed_tasks_in_batch=len(results)
                )
                progress_monitor.finish()
            else:
                # å¦‚æœæ²’æœ‰é€²åº¦ç›£æ§å™¨ï¼Œç›´æ¥é¡¯ç¤ºå®Œæˆä¿¡æ¯
                console.print(
                    Panel(
                        f"âœ… å–®é€²ç¨‹è™•ç†å®Œæˆ: {n_tasks} å€‹ä»»å‹™",
                        title=Text("ğŸ‘¨â€ğŸ’» äº¤æ˜“å›æ¸¬ Backtester", style="bold #8f1511"),
                        border_style="#dbac30",
                    )
                )

            # å–®é€²ç¨‹è™•ç†å®Œæˆå¾Œé€²è¡Œè¨˜æ†¶é«”æª¢æŸ¥
            current_memory = SpecMonitor.get_memory_usage()
            memory_used = current_memory - initial_memory
            if memory_used > warning_threshold:  # ä½¿ç”¨å‹•æ…‹é–¾å€¼
                memory_percent = (
                    (memory_used / (memory_thresholds["total_memory_gb"] * 1024)) * 100
                    if memory_thresholds["total_memory_gb"] > 0
                    else 0
                )
                console.print(
                    Panel(
                        (
                            f"âš ï¸ è¨˜æ†¶é«”ä½¿ç”¨éé«˜: {memory_used:.1f} MB "
                            f"({memory_percent:.1f}% of "
                            f"{memory_thresholds['total_memory_gb']:.1f}GB)ï¼Œå¼·åˆ¶åƒåœ¾å›æ”¶"
                        ),
                        title=Text("ğŸ’¾ è¨˜æ†¶é«”ç®¡ç†", style="bold #8f1511"),
                        border_style="#dbac30",
                    )
                )
                gc.collect()
        else:
            # å¤šæ‰¹æ¬¡ä¸¦è¡Œè™•ç†
            results = []
            try:
                with ProcessPoolExecutor(max_workers=n_cores) as executor:
                    futures = []

                    # åˆ†æ‰¹æäº¤ä»»å‹™ï¼Œç›´æ¥å‚³é numpy æ•¸çµ„
                    for batch_idx, batch_idx_list in enumerate(batch_indices):
                        batch_data = self._prepare_batch_data(
                            batch_idx_list,
                            all_tasks,
                            all_trade_results,
                            all_signals,
                            condition_pairs,
                            trading_params,  # å‚³å…¥ trading_params
                        )
                        future = executor.submit(
                            self._process_batch_results_optimized, batch_data
                        )
                        futures.append((batch_idx, future))

                # æ”¶é›†çµæœä¸¦æ›´æ–°é€²åº¦
                for batch_idx, future in futures:
                    try:
                        # æ·»åŠ è¶…æ™‚è™•ç†ï¼Œé˜²æ­¢å­é€²ç¨‹å¡æ­»
                        batch_results = future.result(timeout=300)  # 5åˆ†é˜è¶…æ™‚
                        results.extend(batch_results)

                        # é€šçŸ¥é€²åº¦ç›£æ§å™¨æ‰¹æ¬¡å®Œæˆ
                        if progress_monitor is not None:
                            progress_monitor.batch_completed(
                                batch_idx=batch_idx,
                                completed_tasks_in_batch=len(batch_results),
                            )

                        # å¯¦æ™‚è¨˜æ†¶é«”ç›£æ§å’Œåƒåœ¾å›æ”¶
                        if (batch_idx + 1) % 3 == 0:
                            # æ¯3å€‹æ‰¹æ¬¡æª¢æŸ¥ä¸€æ¬¡è¨˜æ†¶é«”
                            current_memory = SpecMonitor.get_memory_usage()
                            memory_used = current_memory - initial_memory

                            # å¦‚æœè¨˜æ†¶é«”ä½¿ç”¨è¶…éé–¾å€¼ï¼Œç«‹å³é€²è¡Œåƒåœ¾å›æ”¶
                            if memory_used > warning_threshold:  # ä½¿ç”¨å‹•æ…‹é–¾å€¼
                                memory_percent = (
                                    (
                                        memory_used
                                        / (memory_thresholds["total_memory_gb"] * 1024)
                                    )
                                    * 100
                                    if memory_thresholds["total_memory_gb"] > 0
                                    else 0
                                )
                                console.print(
                                    Panel(
                                        (
                                            f"âš ï¸ è¨˜æ†¶é«”ä½¿ç”¨éé«˜: {memory_used:.1f} MB "
                                            f"({memory_percent:.1f}% of "
                                            f"{memory_thresholds['total_memory_gb']:.1f}GB)ï¼Œ"
                                            f"å¼·åˆ¶åƒåœ¾å›æ”¶"
                                        ),
                                        title=Text(
                                            "ğŸ’¾ è¨˜æ†¶é«”ç®¡ç†", style="bold #8f1511"
                                        ),
                                        border_style="#dbac30",
                                    )
                                )
                                gc.collect()
                            else:
                                # å®šæœŸåƒåœ¾å›æ”¶
                                gc.collect()

                    except Exception as batch_error:
                        console.print(
                            Panel(
                                f"æ‰¹æ¬¡ {batch_idx + 1} è™•ç†å¤±æ•—: {batch_error}",
                                title=Text("âš ï¸ è™•ç†éŒ¯èª¤", style="bold #8f1511"),
                                border_style="#dbac30",
                            )
                        )

                        # ç‚ºå¤±æ•—çš„æ‰¹æ¬¡æ·»åŠ éŒ¯èª¤çµæœ
                        batch_size = (
                            len(batch_indices[batch_idx])
                            if batch_idx < len(batch_indices)
                            else 1
                        )
                        for j in range(batch_size):
                            error_result = {
                                "Backtest_id": f"error_batch_{batch_idx}_item_{j}",
                                "strategy_id": "error",
                                "params": {
                                    "entry": [],
                                    "exit": [],
                                    "predictor": "error",
                                },
                                "records": pd.DataFrame(),
                                "warning_msg": None,
                                "error": f"æ‰¹æ¬¡è™•ç†å¤±æ•—: {batch_error}",
                            }
                            results.append(error_result)

                        # é€šçŸ¥é€²åº¦ç›£æ§å™¨æ‰¹æ¬¡å®Œæˆï¼ˆå³ä½¿å¤±æ•—ï¼‰
                        if progress_monitor is not None:
                            progress_monitor.batch_completed(
                                batch_idx=batch_idx, completed_tasks_in_batch=batch_size
                            )

                # å®Œæˆé€²åº¦ç›£æ§
                if progress_monitor is not None:
                    progress_monitor.finish()

            except Exception as e:
                console.print(
                    Panel(
                        f"ä¸¦è¡Œè™•ç†å¤±æ•—: {e}",
                        title=Text("âŒ è™•ç†éŒ¯èª¤", style="bold #8f1511"),
                        border_style="#dbac30",
                    )
                )
                # å¦‚æœä¸¦è¡Œè™•ç†å®Œå…¨å¤±æ•—ï¼Œä½¿ç”¨ç°¡åŒ–çš„ä¸²è¡Œè™•ç†
                console.print(
                    Panel(
                        "å›é€€åˆ°ç°¡åŒ–ä¸²è¡Œè™•ç†...",
                        title="âš ï¸ è™•ç†è­¦å‘Š",
                        border_style="#8f1511",
                    )
                )
                return self._generate_all_results_simple(
                    all_tasks,
                    all_trade_results,
                    all_signals,
                    condition_pairs,
                    progress,
                    task,
                    total_backtests,
                )

        return results

    def _prepare_batch_data(
        self,
        batch_indices: List[int],
        all_tasks: Dict,
        all_trade_results: Dict,
        all_signals: Dict,
        condition_pairs: List[Dict],
        trading_params: Dict,  # æ·»åŠ  trading_params åƒæ•¸
    ) -> Dict:
        """æº–å‚™æ‰¹æ¬¡æ•¸æ“šï¼Œç›´æ¥å‚³é numpy æ•¸çµ„ä»¥å„ªåŒ–æ€§èƒ½"""
        batch_data = {
            "batch_indices": batch_indices,
            "condition_pairs": condition_pairs,
            "task_data": {},
        }

        # åªæå–ç•¶å‰æ‰¹æ¬¡éœ€è¦çš„ä»»å‹™æ•¸æ“š
        for idx in batch_indices:
            batch_data["task_data"][idx] = {
                "predictor": all_tasks["predictors"][idx],
                "backtest_id": all_tasks["backtest_ids"][idx],
                "strategy_id": all_tasks["strategy_ids"][idx],
                "combo": all_tasks["combinations"][idx],
            }

        # ç›´æ¥ä½¿ç”¨å–®å€‹numpyæ•¸çµ„æ ¼å¼çš„ä¿¡è™Ÿ
        batch_data["signals"] = {
            "entry_signals": all_signals["entry_signals"][:, batch_indices],
            "exit_signals": all_signals["exit_signals"][:, batch_indices],
        }

        # æå–äº¤æ˜“çµæœæ•¸æ“šï¼Œç›´æ¥å‚³é numpy æ•¸çµ„
        batch_data["trade_results"] = {
            "positions": all_trade_results["positions"][:, batch_indices],
            "returns": all_trade_results["returns"][:, batch_indices],
            "trade_actions": all_trade_results["trade_actions"][:, batch_indices],
            "equity_values": all_trade_results["equity_values"][:, batch_indices],
        }

        # æ·»åŠ  trading_params åˆ° batch_data
        batch_data["trading_params"] = trading_params

        return batch_data

    def _process_batch_results_optimized(self, batch_data: Dict) -> List[Dict]:
        """å„ªåŒ–çš„æ‰¹æ¬¡è™•ç†å‡½æ•¸ï¼Œç›´æ¥ä½¿ç”¨ numpy æ•¸çµ„"""

        batch_indices = batch_data["batch_indices"]
        condition_pairs = batch_data["condition_pairs"]
        task_data = batch_data["task_data"]
        signals = batch_data["signals"]
        trade_results = batch_data["trade_results"]
        trading_params = batch_data[
            "trading_params"
        ]  # å¾ batch_data ä¸­ç²å– trading_params

        try:
            results = []

            # å‰µå»ºç´¢å¼•æ˜ å°„ï¼Œé¿å…é‡è¤‡çš„ list.index() æ“ä½œ
            batch_idx_map = {
                task_idx: idx for idx, task_idx in enumerate(batch_indices)
            }

            # è™•ç†æ‰€æœ‰ä»»å‹™
            for task_idx in batch_indices:
                try:
                    # è§£æç­–ç•¥åƒæ•¸
                    strategy_id = task_data[task_idx]["strategy_id"]
                    strategy_idx = self._parse_strategy_id(strategy_id)
                    condition_pair = condition_pairs[strategy_idx]

                    combo = task_data[task_idx]["combo"]
                    entry_params = list(combo[: len(condition_pair["entry"])])
                    exit_params = list(
                        combo[
                            len(condition_pair["entry"]) : len(condition_pair["entry"])
                            + len(condition_pair["exit"])
                        ]
                    )

                    # ç›´æ¥ä½¿ç”¨ numpy æ•¸çµ„ï¼Œé¿å… np.array() è½‰æ›
                    batch_idx = batch_idx_map[task_idx]
                    entry_signal = signals["entry_signals"][:, batch_idx]
                    exit_signal = signals["exit_signals"][:, batch_idx]
                    position = trade_results["positions"][:, batch_idx]
                    returns = trade_results["returns"][:, batch_idx]
                    trade_actions = trade_results["trade_actions"][:, batch_idx]
                    equity_values = trade_results["equity_values"][:, batch_idx]

                    # ç”Ÿæˆå–®å€‹çµæœ
                    result = self._generate_single_result(
                        task_idx,
                        entry_signal,
                        exit_signal,
                        position,
                        returns,
                        trade_actions,
                        equity_values,
                        task_data[task_idx]["predictor"],
                        task_data[task_idx]["backtest_id"],
                        entry_params,
                        exit_params,
                        trading_params,  # ä½¿ç”¨å®Œæ•´çš„ trading_params
                    )
                    results.append(result)

                except Exception as e:
                    error_msg = f"ç”Ÿæˆçµæœå¤±æ•— (task_idx={task_idx}): {str(e)}"
                    error_result = {
                        "Backtest_id": task_data[task_idx]["backtest_id"],
                        "strategy_id": (
                            f"strategy_{strategy_idx + 1}"
                            if "strategy_idx" in locals()
                            else "unknown"
                        ),
                        "params": {
                            "entry": [],
                            "exit": [],
                            "predictor": task_data[task_idx]["predictor"],
                        },
                        "records": pd.DataFrame(),
                        "warning_msg": None,
                        "error": error_msg,
                    }
                    results.append(error_result)

            return results

        except Exception as e:
            # è¿”å›éŒ¯èª¤çµæœ
            error_results = []
            for task_idx in batch_indices:
                error_result = {
                    "Backtest_id": f"error_{task_idx}",
                    "strategy_id": "error",
                    "params": {"entry": [], "exit": [], "predictor": "error"},
                    "records": pd.DataFrame(),
                    "warning_msg": None,
                    "error": f"å­é€²ç¨‹éŒ¯èª¤: {str(e)}",
                }
                error_results.append(error_result)
            return error_results

    def _generate_all_results_simple(  # pylint: disable=too-complex
        self,
        all_tasks: Dict[str, Any],
        all_trade_results: Dict[str, Any],
        all_signals: Dict[str, Any],
        condition_pairs: List[Dict[str, Any]],
        progress: Optional[Any] = None,
        task: Optional[Any] = None,
        total_backtests: Optional[int] = None,
    ) -> List[Dict[str, Any]]:
        """ç°¡åŒ–çš„ä¸²è¡Œè™•ç†ï¼ˆå‚™ç”¨æ–¹æ¡ˆï¼‰- æ”¹é€²é€²åº¦è¿½è¹¤"""

        n_tasks = len(all_tasks["combinations"])

        # è¨˜éŒ„åˆå§‹è¨˜æ†¶é«”ä½¿ç”¨é‡
        initial_memory = SpecMonitor.get_memory_usage()

        # ç²å–å‹•æ…‹è¨˜æ†¶é«”é–¾å€¼
        memory_thresholds = SpecMonitor.get_memory_thresholds()
        warning_threshold = memory_thresholds["warning"]

        from rich.console import Console

        console = Console()
        console.print(
            Panel(
                f"ğŸ”§ ç°¡åŒ–ä¸²è¡Œè™•ç†: {n_tasks} å€‹ä»»å‹™",
                title=Text("ğŸ‘¨â€ğŸ’» äº¤æ˜“å›æ¸¬ Backtester", style="bold #8f1511"),
                border_style="#dbac30",
            )
        )

        # ç›´æ¥ä½¿ç”¨å–®å€‹numpyæ•¸çµ„æ ¼å¼çš„ä¿¡è™Ÿ
        entry_signals = all_signals["entry_signals"]
        exit_signals = all_signals["exit_signals"]

        # å‰µå»ºæ”¹é€²çš„é€²åº¦ç›£æ§å™¨
        progress_monitor = None
        if progress is not None and task is not None:
            # å°æ–¼ä¸²è¡Œè™•ç†ï¼Œå°‡æ¯å€‹ä»»å‹™è¦–ç‚ºä¸€å€‹æ‰¹æ¬¡
            progress_monitor = ProgressMonitor(progress, task, total_backtests, n_tasks)
            progress_monitor.set_batch_sizes([1] * n_tasks)  # æ¯å€‹æ‰¹æ¬¡å¤§å°ç‚º1

            # åˆå§‹åŒ–é€²åº¦æ¢é¡¯ç¤º
            progress.update(
                task,
                description=f"ç”Ÿæˆå›æ¸¬çµæœ (0/{n_tasks} æ‰¹æ¬¡, 0/{total_backtests} ä»»å‹™)",
            )

        results = []

        for task_idx in range(n_tasks):
            try:
                # è§£æç­–ç•¥åƒæ•¸
                strategy_id = all_tasks["strategy_ids"][task_idx]
                strategy_idx = self._parse_strategy_id(strategy_id)
                condition_pair = condition_pairs[strategy_idx]

                combo = all_tasks["combinations"][task_idx]
                entry_params = list(combo[: len(condition_pair["entry"])])
                exit_params = list(
                    combo[
                        len(condition_pair["entry"]) : len(condition_pair["entry"])
                        + len(condition_pair["exit"])
                    ]
                )

                # ç”Ÿæˆå–®å€‹çµæœ
                result = self._generate_single_result(
                    task_idx,
                    (
                        entry_signals[:, task_idx]
                        if task_idx < entry_signals.shape[1]
                        else np.zeros(len(self.data))
                    ),
                    (
                        exit_signals[:, task_idx]
                        if task_idx < exit_signals.shape[1]
                        else np.zeros(len(self.data))
                    ),
                    all_trade_results["positions"][:, task_idx],
                    all_trade_results["returns"][:, task_idx],
                    all_trade_results["trade_actions"][:, task_idx],
                    all_trade_results["equity_values"][:, task_idx],
                    all_tasks["predictors"][task_idx],
                    all_tasks["backtest_ids"][task_idx],
                    entry_params,
                    exit_params,
                    {"transaction_cost": 0.001, "slippage": 0.0005},
                )
                results.append(result)

                # é€šçŸ¥é€²åº¦ç›£æ§å™¨ä»»å‹™å®Œæˆ
                if progress_monitor is not None:
                    progress_monitor.batch_completed(
                        batch_idx=task_idx, completed_tasks_in_batch=1
                    )

                # æ¯1000å€‹ä»»å‹™æª¢æŸ¥ä¸€æ¬¡è¨˜æ†¶é«”
                if (task_idx + 1) % 1000 == 0:
                    current_memory = SpecMonitor.get_memory_usage()
                    memory_used = current_memory - initial_memory
                    if memory_used > warning_threshold:  # ä½¿ç”¨å‹•æ…‹é–¾å€¼
                        memory_percent = (
                            (
                                memory_used
                                / (memory_thresholds["total_memory_gb"] * 1024)
                            )
                            * 100
                            if memory_thresholds["total_memory_gb"] > 0
                            else 0
                        )
                        console.print(
                            Panel(
                                (
                                    f"âš ï¸ è¨˜æ†¶é«”ä½¿ç”¨éé«˜: {memory_used:.1f} MB "
                                    f"({memory_percent:.1f}% of "
                                    f"{memory_thresholds['total_memory_gb']:.1f}GB)ï¼Œå¼·åˆ¶åƒåœ¾å›æ”¶"
                                ),
                                title=Text("ğŸ’¾ è¨˜æ†¶é«”ç®¡ç†", style="bold #8f1511"),
                                border_style="#dbac30",
                            )
                        )
                        gc.collect()
                    else:
                        # å®šæœŸåƒåœ¾å›æ”¶
                        gc.collect()

            except Exception as e:
                error_msg = f"ç”Ÿæˆçµæœå¤±æ•— (task_idx={task_idx}): {str(e)}"
                error_result = {
                    "Backtest_id": all_tasks["backtest_ids"][task_idx],
                    "strategy_id": (
                        f"strategy_{strategy_idx + 1}"
                        if "strategy_idx" in locals()
                        else "unknown"
                    ),
                    "params": {
                        "entry": [],
                        "exit": [],
                        "predictor": (
                            all_tasks["predictors"][task_idx]
                            if task_idx < len(all_tasks["predictors"])
                            else "unknown"
                        ),
                    },
                    "records": pd.DataFrame(),
                    "warning_msg": None,
                    "error": error_msg,
                }
                results.append(error_result)

                # é€šçŸ¥é€²åº¦ç›£æ§å™¨ä»»å‹™å®Œæˆï¼ˆå³ä½¿å¤±æ•—ä¹Ÿè¦æ›´æ–°ï¼‰
                if progress_monitor is not None:
                    progress_monitor.batch_completed(
                        batch_idx=task_idx, completed_tasks_in_batch=1
                    )

        # å®Œæˆé€²åº¦ç›£æ§
        if progress_monitor is not None:
            progress_monitor.finish()

        console.print(
            Panel(
                f"ä¸²è¡Œè™•ç†å®Œæˆï¼Œç¸½å…±è¿”å› {len(results)} å€‹çµæœ",
                title=Text("ğŸ‘¨â€ğŸ’» äº¤æ˜“å›æ¸¬ Backtester", style="bold #8f1511"),
                border_style="#dbac30",
            )
        )

        return results

    def _generate_single_result(
        self,
        task_idx: int,
        entry_signal: np.ndarray,
        exit_signal: np.ndarray,
        position: np.ndarray,
        returns: np.ndarray,
        trade_actions: np.ndarray,
        equity_values: np.ndarray,
        predictor: str,
        backtest_id: str,
        entry_params: List,
        exit_params: List,
        trading_params: Dict,
    ) -> Dict:
        """ç”Ÿæˆå–®å€‹ä»»å‹™çš„çµæœ - æ”¹ç‚ºèª¿ç”¨ TradeSimulator"""

        # å‰µå»º TradeSimulator å¯¦ä¾‹
        simulator = TradeSimulator_backtester(
            self.data,
            pd.Series(entry_signal),
            pd.Series(exit_signal),
            trading_params.get("transaction_cost", 0.001),
            trading_params.get("slippage", 0.0005),
            trading_params.get("trade_delay", 0),
            trading_params.get("trade_price", "close"),
            backtest_id,
            None,  # parameter_set_id
            predictor,
            1.0,  # initial_equity
            None,  # indicators
            self.symbol,  # trading_instrument
        )

        # èª¿ç”¨ TradeSimulator çš„ generate_single_result æ–¹æ³•
        result = simulator.generate_single_result(
            task_idx,
            entry_signal,
            exit_signal,
            position,
            returns,
            trade_actions,
            equity_values,
            predictor,
            backtest_id,
            entry_params,
            exit_params,
            trading_params,
        )

        return result

    # åƒæ•¸è½‰æ›æ–¹æ³•å·²ç§»æ¤åˆ° TradeSimulator ä¸­

    def _vectorized_generate_signals(  # pylint: disable=too-complex
        self, params_list: List[List[Any]], predictors: List[str]
    ) -> np.ndarray:
        """çœŸæ­£çš„å‘é‡åŒ–ç”Ÿæˆä¿¡è™Ÿ - æ‰¹é‡è¨ˆç®—æŒ‡æ¨™ï¼Œåªç”Ÿæˆç´”ç²¹çš„ +1/-1/0 ä¿¡è™Ÿ"""

        n_tasks = len(params_list)

        # è¨ˆç®—æœ€å¤§æŒ‡æ¨™æ•¸é‡
        n_indicators = 0
        for params in params_list:
            if isinstance(params, list):
                n_indicators = max(n_indicators, len(params))
            else:
                # å¦‚æœ params ä¸æ˜¯åˆ—è¡¨ï¼Œèªªæ˜åªæœ‰ä¸€å€‹æŒ‡æ¨™
                n_indicators = max(n_indicators, 1)

        # ç¢ºä¿è‡³å°‘æœ‰1å€‹æŒ‡æ¨™
        n_indicators = max(n_indicators, 1)

        n_time = len(self.data)

        # åˆå§‹åŒ–ä¿¡è™ŸçŸ©é™£
        signals_matrix = np.zeros((n_time, n_tasks, n_indicators))

        # åˆå§‹åŒ–å…¨å±€å¿«å–
        global_ma_cache: Dict[str, Any] = {}
        global_boll_cache: Dict[str, Any] = {}
        global_hl_cache: Dict[str, Any] = {}
        global_value_cache: Dict[str, Any] = {}
        global_percentile_cache: Dict[str, Any] = {}

        # æŒ‰æŒ‡æ¨™é¡å‹åˆ†çµ„ä»»å‹™
        indicator_groups: Dict[str, List[Any]] = {}
        for task_idx, params in enumerate(params_list):
            # ç¢ºä¿ params æ˜¯åˆ—è¡¨æ ¼å¼
            if not isinstance(params, list):
                params = [params]  # å–®å€‹æŒ‡æ¨™è½‰æ›ç‚ºåˆ—è¡¨

            for indicator_idx, param in enumerate(params):
                if param is None:
                    continue

                # å‰µå»ºæŒ‡æ¨™åˆ†çµ„éµ
                indicator_key = (param.indicator_type, predictors[task_idx])
                if indicator_key not in indicator_groups:
                    indicator_groups[indicator_key] = []
                indicator_groups[indicator_key].append((task_idx, indicator_idx, param))

        # æ‰¹é‡è¨ˆç®—æ¯ç¨®æŒ‡æ¨™é¡å‹
        for (indicator_type, predictor), tasks in indicator_groups.items():
            try:
                # æ‰¹é‡ç”Ÿæˆä¿¡è™Ÿ
                if indicator_type == "MA":
                    # ä½¿ç”¨MovingAverage_Indicator_backtesterçš„å‘é‡åŒ–æ–¹æ³•
                    from .MovingAverage_Indicator_backtester import (
                        MovingAverageIndicator,
                    )

                    MovingAverageIndicator.vectorized_calculate_ma_signals(
                        tasks, predictor, signals_matrix, global_ma_cache, self.data
                    )
                elif indicator_type == "BOLL":
                    BollingerBandIndicator.vectorized_calculate_boll_signals(
                        tasks, predictor, signals_matrix, global_boll_cache, self.data
                    )
                elif indicator_type == "HL":
                    HLIndicator.vectorized_calculate_hl_signals(
                        tasks, predictor, signals_matrix, global_hl_cache, self.data
                    )
                elif indicator_type == "VALUE":
                    VALUEIndicator.vectorized_calculate_value_signals(
                        tasks, predictor, signals_matrix, global_value_cache, self.data
                    )

                elif indicator_type == "PERC":
                    # Use Percentile_Indicator_backtester's vectorized method
                    from .Percentile_Indicator_backtester import PercentileIndicator

                    PercentileIndicator.vectorized_calculate_percentile_signals(
                        tasks,
                        predictor,
                        signals_matrix,
                        global_percentile_cache,
                        self.data,
                    )
                else:
                    # å…¶ä»–æŒ‡æ¨™é¡å‹ä½¿ç”¨åŸæœ‰æ–¹æ³•
                    for task_idx, indicator_idx, param in tasks:
                        try:
                            signal = self.indicators.calculate_signals(
                                param.indicator_type, self.data, param, predictor
                            )

                            if isinstance(signal, pd.DataFrame):
                                signal = signal.iloc[:, 0]

                            signal_array = signal.values.astype(np.float64)
                            signal_array = np.nan_to_num(signal_array, nan=0.0)
                            signals_matrix[:, task_idx, indicator_idx] = signal_array

                        except Exception as e:
                            self.logger.warning(f"ä¿¡è™Ÿç”Ÿæˆå¤±æ•—: {e}")
                            signals_matrix[:, task_idx, indicator_idx] = 0
            except Exception as e:
                self.logger.warning(f"æ‰¹é‡è¨ˆç®— {indicator_type} æŒ‡æ¨™å¤±æ•—: {e}")
                # ç‚ºè©²æŒ‡æ¨™é¡å‹çš„æ‰€æœ‰ä»»å‹™è¨­ç½®é›¶ä¿¡è™Ÿ
                for task_idx, indicator_idx, param in tasks:
                    signals_matrix[:, task_idx, indicator_idx] = 0

        # å¼·åˆ¶åƒåœ¾å›æ”¶
        import gc

        gc.collect()

        return signals_matrix

    def _vectorized_combine_signals(  # pylint: disable=too-complex
        self, signals_matrix: np.ndarray, is_exit_signals: bool = False
    ) -> np.ndarray:
        """å‘é‡åŒ–åˆä½µä¿¡è™Ÿ"""
        if NUMBA_AVAILABLE:
            return _vectorized_combine_signals_njit(signals_matrix, is_exit_signals)
        else:
            # å‚™ç”¨å¯¦ç¾
            n_time, n_tasks, n_indicators = signals_matrix.shape
            result = np.zeros((n_time, n_tasks))

            for t in range(n_time):
                for s in range(n_tasks):
                    all_long = True
                    all_short = True

                    for i in range(n_indicators):
                        if signals_matrix[t, s, i] != 1.0:
                            all_long = False
                        if signals_matrix[t, s, i] != -1.0:
                            all_short = False

                    if is_exit_signals:
                        # å¹³å€‰ä¿¡è™Ÿï¼š1 = å¹³å¤šï¼Œ-1 = å¹³ç©º
                        if all_long:  # æ‰€æœ‰ä¿¡è™Ÿéƒ½æ˜¯1
                            result[t, s] = 1.0  # å¹³å¤š
                        elif all_short:  # æ‰€æœ‰ä¿¡è™Ÿéƒ½æ˜¯-1
                            result[t, s] = -1.0  # å¹³ç©º
                    else:
                        # é–‹å€‰ä¿¡è™Ÿï¼š1 = é–‹å¤šï¼Œ-1 = é–‹ç©º
                        if all_long:  # æ‰€æœ‰ä¿¡è™Ÿéƒ½æ˜¯1
                            result[t, s] = 1.0  # é–‹å¤š
                        elif all_short:  # æ‰€æœ‰ä¿¡è™Ÿéƒ½æ˜¯-1
                            result[t, s] = -1.0  # é–‹ç©º

            return result

    def _vectorized_trade_simulation(
        self,
        entry_signals: np.ndarray,
        exit_signals: np.ndarray,
        predictors: List[str],
        backtest_ids: List[str],
        entry_params_list: List[List],
        exit_params_list: List[List],
        trading_params: Dict,
    ) -> List[Dict]:
        """å‘é‡åŒ–äº¤æ˜“æ¨¡æ“¬"""
        n_time, n_tasks = entry_signals.shape
        results = []

        # è¨ˆç®—åƒ¹æ ¼æ”¶ç›Š
        price_returns = self.data["Close"].pct_change().fillna(0).values

        # é©—è­‰äº¤æ˜“åƒæ•¸
        required_params = [
            "transaction_cost",
            "slippage",
            "trade_price",
            "trade_delay",
        ]
        missing_params = [
            param for param in required_params if param not in trading_params
        ]
        if missing_params:
            raise ValueError(f"ç¼ºå°‘äº¤æ˜“åƒæ•¸: {', '.join(missing_params)}")

        # å–å¾—åƒ¹æ ¼è³‡æ–™
        if "Close" not in self.data.columns:
            raise ValueError("æ•¸æ“šç¼ºå°‘ Close æ¬„ä½ï¼Œç„¡æ³•åŸ·è¡Œäº¤æ˜“æ¨¡æ“¬")
        if "Open" not in self.data.columns:
            raise ValueError("æ•¸æ“šç¼ºå°‘ Open æ¬„ä½ï¼Œç„¡æ³•åŸ·è¡Œäº¤æ˜“æ¨¡æ“¬")

        close_prices = self.data["Close"].values.astype(np.float64)
        open_prices = self.data["Open"].values.astype(np.float64)

        # å‘é‡åŒ–äº¤æ˜“æ¨¡æ“¬
        if NUMBA_AVAILABLE:
            positions, returns, trade_actions, equity_values = (
                _vectorized_trade_simulation_njit(
                    entry_signals,
                    exit_signals,
                    close_prices,
                    open_prices,
                    float(trading_params["transaction_cost"]),
                    float(trading_params["slippage"]),
                    str(trading_params["trade_price"]),
                    int(trading_params["trade_delay"]),
                )
            )
        else:
            # å‚™ç”¨å¯¦ç¾
            positions, returns, trade_actions, equity_values = (
                self._fallback_trade_simulation(
                    entry_signals,
                    exit_signals,
                    price_returns,
                    trading_params,
                )
            )

        # ç‚ºæ¯å€‹ä»»å‹™ç”Ÿæˆçµæœ
        for task_idx in range(n_tasks):
            result = self._generate_single_result(
                task_idx,
                entry_signals[:, task_idx],
                exit_signals[:, task_idx],
                positions[:, task_idx],
                returns[:, task_idx],
                trade_actions[:, task_idx],
                equity_values[:, task_idx],
                predictors[task_idx],
                backtest_ids[task_idx],
                entry_params_list[task_idx],
                exit_params_list[task_idx],
                trading_params,
            )
            results.append(result)

        return results

    # å‚™ç”¨äº¤æ˜“æ¨¡æ“¬å¯¦ç¾å·²ç§»æ¤åˆ° TradeSimulator ä¸­

    def _parse_strategy_id(self, strategy_id: str) -> int:
        """è§£æç­–ç•¥ID"""
        try:
            if strategy_id.startswith("strategy_"):
                return int(strategy_id.split("_")[1]) - 1
            else:
                return 0
        except (IndexError, ValueError):
            return 0

    # åƒæ•¸é›†IDç”Ÿæˆæ–¹æ³•å·²ç§»æ¤åˆ° TradeSimulator ä¸­

    def _convert_params_to_dict(  # pylint: disable=too-complex
        self, entry_params: List[Any], exit_params: List[Any]
    ) -> Dict[str, Any]:
        """å°‡åƒæ•¸åˆ—è¡¨è½‰æ›ç‚ºå­—å…¸æ ¼å¼"""

        def param_to_dict(param: Any) -> Dict[str, Any]:
            if param is None:
                return {}

            result = {"indicator_type": param.indicator_type}
            # åªå…è¨±ç‰¹å®šåƒæ•¸é€²å…¥å­—å…¸ï¼Œéæ¿¾å¤šé¤˜æ¬„ä½
            if param.indicator_type == "MA":
                for key in [
                    "period",
                    "ma_type",
                    "strat_idx",
                    "shortMA_period",
                    "longMA_period",
                    "mode",
                    "m",
                ]:
                    if key in param.params:
                        result[key] = param.params[key]
            elif param.indicator_type == "BOLL":
                for key in ["ma_length", "std_multiplier", "strat_idx"]:
                    if key in param.params:
                        result[key] = param.params[key]
            elif param.indicator_type == "HL":
                for key in ["n_length", "m_length", "strat_idx"]:
                    if key in param.params:
                        result[key] = param.params[key]
            elif param.indicator_type == "VALUE":
                for key in ["n_length", "m_value", "m1_value", "m2_value", "strat_idx"]:
                    if key in param.params:
                        result[key] = param.params[key]
            else:
                # å…¶ä»–æŒ‡æ¨™é¡å‹ï¼Œä¿ç•™æ‰€æœ‰åƒæ•¸
                for key, value in param.params.items():
                    result[key] = value
            return result

        return {
            "entry": [param_to_dict(param) for param in entry_params],
            "exit": [param_to_dict(param) for param in exit_params],
        }

    def _convert_combo_to_dict(self, combo: Tuple, strategy_idx: int) -> Dict:
        """å°‡comboè½‰æ›ç‚ºå­—å…¸æ ¼å¼"""
        # è§£æcomboçµæ§‹ï¼šentry_params + exit_params + strategy_id
        # é€™è£¡éœ€è¦æ ¹æ“šå¯¦éš›çš„åƒæ•¸çµæ§‹ä¾†è§£æ
        try:
            # å‡è¨­comboçš„çµæ§‹æ˜¯ (entry_params, exit_params, strategy_id)
            # å¯¦éš›çµæ§‹éœ€è¦æ ¹æ“šgenerate_parameter_combinationsçš„è¼¸å‡ºèª¿æ•´
            return {
                "strategy_idx": strategy_idx,
                "entry_params": combo[:-1],  # é™¤äº†æœ€å¾Œä¸€å€‹strategy_id
                "exit_params": [],  # éœ€è¦æ ¹æ“šå¯¦éš›çµæ§‹èª¿æ•´
                "combo": combo,
            }
        except Exception:
            return {"strategy_idx": strategy_idx, "combo": combo}
