# pylint: disable=too-many-lines
"""
DataLoader_autorunner.py

ã€åŠŸèƒ½èªªæ˜ã€‘
------------------------------------------------------------
æœ¬æ¨¡çµ„è² è²¬æ•¸æ“šè¼‰å…¥åŠŸèƒ½ï¼Œç›´æ¥ä½¿ç”¨åŸç‰ˆ dataloader æ¨¡çµ„ï¼Œ
æ ¹æ“šé…ç½®æ–‡ä»¶è‡ªå‹•è¼‰å…¥æ•¸æ“šï¼Œç„¡éœ€ç”¨æˆ¶äº’å‹•è¼¸å…¥ã€‚

ã€æµç¨‹èˆ‡æ•¸æ“šæµã€‘
------------------------------------------------------------
- ä¸»æµç¨‹ï¼šè®€å–é…ç½® â†’ èª¿ç”¨åŸç‰ˆ dataloader â†’ è¿”å›æ•¸æ“š
- æ•¸æ“šæµï¼šé…ç½®æ•¸æ“š â†’ åŸç‰ˆè¼‰å…¥å™¨ â†’ æ¨™æº–åŒ–æ•¸æ“š

ã€ç¶­è­·èˆ‡æ“´å……é‡é»ã€‘
------------------------------------------------------------
- ç›´æ¥ä½¿ç”¨åŸç‰ˆ dataloader æ¨¡çµ„ï¼Œé¿å…é‡è¤‡å¯¦ç¾
- è‹¥ dataloader ä»‹é¢æœ‰è®Šå‹•ï¼Œéœ€åŒæ­¥æ›´æ–°èª¿ç”¨é‚è¼¯
- æ–°å¢/ä¿®æ”¹æ•¸æ“šè™•ç†æ™‚ï¼Œå„ªå…ˆè€ƒæ…®åœ¨åŸç‰ˆ dataloader ä¸­å¯¦ç¾

ã€å¸¸è¦‹æ˜“éŒ¯é»ã€‘
------------------------------------------------------------
- æ•¸æ“šæºé…ç½®éŒ¯èª¤å°è‡´è¼‰å…¥å¤±æ•—
- é æ¸¬å› å­è™•ç†éŒ¯èª¤å°è‡´æ•¸æ“šä¸å®Œæ•´
- æ•¸æ“šæ ¼å¼ä¸çµ±ä¸€å°è‡´å¾ŒçºŒè™•ç†å¤±æ•—

ã€ç¯„ä¾‹ã€‘
------------------------------------------------------------
- è¼‰å…¥æ•¸æ“šï¼šloader.load_data(config) -> DataFrame
- ç²å–è¼‰å…¥æ‘˜è¦ï¼šloader.get_loading_summary() -> dict

ã€èˆ‡å…¶ä»–æ¨¡çµ„çš„é—œè¯ã€‘
------------------------------------------------------------
- è¢« Base_autorunner èª¿ç”¨ï¼Œæä¾›æ•¸æ“šè¼‰å…¥åŠŸèƒ½
- ç›´æ¥èª¿ç”¨åŸç‰ˆ dataloader æ¨¡çµ„é€²è¡Œå¯¦éš›æ•¸æ“šè¼‰å…¥
- ç‚º BacktestRunner æä¾›æ¨™æº–åŒ–æ•¸æ“š

ã€ç‰ˆæœ¬èˆ‡è®Šæ›´è¨˜éŒ„ã€‘
------------------------------------------------------------
- v1.0: åˆå§‹ç‰ˆæœ¬ï¼ŒåŸºæœ¬è¼‰å…¥åŠŸèƒ½
- v1.1: æ–°å¢é æ¸¬å› å­è™•ç†
- v1.2: æ–°å¢ Rich Panel é¡¯ç¤ºå’Œèª¿è©¦è¼¸å‡º
- v2.0: é‡æ§‹ç‚ºç›´æ¥ä½¿ç”¨åŸç‰ˆ dataloader æ¨¡çµ„ï¼Œé¿å…é‡è¤‡å¯¦ç¾

ã€åƒè€ƒã€‘
------------------------------------------------------------
- autorunner/DEVELOPMENT_PLAN.md
- Development_Guideline.md
- Base_autorunner.py
- dataloader/base_loader.py
"""

import logging
import traceback
from pathlib import Path
from typing import Any, Dict, Optional, Tuple

import pandas as pd

from rich.table import Table
from rich.text import Text

from autorunner.utils import get_console
from utils import show_error, show_info, show_step_panel, show_success, show_warning

console = get_console()


class DataLoaderAutorunner:
    """
    æ•¸æ“šè¼‰å…¥å°è£å™¨

    ç›´æ¥ä½¿ç”¨åŸç‰ˆ dataloader æ¨¡çµ„ï¼Œæ ¹æ“šé…ç½®æ–‡ä»¶è‡ªå‹•è¼‰å…¥æ•¸æ“šï¼Œ
    ç„¡éœ€ç”¨æˆ¶äº’å‹•è¼¸å…¥ï¼Œæä¾›æ¨™æº–åŒ–çš„æ•¸æ“šè¼‰å…¥ä»‹é¢ã€‚
    """

    def __init__(self, logger: Optional[logging.Logger] = None):
        """
        åˆå§‹åŒ– DataLoaderAutorunner

        Args:
            logger: æ—¥èªŒè¨˜éŒ„å™¨
        """

        self.logger = logger or logging.getLogger("DataLoaderAutorunner")
        self.data: Optional[pd.DataFrame] = None
        self.frequency: Optional[str] = None
        self.source: Optional[str] = None
        self.loading_summary: Dict[str, Any] = {}
        self.current_predictor_column: Optional[str] = None
        self.using_price_predictor_only: bool = False
        
        # å‰µå»ºä¸€å€‹ FileLoader å¯¦ä¾‹ä¾†èª¿ç”¨åŸç‰ˆ dataloader çš„æ–¹æ³•
        from dataloader.file_loader import FileLoader
        self._loader_helper = FileLoader()

    def _validate_and_get_end_date(self, config: Dict[str, Any]) -> str:
        """
        é©—è­‰ä¸¦ç²å–çµæŸæ—¥æœŸ
        
        Args:
            config: æ•¸æ“šè¼‰å…¥é…ç½®
            
        Returns:
            str: æœ‰æ•ˆçš„çµæŸæ—¥æœŸï¼ˆYYYY-MM-DDæ ¼å¼ï¼‰ï¼Œå¦‚æœç„¡æ•ˆå‰‡è¿”å›ä»Šå¤©çš„æ—¥æœŸ
        """
        import re
        from datetime import datetime
        
        end_date = config.get("end_date")
        
        # å¦‚æœæ²’æœ‰ end_date æˆ–ç‚ºç©ºå­—ç¬¦ä¸²æˆ–ç‚º "/"ï¼Œä½¿ç”¨ä»Šå¤©
        if not end_date or end_date == "/" or end_date.strip() == "":
            return datetime.now().strftime("%Y-%m-%d")
        
        # é©—è­‰æ—¥æœŸæ ¼å¼æ˜¯å¦ç‚º YYYY-MM-DD
        if re.match(r"^\d{4}-\d{2}-\d{2}$", str(end_date)):
            return str(end_date)
        else:
            # æ ¼å¼ç„¡æ•ˆï¼Œä½¿ç”¨ä»Šå¤©
            self.logger.warning(
                f"end_date æ ¼å¼ç„¡æ•ˆ: {end_date}ï¼Œæ‡‰ç‚º YYYY-MM-DD æ ¼å¼ï¼Œå°‡ä½¿ç”¨ä»Šå¤©çš„æ—¥æœŸ"
            )
            return datetime.now().strftime("%Y-%m-%d")

    def load_data(self, config: Dict[str, Any]) -> Optional[pd.DataFrame]:
        """
        æ ¹æ“šé…ç½®è¼‰å…¥æ•¸æ“š - ç›´æ¥ä½¿ç”¨åŸç‰ˆ dataloader æ¨¡çµ„

        Args:
            config: æ•¸æ“šè¼‰å…¥é…ç½®

        Returns:
            Optional[pd.DataFrame]: è¼‰å…¥çš„æ•¸æ“šï¼Œå¦‚æœè¼‰å…¥å¤±æ•—å‰‡è¿”å› None
        """

        try:
            
            # æ ¹æ“šé…ç½®é¸æ“‡è¼‰å…¥å™¨
            source = config.get("source", "yfinance")
            
            # ç›´æ¥ä½¿ç”¨åŸç‰ˆ dataloader æ¨¡çµ„ï¼Œä¸¦è¨­ç½®é…ç½®åƒæ•¸
            if source == "yfinance":
                from dataloader.yfinance_loader import YahooFinanceLoader
                loader = YahooFinanceLoader()
                # è¨­ç½®é…ç½®åƒæ•¸
                yfinance_config = config.get("yfinance_config", {})
                loader.symbol = yfinance_config.get("symbol", "AAPL")
                loader.interval = yfinance_config.get("interval", "1d")
                loader.start_date = config.get("start_date", "2020-01-01")
                # é©—è­‰ä¸¦ç²å– end_date
                loader.end_date = self._validate_and_get_end_date(config)
                
            elif source == "binance":
                from dataloader.binance_loader import BinanceLoader
                loader = BinanceLoader()
                # è¨­ç½®é…ç½®åƒæ•¸
                binance_config = config.get("binance_config", {})
                loader.symbol = binance_config.get("symbol", "BTCUSDT")
                loader.interval = binance_config.get("interval", "1d")
                loader.start_date = config.get("start_date", "2020-01-01")
                # é©—è­‰ä¸¦ç²å– end_date
                loader.end_date = self._validate_and_get_end_date(config)
                
            elif source == "coinbase":
                from dataloader.coinbase_loader import CoinbaseLoader
                loader = CoinbaseLoader()
                # è¨­ç½®é…ç½®åƒæ•¸
                coinbase_config = config.get("coinbase_config", {})
                loader.symbol = coinbase_config.get("symbol", "BTC-USD")
                loader.start_date = config.get("start_date", "2020-01-01")
                # é©—è­‰ä¸¦ç²å– end_date
                loader.end_date = self._validate_and_get_end_date(config)
                
            elif source == "file":
                from dataloader.file_loader import FileLoader
                loader = FileLoader()
                # è¨­ç½®é…ç½®åƒæ•¸
                file_config = config.get("file_config", {})
                loader.file_path = file_config.get("file_path", "")
                loader.time_column = file_config.get("time_column", "Time")
                loader.open_column = file_config.get("open_column", "Open")
                loader.high_column = file_config.get("high_column", "High")
                loader.low_column = file_config.get("low_column", "Low")
                loader.close_column = file_config.get("close_column", "Close")
                loader.volume_column = file_config.get("volume_column", "Volume")
                
            else:
                console.print(
show_error("AUTORUNNER", f"ä¸æ”¯æ´çš„æ•¸æ“šæº: {source}")
                )
                return None
            
            # ä½¿ç”¨åŸç‰ˆè¼‰å…¥é‚è¼¯
            data, frequency = loader.load()
            
            if data is None:
                show_error("AUTORUNNER", "æ•¸æ“šè¼‰å…¥å¤±æ•—")
                return None
            
            # è¨­ç½®å±¬æ€§
            self.data = data
            self.frequency = frequency
            self.source = source
            
            # è™•ç†æ”¶ç›Šç‡è¨ˆç®—ï¼ˆå¦‚æœé…ç½®éœ€è¦ï¼‰
            if config.get("returns_config", {}).get("calculate_returns", False):
                self.data = self._calculate_returns(config)
            
            # è™•ç†é æ¸¬å› å­ï¼ˆå¦‚æœé…ç½®éœ€è¦ï¼‰
            predictor_config = config.get("predictor_config", {})
            skip_predictor = predictor_config.get("skip_predictor", False)
            
            if skip_predictor:
                # ä½¿ç”¨åƒ¹æ ¼æ•¸æ“šï¼ˆcloseï¼‰ä½œç‚ºé æ¸¬å› å­
                if "Close" in self.data.columns:
                    self.data["X"] = self.data["Close"].copy()
                    self.current_predictor_column = "X"
                else:
                    show_error("AUTORUNNER", "æ•¸æ“šä¸­æ‰¾ä¸åˆ° Close æ¬„ä½")
            else:
                # è¼‰å…¥é æ¸¬å› å­
                self.data = self._load_predictor_data(config)
            
            # è™•ç†å·®åˆ†ï¼ˆå¦‚æœé…ç½®éœ€è¦ï¼‰
            if config.get("difference_config", {}).get("enable_difference", False):
                self.data = self._process_difference(config)
            
            # æ›´æ–°è¼‰å…¥æ‘˜è¦
            self._update_loading_summary(config)
            
            return self.data

        except Exception as e:
            show_error("AUTORUNNER", f"æ•¸æ“šè¼‰å…¥å¤±æ•—: {e}\n\nè©³ç´°éŒ¯èª¤:\n{traceback.format_exc()}")
            self._display_error(f"æ•¸æ“šè¼‰å…¥å¤±æ•—: {e}")
            return None


    def _load_predictor_data(self, config: Dict[str, Any]) -> Optional[pd.DataFrame]:
        """è¼‰å…¥é æ¸¬å› å­æ•¸æ“š - ä½¿ç”¨ config ä¸­çš„è¨­ç½®"""
        try:
            predictor_config = config.get("predictor_config", {})
            predictor_path = predictor_config.get("predictor_path", "")
            predictor_column = predictor_config.get("predictor_column", "X")
            
            if not predictor_path:
                show_warning("AUTORUNNER", "é æ¸¬å› å­è·¯å¾‘ç‚ºç©ºï¼Œä½¿ç”¨åƒ¹æ ¼æ•¸æ“š")
                self.data["X"] = self.data["Close"].copy()
                self.current_predictor_column = "X"
                return self.data
            
            # é©—è­‰é æ¸¬å› å­æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            predictor_path_obj = Path(predictor_path)
            if not predictor_path_obj.is_absolute():
                project_root = Path(__file__).parent.parent
                predictor_path_obj = project_root / predictor_path
            
            if not predictor_path_obj.exists():
                show_warning("AUTORUNNER", f"é æ¸¬å› å­æ–‡ä»¶ä¸å­˜åœ¨: {predictor_path_obj}\nâš ï¸ ä½¿ç”¨åƒ¹æ ¼æ•¸æ“šä½œç‚ºé æ¸¬å› å­")
                self.data["X"] = self.data["Close"].copy()
                self.current_predictor_column = "X"
                return self.data
            
            # è®€å–é æ¸¬å› å­æ–‡ä»¶
            if predictor_path_obj.suffix.lower() in [".xlsx", ".xls"]:
                predictor_df = pd.read_excel(predictor_path_obj)
            elif predictor_path_obj.suffix.lower() == ".csv":
                predictor_df = pd.read_csv(predictor_path_obj)
            else:
                show_error("AUTORUNNER", f"ä¸æ”¯æ´çš„é æ¸¬å› å­æ–‡ä»¶æ ¼å¼: {predictor_path_obj.suffix}")
                self.data["X"] = self.data["Close"].copy()
                self.current_predictor_column = "X"
                return self.data
            
            # è­˜åˆ¥æ™‚é–“æ¬„ä½
            time_column = predictor_config.get("time_column")
            if not time_column or time_column not in predictor_df.columns:
                # è‡ªå‹•è­˜åˆ¥æ™‚é–“æ¬„ä½ï¼ˆä¸å€åˆ†å¤§å°å¯«ï¼‰
                time_candidates = ["time", "date", "timestamp", "datetime", "period"]
                for col in predictor_df.columns:
                    if col.lower() in time_candidates:
                        time_column = col
                        break
            
            if not time_column or time_column not in predictor_df.columns:
                show_error("AUTORUNNER", "ç„¡æ³•è­˜åˆ¥é æ¸¬å› å­æ–‡ä»¶ä¸­çš„æ™‚é–“æ¬„ä½")
                self.data["X"] = self.data["Close"].copy()
                self.current_predictor_column = "X"
                return self.data
            
            # æª¢æŸ¥é æ¸¬å› å­æ¬„ä½æ˜¯å¦å­˜åœ¨
            if predictor_column not in predictor_df.columns:
                show_error("AUTORUNNER", f"é æ¸¬å› å­æ¬„ä½ {predictor_column} ä¸å­˜åœ¨æ–¼æ–‡ä»¶ä¸­\n\nå¯ç”¨æ¬„ä½: {list(predictor_df.columns)}")
                self.data["X"] = self.data["Close"].copy()
                self.current_predictor_column = "X"
                return self.data
            
            # åªä¿ç•™æ™‚é–“å’Œé æ¸¬å› å­æ¬„ä½
            predictor_df = predictor_df[[time_column, predictor_column]].copy()
            
            # æª¢æ¸¬ä¸¦è½‰æ›timestampæ ¼å¼ - èª¿ç”¨åŸç‰ˆ dataloader æ–¹æ³•
            predictor_df = self._loader_helper.detect_and_convert_timestamp(predictor_df, time_column)
            
            # è½‰æ›æ™‚é–“æ ¼å¼
            time_format = predictor_config.get("time_format")
            # å¦‚æœå·²ç¶“æ˜¯datetimeæ ¼å¼ï¼Œè·³éè½‰æ›
            if not pd.api.types.is_datetime64_any_dtype(predictor_df[time_column]):
                if time_format:
                    try:
                        predictor_df[time_column] = pd.to_datetime(predictor_df[time_column], format=time_format)
                    except Exception as e:
                        show_warning("AUTORUNNER", f"æ™‚é–“æ ¼å¼è½‰æ›å¤±æ•—: {e}ï¼Œå˜—è©¦è‡ªå‹•æ¨æ–·")
                        predictor_df[time_column] = pd.to_datetime(predictor_df[time_column])
                else:
                    predictor_df[time_column] = pd.to_datetime(predictor_df[time_column])
            
            # è¨­ç½®æ™‚é–“ç‚ºç´¢å¼•
            predictor_df = predictor_df.set_index(time_column)
            
            # åˆä½µé æ¸¬å› å­å’Œåƒ¹æ ¼æ•¸æ“š
            # ç¢ºä¿åƒ¹æ ¼æ•¸æ“šçš„ Time ç‚ºç´¢å¼•
            if "Time" in self.data.columns:
                price_df = self.data.set_index("Time")
            else:
                price_df = self.data
            
            # åˆä½µæ•¸æ“š
            merged_df = price_df.merge(predictor_df, left_index=True, right_index=True, how="inner")
            
            if merged_df.empty:
                show_warning("AUTORUNNER", "åƒ¹æ ¼æ•¸æ“šèˆ‡é æ¸¬å› å­æ•¸æ“šç„¡æ™‚é–“äº¤é›†ï¼Œä½¿ç”¨åƒ¹æ ¼æ•¸æ“š")
                self.data["X"] = self.data["Close"].copy()
                self.current_predictor_column = "X"
                return self.data
            
            # é‡ç½®ç´¢å¼•
            merged_df = merged_df.reset_index()
            merged_df = merged_df.rename(columns={"index": "Time"})
            
            # é¡¯ç¤ºåˆä½µæˆåŠŸä¿¡æ¯ï¼ˆä½¿ç”¨åŸç‰ˆæ¨£å¼ï¼‰
            show_success("DATALOADER", f"åˆä½µæ•¸æ“šæˆåŠŸï¼Œè¡Œæ•¸ï¼š{len(merged_df)}")
            
            # autorunner é¡å¤–é¡¯ç¤ºé æ¸¬å› å­æ¬„ä½ä¿¡æ¯
            show_info("DATALOADER", f"ğŸ“Š ä½¿ç”¨é æ¸¬å› å­æ¬„ä½: {predictor_column}")
            
            self.current_predictor_column = predictor_column
            return merged_df
            
        except Exception as e:
            show_error("AUTORUNNER", f"é æ¸¬å› å­è¼‰å…¥å¤±æ•—: {e}\n\nè©³ç´°éŒ¯èª¤:\n{traceback.format_exc()}")
            self.data["X"] = self.data["Close"].copy()
            self.current_predictor_column = "X"
            return self.data

    def _calculate_returns(self, config: Dict[str, Any]) -> pd.DataFrame:
        """è¨ˆç®—æ”¶ç›Šç‡ - ç›´æ¥ä½¿ç”¨åŸç‰ˆ dataloader"""
        try:
            from dataloader.calculator_loader import ReturnCalculator
            
            calculator = ReturnCalculator(self.data)
            return calculator.calculate_returns()
            
        except Exception as e:
            show_error("AUTORUNNER", f"æ”¶ç›Šç‡è¨ˆç®—å¤±æ•—: {e}")
            return self.data

    def _process_difference(self, config: Dict[str, Any]) -> pd.DataFrame:
        """è™•ç†å·®åˆ† - ç›´æ¥ä½¿ç”¨åŸç‰ˆ dataloader"""
        try:
            from dataloader.predictor_loader import PredictorLoader
            
            predictor_config = config.get("predictor_config", {})
            selected_predictor = predictor_config.get("predictor_column", "aggregated")
            
            predictor_loader = PredictorLoader(self.data)
            data_with_difference, _, _ = predictor_loader.process_difference(
                self.data, selected_predictor
            )
            
            return data_with_difference
            
        except Exception as e:
            show_error("AUTORUNNER", f"å·®åˆ†è™•ç†å¤±æ•—: {e}")
            return self.data

    def _update_loading_summary(self, config: Dict[str, Any]) -> None:
        """æ›´æ–°è¼‰å…¥æ‘˜è¦"""

        self.loading_summary = {
            "source": self.source,
            "frequency": self.frequency,
            "data_shape": self.data.shape if self.data is not None else (0, 0),
            "columns": list(self.data.columns) if self.data is not None else [],
            "date_range": self._get_date_range(),
            "config_used": {
                "source": config.get("source"),
                "start_date": config.get("start_date"),
                "end_date": config.get("end_date"),
            },
        }

    def _get_date_range(self) -> Tuple[str, str]:
        """ç²å–æ•¸æ“šæ—¥æœŸç¯„åœ"""
        if self.data is None or "Time" not in self.data.columns:
            return "N/A", "N/A"

        try:
            start_date = self.data["Time"].min().strftime("%Y-%m-%d")
            end_date = self.data["Time"].max().strftime("%Y-%m-%d")
            return start_date, end_date
        except Exception:
            return "N/A", "N/A"

    def get_loading_summary(self) -> Dict[str, Any]:
        """
        ç²å–è¼‰å…¥æ‘˜è¦

        Returns:
            Dict[str, Any]: è¼‰å…¥æ‘˜è¦ä¿¡æ¯
        """
        return self.loading_summary.copy()

    def display_loading_summary(self) -> None:
        """é¡¯ç¤ºè¼‰å…¥æ‘˜è¦"""

        if not self.loading_summary:
            show_error("AUTORUNNER", "æ²’æœ‰è¼‰å…¥æ‘˜è¦ä¿¡æ¯")
            return

        # å‰µå»ºæ‘˜è¦è¡¨æ ¼
        table = Table(title="ğŸ“Š æ•¸æ“šè¼‰å…¥æ‘˜è¦")
        table.add_column("é …ç›®", style="cyan")
        table.add_column("å€¼", style="magenta")

        table.add_row("æ•¸æ“šæº", self.loading_summary.get("source", "N/A"))
        table.add_row("é »ç‡", self.loading_summary.get("frequency", "N/A"))
        table.add_row(
            "æ•¸æ“šå½¢ç‹€",
            f"{self.loading_summary.get('data_shape', (0, 0))[0]} è¡Œ x {self.loading_summary.get('data_shape', (0, 0))[1]} åˆ—",
        )

        date_range = self.loading_summary.get("date_range", ("N/A", "N/A"))
        table.add_row("æ—¥æœŸç¯„åœ", f"{date_range[0]} è‡³ {date_range[1]}")

        columns = self.loading_summary.get("columns", [])
        table.add_row("æ¬„ä½æ•¸é‡", str(len(columns)))
        table.add_row(
            "ä¸»è¦æ¬„ä½", ", ".join(columns[:5]) + ("..." if len(columns) > 5 else "")
        )

        console.print(table)

        # é¡¯ç¤ºè¼‰å…¥æˆåŠŸä¿¡æ¯
        show_success("DATALOADER", f"æ•¸æ“šè¼‰å…¥æˆåŠŸï¼è¼‰å…¥äº† {self.loading_summary.get('data_shape', (0, 0))[0]} è¡Œæ•¸æ“š")

    def _display_error(self, message: str) -> None:
        """
        é¡¯ç¤ºéŒ¯èª¤ä¿¡æ¯

        Args:
            message: éŒ¯èª¤ä¿¡æ¯
        """

        show_error("AUTORUNNER", message)