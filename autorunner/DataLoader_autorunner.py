# pylint: disable=too-many-lines
"""
DataLoader_autorunner.py

ã€åŠŸèƒ½èªªæ˜ã€‘
------------------------------------------------------------
æœ¬æ¨¡çµ„è² è²¬æ•¸æ“šè¼‰å…¥åŠŸèƒ½ï¼Œå°è£ç¾æœ‰çš„ dataloader æ¨¡çµ„ï¼Œ
æ ¹æ“šé…ç½®æ–‡ä»¶è‡ªå‹•è¼‰å…¥æ•¸æ“šï¼Œç„¡éœ€ç”¨æˆ¶äº’å‹•è¼¸å…¥ã€‚

ã€æµç¨‹èˆ‡æ•¸æ“šæµã€‘
------------------------------------------------------------
- ä¸»æµç¨‹ï¼šè®€å–é…ç½® â†’ é¸æ“‡è¼‰å…¥å™¨ â†’ è¼‰å…¥æ•¸æ“š â†’ è™•ç†é æ¸¬å› å­ â†’ è¿”å›æ•¸æ“š
- æ•¸æ“šæµï¼šé…ç½®æ•¸æ“š â†’ è¼‰å…¥å™¨é¸æ“‡ â†’ åŸå§‹æ•¸æ“š â†’ è™•ç†å¾Œæ•¸æ“š â†’ æ¨™æº–åŒ–æ•¸æ“š

ã€ç¶­è­·èˆ‡æ“´å……é‡é»ã€‘
------------------------------------------------------------
- æ–°å¢æ•¸æ“šæºæ™‚ï¼Œè«‹åŒæ­¥æ›´æ–°è¼‰å…¥å™¨é¸æ“‡é‚è¼¯
- è‹¥ dataloader ä»‹é¢æœ‰è®Šå‹•ï¼Œéœ€åŒæ­¥æ›´æ–°å°è£é‚è¼¯
- æ–°å¢/ä¿®æ”¹æ•¸æ“šè™•ç†ã€é æ¸¬å› å­è™•ç†æ™‚ï¼Œå‹™å¿…åŒæ­¥æ›´æ–°æœ¬æª”æ¡ˆ

ã€å¸¸è¦‹æ˜“éŒ¯é»ã€‘
------------------------------------------------------------
- æ•¸æ“šæºé…ç½®éŒ¯èª¤å°è‡´è¼‰å…¥å¤±æ•—
- é æ¸¬å› å­è™•ç†éŒ¯èª¤å°è‡´æ•¸æ“šä¸å®Œæ•´
- æ•¸æ“šæ ¼å¼ä¸çµ±ä¸€å°è‡´å¾ŒçºŒè™•ç†å¤±æ•—

ã€ç¯„ä¾‹ã€‘
------------------------------------------------------------
- è¼‰å…¥æ•¸æ“šï¼šloader.load_data(config) -> DataFrame
- ç²å–è¼‰å…¥æ‘˜è¦ï¼šloader.get_loading_summary() -> dict

ã€èˆ‡å…¶ä»–æ¨¡çµ„çš„é—œè¯ã€‘
------------------------------------------------------------
- è¢« Base_autorunner èª¿ç”¨ï¼Œæä¾›æ•¸æ“šè¼‰å…¥åŠŸèƒ½
- ä¾è³´ dataloader æ¨¡çµ„é€²è¡Œå¯¦éš›æ•¸æ“šè¼‰å…¥
- ç‚º BacktestRunner æä¾›æ¨™æº–åŒ–æ•¸æ“š

ã€ç‰ˆæœ¬èˆ‡è®Šæ›´è¨˜éŒ„ã€‘
------------------------------------------------------------
- v1.0: åˆå§‹ç‰ˆæœ¬ï¼ŒåŸºæœ¬è¼‰å…¥åŠŸèƒ½
- v1.1: æ–°å¢é æ¸¬å› å­è™•ç†
- v1.2: æ–°å¢ Rich Panel é¡¯ç¤ºå’Œèª¿è©¦è¼¸å‡º

ã€åƒè€ƒã€‘
------------------------------------------------------------
- autorunner/DEVELOPMENT_PLAN.md
- Development_Guideline.md
- Base_autorunner.py
- dataloader/base_loader.py
"""

import logging
import os
import traceback
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, Optional, Tuple

import pandas as pd
import requests

# å°å…¥ dataloader æ¨¡çµ„
from binance.client import Client
from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from rich.text import Text

from dataloader.binance_loader import BinanceLoader
from dataloader.calculator_loader import ReturnCalculator
from dataloader.coinbase_loader import CoinbaseLoader
from dataloader.file_loader import FileLoader
from dataloader.predictor_loader import PredictorLoader
from dataloader.yfinance_loader import YahooFinanceLoader

console = Console()


class DataLoaderAutorunner:
    """
    æ•¸æ“šè¼‰å…¥å°è£å™¨

    å°è£ç¾æœ‰çš„ dataloader æ¨¡çµ„ï¼Œæ ¹æ“šé…ç½®æ–‡ä»¶è‡ªå‹•è¼‰å…¥æ•¸æ“šï¼Œ
    ç„¡éœ€ç”¨æˆ¶äº’å‹•è¼¸å…¥ï¼Œæä¾›æ¨™æº–åŒ–çš„æ•¸æ“šè¼‰å…¥ä»‹é¢ã€‚
    """

    def __init__(self, logger: Optional[logging.Logger] = None):
        """
        åˆå§‹åŒ– DataLoaderAutorunner

        Args:
            logger: æ—¥èªŒè¨˜éŒ„å™¨
        """

        self.logger = logger or logging.getLogger("DataLoaderAutorunner")
        self.data: Optional[pd.DataFrame] = None
        self.frequency: Optional[str] = None
        self.source: Optional[str] = None
        self.loading_summary: Dict[str, Any] = {}
        self.current_predictor_column: Optional[str] = None
        self.using_price_predictor_only: bool = False

    @staticmethod
    def _require_config_field(config: Dict[str, Any], key: str, context: str) -> Any:
        if key not in config:
            raise ValueError(f"{context} ç¼ºå°‘ {key} è¨­å®š")
        value = config[key]
        if isinstance(value, str):
            value = value.strip()
            if value == "":
                raise ValueError(f"{context} çš„ {key} ä¸å¯ç‚ºç©ºå­—ä¸²")
            return value
        if value is None:
            raise ValueError(f"{context} çš„ {key} ä¸å¯ç‚º None")
        return value

    def load_data(self, config: Dict[str, Any]) -> Optional[pd.DataFrame]:
        """
        æ ¹æ“šé…ç½®è¼‰å…¥æ•¸æ“š - åè½‰é †åºï¼šå…ˆè¼‰å…¥é æ¸¬å› å­ï¼Œå†è¼‰å…¥å°æ‡‰æ—¥æœŸçš„åƒ¹æ ¼æ•¸æ“š

        Args:
            config: æ•¸æ“šè¼‰å…¥é…ç½®

        Returns:
            Optional[pd.DataFrame]: è¼‰å…¥çš„æ•¸æ“šï¼Œå¦‚æœè¼‰å…¥å¤±æ•—å‰‡è¿”å› None
        """

        try:
            # æª¢æŸ¥æ˜¯å¦è·³éé æ¸¬å› å­
            if config.get("predictor_config", {}).get("skip_predictor", False):
                return self._handle_skip_predictor_mode(config)

            # è¼‰å…¥é æ¸¬å› å­æ•¸æ“š
            predictor_data = self._load_predictor_data(config)
            if predictor_data is None:
                return self._handle_predictor_load_failure(config)

            # è¼‰å…¥åƒ¹æ ¼æ•¸æ“šä¸¦åˆä½µ
            result_data = self._load_and_merge_data(config, predictor_data)
            if result_data is None:
                return None

            # å¾Œè™•ç†æ•¸æ“š
            self.data = self._post_process_data(result_data, config)

            # æ›´æ–°ç‹€æ…‹å’Œæ‘˜è¦
            self._update_final_state(config)

            return self.data

        except Exception as e:
            print(f"âŒ [ERROR] æ•¸æ“šè¼‰å…¥å¤±æ•—: {e}")
            self._display_error(f"æ•¸æ“šè¼‰å…¥å¤±æ•—: {e}")
            return None

    def _handle_skip_predictor_mode(
        self, config: Dict[str, Any]
    ) -> Optional[pd.DataFrame]:
        """è™•ç†è·³éé æ¸¬å› å­çš„æ¨¡å¼"""
        price_data = self._load_price_data_only(config)
        if price_data is None:
            return None
        self.using_price_predictor_only = True
        return self._apply_price_predictor_only(config, price_data)

    def _handle_predictor_load_failure(
        self, config: Dict[str, Any]
    ) -> Optional[pd.DataFrame]:
        """è™•ç†é æ¸¬å› å­è¼‰å…¥å¤±æ•—çš„æƒ…æ³"""
        print("âš ï¸ [WARNING] é æ¸¬å› å­è¼‰å…¥å¤±æ•—,å›é€€åˆ°ä½¿ç”¨åƒ¹æ ¼æ•¸æ“šä½œç‚ºé æ¸¬å› å­")
        fallback_price_data = self._load_price_data_only(config)
        if fallback_price_data is None:
            return None
        self.using_price_predictor_only = True
        return self._apply_price_predictor_only(config, fallback_price_data)

    def _load_and_merge_data(
        self, config: Dict[str, Any], predictor_data: pd.DataFrame
    ) -> Optional[pd.DataFrame]:
        """è¼‰å…¥åƒ¹æ ¼æ•¸æ“šä¸¦èˆ‡é æ¸¬å› å­åˆä½µ"""
        price_data = self._load_price_data_by_date_range(config, predictor_data)
        if price_data is None:
            return None

        merged_data = self._merge_predictor_and_price_data(predictor_data, price_data)
        if merged_data is None:
            return None

        # å°‡é æ¸¬å› å­ä¿¡æ¯å­˜å„²åˆ° data.attrs ä¸­
        self._store_predictor_info(config, merged_data)

        return merged_data

    def _store_predictor_info(
        self,
        config: Dict[str, Any],
        predictor_data: pd.DataFrame,  # pylint: disable=unused-argument
    ) -> None:
        """å­˜å„²é æ¸¬å› å­ä¿¡æ¯åˆ°æ•¸æ“šå±¬æ€§ä¸­"""
        predictor_config = config.get("predictor_config", {})
        predictor_path = predictor_config.get("predictor_path", "")
        predictor_column = predictor_config.get("predictor_column", "")

        if predictor_path:
            predictor_file_name = Path(predictor_path).stem
            if hasattr(predictor_data, "attrs"):
                predictor_data.attrs["predictor_file_name"] = predictor_file_name
                predictor_data.attrs["predictor_column"] = predictor_column

    def _post_process_data(
        self, processed_data: pd.DataFrame, config: Dict[str, Any]
    ) -> pd.DataFrame:
        """å¾Œè™•ç†æ•¸æ“šï¼šè¨ˆç®—å ±é…¬ç‡ã€è™•ç†å·®åˆ†ã€é©—è­‰æ•¸æ“š"""
        # è™•ç†å ±é…¬ç‡è¨ˆç®—
        if config.get("returns_config", {}).get("calculate_returns", False):
            processed_data = self._calculate_returns(config)

        # è™•ç†å·®åˆ†
        if config.get("difference_config", {}).get("enable_difference", False):
            processed_data = self._process_difference(config)

        # æ•¸æ“šé©—è­‰
        processed_data = self._validate_data(processed_data, config)

        return processed_data

    def _update_final_state(self, config: Dict[str, Any]) -> None:
        """æ›´æ–°æœ€çµ‚ç‹€æ…‹å’Œæ‘˜è¦"""
        # æ›´æ–°è¼‰å…¥æ‘˜è¦
        self._update_loading_summary(config)

        self.using_price_predictor_only = False
        predictor_column = config.get("predictor_config", {}).get("predictor_column")
        self.current_predictor_column = predictor_column

    def _load_yfinance_data(self, config: Dict[str, Any]) -> Optional[pd.DataFrame]:
        """è¼‰å…¥ Yahoo Finance æ•¸æ“š"""

        try:
            yfinance_config = config.get("yfinance_config")
            if yfinance_config is None:
                raise ValueError("dataloader.yfinance_config æœªè¨­å®š")

            symbol = self._require_config_field(
                yfinance_config, "symbol", "dataloader.yfinance_config"
            )
            _ = self._require_config_field(
                yfinance_config, "period", "dataloader.yfinance_config"
            )
            interval = self._require_config_field(
                yfinance_config, "interval", "dataloader.yfinance_config"
            )

            # å‰µå»ºè‡ªå®šç¾©çš„ YahooFinanceLoader ä¾†è™•ç†é…ç½®
            class ConfigurableYahooFinanceLoader(YahooFinanceLoader):
                """å¯é…ç½®çš„ YahooFinanceLoader"""

                def __init__(
                    self, symbol: str, frequency: str, start_date: str, end_date: str
                ) -> None:
                    super().__init__()
                    self._symbol = symbol
                    self._frequency = frequency
                    self._start_date = start_date
                    self._end_date = end_date

                def _get_ticker(self) -> str:
                    return self._symbol

                def _get_frequency(self) -> str:
                    return self._frequency

                def _get_date_range(self) -> Tuple[str, str]:
                    return self._start_date, self._end_date

            start_date = self._require_config_field(config, "start_date", "dataloader")

            end_date = config.get("end_date") or datetime.now().strftime("%Y-%m-%d")

            yfinance_loader = ConfigurableYahooFinanceLoader(
                symbol=symbol,
                frequency=interval,
                start_date=start_date,
                end_date=end_date,
            )

            yfinance_data, frequency = yfinance_loader.load()

            self.frequency = frequency
            self.source = "yfinance"
            if hasattr(yfinance_data, "attrs"):
                yfinance_data.attrs["frequency"] = frequency

            return yfinance_data

        except Exception as e:
            print(f"âŒ [ERROR] Yahoo Finance æ•¸æ“šè¼‰å…¥å¤±æ•—: {e}")
            return None

    def _load_binance_data(self, config: Dict[str, Any]) -> Optional[pd.DataFrame]:
        """è¼‰å…¥ Binance æ•¸æ“š"""

        try:
            binance_config = config.get("binance_config")
            if binance_config is None:
                raise ValueError("dataloader.binance_config æœªè¨­å®š")

            symbol = self._require_config_field(
                binance_config, "symbol", "dataloader.binance_config"
            )
            interval = self._require_config_field(
                binance_config, "interval", "dataloader.binance_config"
            )

            start_date = self._require_config_field(config, "start_date", "dataloader")
            end_date = config.get("end_date") or datetime.now().strftime("%Y-%m-%d")

            binance_loader = BinanceLoader()
            binance_loader.symbol = symbol
            binance_loader.interval = interval
            binance_loader.start_date = start_date
            binance_loader.end_date = end_date
            binance_data, frequency = binance_loader.load()

            self.frequency = frequency
            self.source = "binance"
            if hasattr(binance_data, "attrs"):
                binance_data.attrs["frequency"] = frequency

            return binance_data

        except Exception as e:
            print(f"âŒ [ERROR] Binance æ•¸æ“šè¼‰å…¥å¤±æ•—: {e}")
            return None

    def _load_coinbase_data(self, config: Dict[str, Any]) -> Optional[pd.DataFrame]:
        """è¼‰å…¥ Coinbase æ•¸æ“š"""

        try:
            coinbase_config = config.get("coinbase_config")
            if coinbase_config is None:
                raise ValueError("dataloader.coinbase_config æœªè¨­å®š")

            symbol = self._require_config_field(
                coinbase_config, "symbol", "dataloader.coinbase_config"
            )

            start_date = self._require_config_field(config, "start_date", "dataloader")
            end_date = config.get("end_date") or datetime.now().strftime("%Y-%m-%d")

            coinbase_loader = CoinbaseLoader()
            coinbase_loader.symbol = symbol
            coinbase_loader.start_date = start_date
            coinbase_loader.end_date = end_date
            coinbase_data, frequency = coinbase_loader.load()

            self.frequency = frequency
            self.source = "coinbase"
            if hasattr(coinbase_data, "attrs"):
                coinbase_data.attrs["frequency"] = frequency

            return coinbase_data

        except Exception as e:
            print(f"âŒ [ERROR] Coinbase æ•¸æ“šè¼‰å…¥å¤±æ•—: {e}")
            return None

    def _load_file_data(self, config: Dict[str, Any]) -> Optional[pd.DataFrame]:
        """è¼‰å…¥æ–‡ä»¶æ•¸æ“š"""

        try:
            file_config = config.get("file_config")
            if file_config is None:
                raise ValueError("dataloader.file_config æœªè¨­å®š")

            file_path = self._require_config_field(
                file_config, "file_path", "dataloader.file_config"
            )

            if not Path(file_path).exists():
                raise FileNotFoundError(f"æ‰¾ä¸åˆ°æ–‡ä»¶: {file_path}")

            file_loader = FileLoader()
            file_data, frequency = file_loader.load()

            self.frequency = frequency
            self.source = "file"
            if hasattr(file_data, "attrs"):
                file_data.attrs["frequency"] = frequency

            return file_data

        except Exception as e:
            print(f"âŒ [ERROR] æ–‡ä»¶æ•¸æ“šè¼‰å…¥å¤±æ•—: {e}")
            return None

    def _process_predictor(self, config: Dict[str, Any]) -> pd.DataFrame:
        """è™•ç†é æ¸¬å› å­"""

        try:
            predictor_config = config.get("predictor_config")
            if predictor_config is None:
                raise ValueError("dataloader.predictor_config æœªè¨­å®š")

            predictor_path = self._require_config_field(
                predictor_config, "predictor_path", "dataloader.predictor_config"
            )
            predictor_column = self._require_config_field(
                predictor_config, "predictor_column", "dataloader.predictor_config"
            )

            # é©—è­‰é æ¸¬å› å­æ–‡ä»¶è·¯å¾‘
            predictor_path_obj = self._validate_predictor_path(predictor_path)
            if predictor_path_obj is None:
                return self.data

            # å‰µå»ºä¸¦ä½¿ç”¨å¯é…ç½®çš„ PredictorLoader
            predictor_loader = self._create_configurable_predictor_loader(
                predictor_path, predictor_column
            )
            data_with_predictor = predictor_loader.load()

            if data_with_predictor is not None:
                return data_with_predictor

            print("âŒ [ERROR] é æ¸¬å› å­è¼‰å…¥å¤±æ•—")
            return self.data

        except Exception as e:
            print(f"âŒ [ERROR] é æ¸¬å› å­è™•ç†å¤±æ•—: {e}")
            return self.data

    def _validate_predictor_path(self, predictor_path: str) -> Optional[Path]:
        """é©—è­‰é æ¸¬å› å­æ–‡ä»¶è·¯å¾‘"""
        if not Path(predictor_path).is_absolute():
            # å¦‚æœæ˜¯ç›¸å°è·¯å¾‘ï¼Œå¾é …ç›®æ ¹ç›®éŒ„é–‹å§‹
            project_root = Path(__file__).parent.parent
            predictor_path_obj = project_root / predictor_path
        else:
            predictor_path_obj = Path(predictor_path)

        if not predictor_path_obj.exists():
            print(f"âŒ [ERROR] æ‰¾ä¸åˆ°é æ¸¬å› å­æ–‡ä»¶: {predictor_path_obj.absolute()}")
            return None

        return predictor_path_obj

    def _create_configurable_predictor_loader(
        self, predictor_path: str, predictor_column: str
    ) -> PredictorLoader:
        """å‰µå»ºå¯é…ç½®çš„ PredictorLoader"""

        class ConfigurablePredictorLoader(PredictorLoader):
            """å¯é…ç½®çš„ PredictorLoader"""

            def __init__(
                self, price_data: Any, predictor_path: str, predictor_column: str
            ) -> None:
                super().__init__(price_data)
                self._predictor_path = predictor_path
                self._predictor_column = predictor_column

            def _get_file_path(self) -> Optional[str]:
                return self._predictor_path

            def _get_time_format(self) -> Optional[str]:
                # è‡ªå‹•æ¨æ–·æ™‚é–“æ ¼å¼
                return None

        return ConfigurablePredictorLoader(self.data, predictor_path, predictor_column)

    def _process_difference(self, config: Dict[str, Any]) -> pd.DataFrame:
        """è™•ç†å·®åˆ†"""

        try:
            difference_config = config.get("difference_config", {})
            difference_config.get("difference_column")

            # æª¢æŸ¥æ˜¯å¦æœ‰é æ¸¬å› å­å¯ä»¥é€²è¡Œå·®åˆ†

            if self.data is None:
                return self.data

            available_factors = [
                col
                for col in self.data.columns
                if col
                not in [
                    "Time",
                    "Open",
                    "High",
                    "Low",
                    "Close",
                    "Volume",
                    "open_return",
                    "close_return",
                    "open_logreturn",
                    "close_logreturn",
                    "index",  # æ’é™¤æ™‚é–“ç´¢å¼•æ¬„ä½
                ]
            ]

            if not available_factors:
                return self.data

            # ä½¿ç”¨é…ç½®ä¸­é¸æ“‡çš„é æ¸¬å› å­é€²è¡Œå·®åˆ†
            predictor_config = config.get("predictor_config", {})
            selected_predictor = predictor_config.get("predictor_column", "aggregated")

            if selected_predictor not in available_factors:
                print(
                    f"âŒ [ERROR] é…ç½®çš„é æ¸¬å› å­ '{selected_predictor}' ä¸å­˜åœ¨æ–¼æ•¸æ“šä¸­"
                )
                return self.data

            predictor_loader = PredictorLoader(self.data)
            data_with_difference, _, _ = predictor_loader.process_difference(
                self.data, selected_predictor
            )

            return data_with_difference

        except Exception as e:
            print(f"âŒ [ERROR] å·®åˆ†è™•ç†å¤±æ•—: {e}")
            return self.data

    def _calculate_returns(
        self, config: Dict[str, Any]  # pylint: disable=unused-argument
    ) -> pd.DataFrame:
        """è¨ˆç®—æ”¶ç›Šç‡"""

        try:
            calculator = ReturnCalculator(self.data)
            data_with_returns = calculator.calculate_returns()

            return data_with_returns

        except Exception as e:
            print(f"âŒ [ERROR] æ”¶ç›Šç‡è¨ˆç®—å¤±æ•—: {e}")
            return self.data

    def _validate_data(
        self, validated_data: pd.DataFrame, config: Dict[str, Any]
    ) -> pd.DataFrame:
        """é©—è­‰æ•¸æ“š"""

        try:
            # åœ¨ autorunner æ¨¡å¼ä¸‹ï¼Œæˆ‘å€‘è·³ééœ€è¦ç”¨æˆ¶äº’å‹•çš„é©—è­‰
            # åªé€²è¡ŒåŸºæœ¬çš„æ•¸æ“šæª¢æŸ¥

            # æª¢æŸ¥å¿…è¦æ¬„ä½
            required_columns = ["Time", "Open", "High", "Low", "Close", "Volume"]
            missing_columns = [
                col for col in required_columns if col not in validated_data.columns
            ]

            if missing_columns:
                print(f"âš ï¸ [WARNING] ç¼ºå°‘å¿…è¦æ¬„ä½: {missing_columns}")

            # æª¢æŸ¥æ•¸æ“šå½¢ç‹€
            if validated_data.empty:
                print("âŒ [ERROR] æ•¸æ“šç‚ºç©º")
                return validated_data

            # è‡ªå‹•åŒ–è™•ç†ç¼ºå¤±å€¼
            validated_data = self._handle_missing_values_automated(
                validated_data, config
            )

            return validated_data

        except Exception as e:
            print(f"âŒ [ERROR] æ•¸æ“šé©—è­‰å¤±æ•—: {e}")
            return validated_data

    def _handle_missing_values_automated(
        self, missing_data: pd.DataFrame, config: Dict[str, Any]
    ) -> pd.DataFrame:
        """
        è‡ªå‹•åŒ–è™•ç†ç¼ºå¤±å€¼

        Args:
            missing_data: æ•¸æ“šæ¡†
            config: é…ç½®ä¿¡æ¯

        Returns:
            è™•ç†å¾Œçš„æ•¸æ“šæ¡†
        """

        try:
            handle_missing = config.get("handle_missing_values")
            missing_strategy = config.get("missing_value_strategy")

            if handle_missing != "fill" or not missing_strategy:
                print("âš ï¸ [WARNING] ç¼ºå¤±å€¼è™•ç†è¨­å®šä¸å®Œæ•´æˆ–é fillï¼Œç›´æ¥è¿”å›åŸå§‹è³‡æ–™")
                return missing_data

            # å®šç¾©éœ€è¦è™•ç†çš„æ¬„ä½ (åƒ¹æ ¼æ•¸æ“šæ¬„ä½)
            missing_columns = ["Open", "High", "Low", "Close", "Volume"]

            # æª¢æŸ¥é æ¸¬å› å­æ¬„ä½
            predictor_config = config.get("predictor_config", {})
            selected_predictor = predictor_config.get("predictor_column", "aggregated")

            # å¦‚æœé æ¸¬å› å­å·²è¼‰å…¥,ä¹ŸåŠ å…¥è™•ç†åˆ—è¡¨
            if not predictor_config.get("skip_predictor", False):
                if selected_predictor in missing_data.columns:
                    missing_columns.append(selected_predictor)
                    # å¦‚æœé æ¸¬å› å­æ²’æœ‰ç¼ºå¤±å€¼,æª¢æŸ¥å…¶ä»–æ¬„ä½
                    if missing_data[selected_predictor].isnull().sum() == 0:
                        # æª¢æŸ¥å…¶ä»–åƒ¹æ ¼æ¬„ä½æ˜¯å¦ä¹Ÿæ²’æœ‰ç¼ºå¤±å€¼
                        other_missing = sum(
                            missing_data[col].isnull().sum()
                            for col in ["Open", "High", "Low", "Close", "Volume"]
                            if col in missing_data.columns
                        )
                        if other_missing == 0:
                            return missing_data

            missing_data = self._fill_missing_values(missing_data, missing_columns, missing_strategy)
            return missing_data

        except Exception as e:
            print(f"âŒ [ERROR] ç¼ºå¤±å€¼è™•ç†å¤±æ•—: {e}")
            print(f"âŒ [ERROR] è©³ç´°éŒ¯èª¤: {traceback.format_exc()}")
            return missing_data

    def _fill_missing_values(
        self, fill_data: pd.DataFrame, missing_columns: list, strategy: str
    ) -> pd.DataFrame:
        """
        ä½¿ç”¨æŒ‡å®šçš„ç­–ç•¥å¡«å……ç¼ºå¤±å€¼

        Args:
            fill_data: æ•¸æ“šæ¡†
            missing_columns: æœ‰ç¼ºå¤±å€¼çš„æ¬„ä½åˆ—è¡¨
            strategy: å¡«å……ç­–ç•¥å­—ä¸²

        Returns:
            å¡«å……å¾Œçš„æ•¸æ“šæ¡†
        """

        try:
            for col in missing_columns:
                fill_data = self._apply_fill_strategy(fill_data, col, strategy)

            self._check_remaining_missing_values(fill_data)
            return fill_data

        except Exception as e:
            print(f"âŒ [ERROR] å¡«å……ç¼ºå¤±å€¼å¤±æ•—: {e}")
            print(f"âŒ [ERROR] è©³ç´°éŒ¯èª¤: {traceback.format_exc()}")
            return fill_data

    def _apply_fill_strategy(
        self, strategy_data: pd.DataFrame, col: str, strategy: str
    ) -> pd.DataFrame:
        """æ‡‰ç”¨ç‰¹å®šçš„å¡«å……ç­–ç•¥åˆ°æŒ‡å®šæ¬„ä½"""
        try:
            if strategy == "A":
                strategy_data[col] = strategy_data[col].ffill()
            elif strategy.startswith("B,"):
                n = int(strategy.split(",")[1])
                strategy_data[col] = strategy_data[col].fillna(
                    strategy_data[col].rolling(window=n, min_periods=1).mean()
                )
            elif strategy.startswith("C,"):
                value = float(strategy.split(",")[1])
                strategy_data[col] = strategy_data[col].fillna(value)
            else:
                print(f"âš ï¸ [WARNING] æœªçŸ¥çš„ç¼ºå¤±å€¼ç­–ç•¥ {strategy}ï¼Œä¿æŒåŸå§‹è³‡æ–™")
        except Exception as e:
            print(f"âš ï¸ [WARNING] ç¼ºå¤±å€¼ç­–ç•¥ {strategy} å¤±æ•—: {e}")

        return strategy_data

    def _check_remaining_missing_values(self, check_data: pd.DataFrame) -> None:
        """æª¢æŸ¥å¡«å……å¾Œæ˜¯å¦é‚„æœ‰ç¼ºå¤±å€¼"""
        remaining_missing = check_data.isnull().sum().sum()
        if remaining_missing > 0:
            print(f"âš ï¸ [WARNING] å¡«å……å¾Œä»æœ‰ {remaining_missing} å€‹ç¼ºå¤±å€¼")

    def _update_loading_summary(self, config: Dict[str, Any]) -> None:
        """æ›´æ–°è¼‰å…¥æ‘˜è¦"""

        self.loading_summary = {
            "source": self.source,
            "frequency": self.frequency,
            "data_shape": self.data.shape if self.data is not None else (0, 0),
            "columns": list(self.data.columns) if self.data is not None else [],
            "date_range": self._get_date_range(),
            "config_used": {
                "source": config.get("source"),
                "start_date": config.get("start_date"),
                "end_date": config.get("end_date"),
            },
        }

    def _get_date_range(self) -> Tuple[str, str]:
        """ç²å–æ•¸æ“šæ—¥æœŸç¯„åœ"""
        if self.data is None or "Time" not in self.data.columns:
            return "N/A", "N/A"

        try:
            start_date = self.data["Time"].min().strftime("%Y-%m-%d")
            end_date = self.data["Time"].max().strftime("%Y-%m-%d")
            return start_date, end_date
        except Exception:
            return "N/A", "N/A"

    def get_loading_summary(self) -> Dict[str, Any]:
        """
        ç²å–è¼‰å…¥æ‘˜è¦

        Returns:
            Dict[str, Any]: è¼‰å…¥æ‘˜è¦ä¿¡æ¯
        """
        return self.loading_summary.copy()

    def display_loading_summary(self) -> None:
        """é¡¯ç¤ºè¼‰å…¥æ‘˜è¦"""

        if not self.loading_summary:
            console.print(
                Panel(
                    "âŒ æ²’æœ‰è¼‰å…¥æ‘˜è¦ä¿¡æ¯",
                    title=Text("âš ï¸ è¼‰å…¥æ‘˜è¦", style="bold #8f1511"),
                    border_style="#8f1511",
                )
            )
            return

        # å‰µå»ºæ‘˜è¦è¡¨æ ¼
        table = Table(title="ğŸ“Š æ•¸æ“šè¼‰å…¥æ‘˜è¦")
        table.add_column("é …ç›®", style="cyan")
        table.add_column("å€¼", style="magenta")

        table.add_row("æ•¸æ“šæº", self.loading_summary.get("source", "N/A"))
        table.add_row("é »ç‡", self.loading_summary.get("frequency", "N/A"))
        table.add_row(
            "æ•¸æ“šå½¢ç‹€",
            f"{self.loading_summary.get('data_shape', (0, 0))[0]} è¡Œ x {self.loading_summary.get('data_shape', (0, 0))[1]} åˆ—",
        )

        date_range = self.loading_summary.get("date_range", ("N/A", "N/A"))
        table.add_row("æ—¥æœŸç¯„åœ", f"{date_range[0]} è‡³ {date_range[1]}")

        columns = self.loading_summary.get("columns", [])
        table.add_row("æ¬„ä½æ•¸é‡", str(len(columns)))
        table.add_row(
            "ä¸»è¦æ¬„ä½", ", ".join(columns[:5]) + ("..." if len(columns) > 5 else "")
        )

        console.print(table)

        # é¡¯ç¤ºè¼‰å…¥æˆåŠŸä¿¡æ¯
        console.print(
            Panel(
                f"âœ… æ•¸æ“šè¼‰å…¥æˆåŠŸï¼è¼‰å…¥äº† {self.loading_summary.get('data_shape', (0, 0))[0]} è¡Œæ•¸æ“š",
                title=Text("ğŸ‰ è¼‰å…¥æˆåŠŸ", style="bold green"),
                border_style="green",
            )
        )

    def _display_error(self, message: str) -> None:
        """
        é¡¯ç¤ºéŒ¯èª¤ä¿¡æ¯

        Args:
            message: éŒ¯èª¤ä¿¡æ¯
        """

        console.print(
            Panel(
                f"âŒ {message}",
                title=Text("âš ï¸ æ•¸æ“šè¼‰å…¥éŒ¯èª¤", style="bold #8f1511"),
                border_style="#8f1511",
            )
        )

    def _load_predictor_data(self, config: Dict[str, Any]) -> Optional[pd.DataFrame]:
        """è¼‰å…¥é æ¸¬å› å­æ•¸æ“š"""

        try:
            predictor_config = config.get("predictor_config", {})
            predictor_path = predictor_config.get("predictor_path", "")
            predictor_column = predictor_config.get("predictor_column")

            # é©—è­‰åŸºæœ¬é…ç½®
            if not self._validate_predictor_config(predictor_path, predictor_column):
                return None

            # è™•ç†æ–‡ä»¶è·¯å¾‘
            predictor_path_obj = self._resolve_predictor_path(predictor_path)
            if predictor_path_obj is None:
                return None

            # è®€å–é æ¸¬å› å­æ•¸æ“š
            predictor_data = self._read_predictor_file(predictor_path_obj)
            if predictor_data is None:
                return None

            # è™•ç†æ™‚é–“å’Œé æ¸¬å› å­æ¬„ä½
            predictor_data = self._process_predictor_columns(
                predictor_data, predictor_config, predictor_column
            )
            if predictor_data is None:
                return None

            # é¡¯ç¤ºè¼‰å…¥æˆåŠŸä¿¡æ¯
            self._display_predictor_load_success(
                predictor_path_obj, predictor_column, predictor_data
            )

            return predictor_data

        except Exception as e:
            print(f"âŒ [ERROR] é æ¸¬å› å­æ•¸æ“šè¼‰å…¥å¤±æ•—: {e}")
            print(f"è©³ç´°éŒ¯èª¤:\n{traceback.format_exc()}")
            return None

    def _validate_predictor_config(
        self, predictor_path: str, predictor_column: str
    ) -> bool:
        """é©—è­‰é æ¸¬å› å­é…ç½®"""
        if not predictor_path:
            return False

        if not predictor_column:
            print("âŒ [ERROR] æœªæŒ‡å®š predictor_column")
            return False

        return True

    def _resolve_predictor_path(self, predictor_path: str) -> Optional[Path]:
        """è§£æé æ¸¬å› å­æ–‡ä»¶è·¯å¾‘"""
        if not Path(predictor_path).is_absolute():
            project_root = Path(__file__).parent.parent
            predictor_path_obj = project_root / predictor_path
        else:
            predictor_path_obj = Path(predictor_path)

        if not predictor_path_obj.exists():
            print(f"âŒ [ERROR] é æ¸¬å› å­æ–‡ä»¶ä¸å­˜åœ¨: {predictor_path_obj}")
            return None

        return predictor_path_obj

    def _read_predictor_file(self, predictor_path_obj: Path) -> Optional[pd.DataFrame]:
        """è®€å–é æ¸¬å› å­æ–‡ä»¶"""
        suffix = predictor_path_obj.suffix.lower()
        try:
            if suffix in [".xlsx", ".xls"]:
                return pd.read_excel(predictor_path_obj)
            if suffix == ".csv":
                return pd.read_csv(predictor_path_obj)

            print(f"âŒ [ERROR] ä¸æ”¯æ´çš„æ–‡ä»¶æ ¼å¼: {suffix}")
            return None
        except Exception as e:
            print(f"âŒ [ERROR] è®€å–é æ¸¬å› å­æ–‡ä»¶å¤±æ•—: {e}")
            return None

    def _process_predictor_columns(
        self,
        predictor_data: pd.DataFrame,
        predictor_config: Dict[str, Any],
        predictor_column: str,
    ) -> Optional[pd.DataFrame]:
        """è™•ç†é æ¸¬å› å­çš„æ™‚é–“å’Œé æ¸¬å› å­æ¬„ä½"""
        time_col = predictor_config.get("time_column")
        if not time_col:
            print("âŒ [ERROR] æœªæŒ‡å®š time_column")
            return None

        if time_col not in predictor_data.columns:
            print(f"âŒ [ERROR] æ™‚é–“æ¬„ä½ {time_col} ä¸å­˜åœ¨æ–¼é æ¸¬å› å­æ–‡ä»¶ä¸­")
            print(f"å¯ç”¨æ¬„ä½: {list(predictor_data.columns)}")
            return None

        if predictor_column not in predictor_data.columns:
            print(f"âŒ [ERROR] é æ¸¬å› å­æ¬„ä½ {predictor_column} ä¸å­˜åœ¨æ–¼æ–‡ä»¶ä¸­")
            print(f"å¯ç”¨æ¬„ä½: {list(predictor_data.columns)}")
            return None

        # åªä¿ç•™æ™‚é–“æ¬„ä½å’Œé æ¸¬å› å­æ¬„ä½
        predictor_data = predictor_data[[time_col, predictor_column]].copy()

        # è™•ç†æ™‚é–“æ ¼å¼
        time_format = predictor_config.get("time_format")
        if time_format:
            predictor_data.loc[:, time_col] = pd.to_datetime(
                predictor_data[time_col], format=time_format
            )
        else:
            predictor_data.loc[:, time_col] = pd.to_datetime(predictor_data[time_col])

        predictor_data = predictor_data.set_index(time_col)
        return predictor_data

    def _display_predictor_load_success(
        self,
        predictor_path_obj: Path,
        predictor_column: str,
        predictor_data: pd.DataFrame,
    ) -> None:
        """é¡¯ç¤ºé æ¸¬å› å­è¼‰å…¥æˆåŠŸä¿¡æ¯"""
        console.print(
            Panel(
                f"âœ… é æ¸¬å› å­è¼‰å…¥æˆåŠŸ\n"
                f"ğŸ“ æ–‡ä»¶: {predictor_path_obj.name}\n"
                f"ğŸ“Š æ¬„ä½: {predictor_column}\n"
                f"ğŸ“ æ•¸æ“šé‡: {len(predictor_data)} è¡Œ",
                title="[bold #dbac30]ğŸ“Š æ•¸æ“šè¼‰å…¥ Dataloader[/bold #dbac30]",
                border_style="#dbac30",
            )
        )

    def _load_price_data_by_date_range(
        self, config: Dict[str, Any], predictor_data: pd.DataFrame
    ) -> Optional[pd.DataFrame]:
        """æ ¹æ“šé æ¸¬å› å­æ—¥æœŸç¯„åœè¼‰å…¥åƒ¹æ ¼æ•¸æ“š"""

        try:
            # ç²å–é æ¸¬å› å­çš„æ—¥æœŸç¯„åœ
            start_date = predictor_data.index.min().strftime("%Y-%m-%d")
            end_date = predictor_data.index.max().strftime("%Y-%m-%d")

            # é¸æ“‡æ•¸æ“šæº
            source = config.get("source", "yfinance")

            # æ ¹æ“šæ•¸æ“šæºè¼‰å…¥åƒ¹æ ¼æ•¸æ“š
            if source == "yfinance":
                return self._load_yfinance_data_by_date(config, start_date, end_date)
            if source == "binance":
                return self._load_binance_data_by_date(config, start_date, end_date)
            if source == "coinbase":
                return self._load_coinbase_data_by_date(config, start_date, end_date)
            if source == "file":
                return self._load_file_data_by_date(config, start_date, end_date)

            print(f"âŒ [ERROR] ä¸æ”¯æ´çš„åƒ¹æ ¼æ•¸æ“šæº: {source}")
            return None

        except Exception as e:
            print(f"âŒ [ERROR] æ ¹æ“šæ—¥æœŸç¯„åœè¼‰å…¥åƒ¹æ ¼æ•¸æ“šå¤±æ•—: {e}")
            return None

    def _load_price_data_only(self, config: Dict[str, Any]) -> Optional[pd.DataFrame]:
        """åƒ…è¼‰å…¥åƒ¹æ ¼æ•¸æ“šï¼ˆè·³éé æ¸¬å› å­æ™‚ä½¿ç”¨ï¼‰"""

        try:
            source = config.get("source", "yfinance")

            # æ ¹æ“šæ•¸æ“šæºè¼‰å…¥åƒ¹æ ¼æ•¸æ“š
            if source == "yfinance":
                self.data = self._load_yfinance_data(config)
            elif source == "binance":
                self.data = self._load_binance_data(config)
            elif source == "coinbase":
                self.data = self._load_coinbase_data(config)
            elif source == "file":
                self.data = self._load_file_data(config)
            else:
                print(f"âŒ [ERROR] ä¸æ”¯æ´çš„åƒ¹æ ¼æ•¸æ“šæº: {source}")
                return None

            if self.data is None:
                return None

            # è¨ˆç®—æ”¶ç›Šç‡
            if config.get("returns_config", {}).get("calculate_returns", False):
                self.data = self._calculate_returns(config)

            # æ•¸æ“šé©—è­‰
            self.data = self._validate_data(self.data, config)

            # æ›´æ–°è¼‰å…¥æ‘˜è¦
            self._update_loading_summary(config)

            return self.data

        except Exception as e:
            print(f"âŒ [ERROR] åƒ¹æ ¼æ•¸æ“šè¼‰å…¥å¤±æ•—: {e}")
            return None

    def _apply_price_predictor_only(
        self, config: Dict[str, Any], price_data: pd.DataFrame
    ) -> Optional[pd.DataFrame]:
        """ä½¿ç”¨åƒ¹æ ¼è³‡æ–™ä½œç‚ºé æ¸¬å› å­å®Œæˆå¾ŒçºŒæµç¨‹"""

        price_data = price_data.copy()
        price_data["Price_predictor"] = price_data["Close"].copy()
        predictor_config = config.setdefault("predictor_config", {})
        predictor_config["predictor_column"] = "Price_predictor"
        predictor_config["skip_predictor"] = True

        self.data = price_data
        self.current_predictor_column = "Price_predictor"
        self.using_price_predictor_only = True

        self.data = self._process_difference(config)

        self.data = self._validate_data(self.data, config)
        self._update_loading_summary(config)
        return self.data

    def _merge_predictor_and_price_data(
        self, predictor_data: pd.DataFrame, price_data: pd.DataFrame
    ) -> Optional[pd.DataFrame]:
        """åˆä½µé æ¸¬å› å­å’Œåƒ¹æ ¼æ•¸æ“š"""

        try:
            # ç¢ºä¿åƒ¹æ ¼æ•¸æ“šçš„ Time ç‚ºç´¢å¼•
            if "Time" not in price_data.index.names:
                if "Time" in price_data.columns:
                    price_data = price_data.set_index("Time")
                else:
                    print("âŒ [ERROR] åƒ¹æ ¼æ•¸æ“šç¼ºå°‘ 'Time' æ¬„ä½æˆ–ç´¢å¼•")
                    return None

            # æ™‚é–“å°é½Šï¼ˆinner joinï¼‰
            merged = price_data.merge(
                predictor_data, left_index=True, right_index=True, how="inner"
            )

            if merged.empty:
                print("âŒ [ERROR] åƒ¹æ ¼æ•¸æ“šèˆ‡é æ¸¬å› å­æ•¸æ“šç„¡æ™‚é–“äº¤é›†ï¼Œç„¡æ³•åˆä½µ")
                return None

            # é‡ç½®ç´¢å¼•ä¸¦é‡å‘½åç‚º Time æ¬„ä½ï¼ˆä¿æŒèˆ‡ dataloader ä¸€è‡´ï¼‰
            merged = merged.reset_index()
            if "index" in merged.columns:
                merged = merged.rename(columns={"index": "Time"})

            # ç¢ºä¿ Time æ¬„ä½æ ¼å¼æ­£ç¢º
            merged["Time"] = pd.to_datetime(merged["Time"])

            # é¡¯ç¤ºåˆä½µæˆåŠŸä¿¡æ¯
            predictor_cols = [
                col
                for col in merged.columns
                if col not in ["Time", "Open", "High", "Low", "Close", "Volume"]
            ]
            console.print(
                Panel(
                    f"âœ… é æ¸¬å› å­èˆ‡åƒ¹æ ¼æ•¸æ“šåˆä½µæˆåŠŸ\n"
                    f"ğŸ“Š é æ¸¬å› å­æ¬„ä½: {', '.join(predictor_cols)}\n"
                    f"ğŸ“ åˆä½µå¾Œæ•¸æ“šé‡: {len(merged)} è¡Œ",
                    title="[bold #dbac30]ğŸ“Š æ•¸æ“šè¼‰å…¥ Dataloader[/bold #dbac30]",
                    border_style="#dbac30",
                )
            )

            return merged

        except Exception as e:
            print(f"âŒ [ERROR] æ•¸æ“šåˆä½µå¤±æ•—: {e}")
            return None

    def _load_yfinance_data_by_date(
        self, config: Dict[str, Any], start_date: str, end_date: str
    ) -> Optional[pd.DataFrame]:
        """æ ¹æ“šæŒ‡å®šæ—¥æœŸç¯„åœè¼‰å…¥ Yahoo Finance æ•¸æ“š"""

        try:
            yfinance_config = config.get("yfinance_config", {})
            symbol = yfinance_config.get("symbol", "AAPL")
            interval = yfinance_config.get("interval", "1d")

            # å‰µå»ºè‡ªå®šç¾©çš„ YahooFinanceLoader
            class ConfigurableYahooFinanceLoader(YahooFinanceLoader):
                """å¯é…ç½®çš„ YahooFinanceLoader"""

                def __init__(
                    self, symbol: str, frequency: str, start_date: str, end_date: str
                ) -> None:
                    super().__init__()
                    self._symbol = symbol
                    self._frequency = frequency
                    self._start_date = start_date
                    self._end_date = end_date

                def _get_ticker(self) -> str:
                    return self._symbol

                def _get_frequency(self) -> str:
                    return self._frequency

                def _get_date_range(self) -> Tuple[str, str]:
                    return self._start_date, self._end_date

            yfinance_loader_by_date = ConfigurableYahooFinanceLoader(
                symbol=symbol,
                frequency=interval,
                start_date=start_date,
                end_date=end_date,
            )

            yfinance_data_by_date, frequency = yfinance_loader_by_date.load()

            self.frequency = frequency
            self.source = "yfinance"
            if hasattr(yfinance_data_by_date, "attrs"):
                yfinance_data_by_date.attrs["frequency"] = frequency

            return yfinance_data_by_date

        except Exception as e:
            print(f"âŒ [ERROR] Yahoo Finance æ•¸æ“šè¼‰å…¥å¤±æ•—: {e}")
            return None

    def _load_binance_data_by_date(
        self, config: Dict[str, Any], start_date: str, end_date: str
    ) -> Optional[pd.DataFrame]:
        """æ ¹æ“šæŒ‡å®šæ—¥æœŸç¯„åœè¼‰å…¥ Binance æ•¸æ“š"""

        try:

            binance_config = config.get("binance_config", {})
            symbol = binance_config.get("symbol", "BTCUSDT")
            interval = binance_config.get("interval", "1d")

            # ä½¿ç”¨ç„¡æ†‘è­‰çš„ Client
            client = Client()
            klines = client.get_historical_klines(
                symbol, interval, start_date, end_date
            )

            if not klines:
                print(f"âŒ [ERROR] ç„¡æ³•ç²å– '{symbol}' çš„æ•¸æ“š")
                return None

            # è½‰æ›ç‚º DataFrame
            binance_data_by_date = pd.DataFrame(
                klines,
                columns=[
                    "timestamp",
                    "open",
                    "high",
                    "low",
                    "close",
                    "volume",
                    "close_time",
                    "quote_asset_volume",
                    "number_of_trades",
                    "taker_buy_base_asset_volume",
                    "taker_buy_quote_asset_volume",
                    "ignore",
                ],
            )

            # é‡å‘½åæ¬„ä½ç‚ºæ¨™æº–æ ¼å¼
            binance_data_by_date = binance_data_by_date.rename(
                columns={
                    "timestamp": "Time",
                    "open": "Open",
                    "high": "High",
                    "low": "Low",
                    "close": "Close",
                    "volume": "Volume",
                }
            )

            # è½‰æ›æ™‚é–“æ ¼å¼
            binance_data_by_date["Time"] = pd.to_datetime(binance_data_by_date["Time"], unit="ms")

            # é¸æ“‡éœ€è¦çš„æ¬„ä½
            binance_data_by_date = binance_data_by_date[["Time", "Open", "High", "Low", "Close", "Volume"]]

            # è½‰æ›ç‚ºæ•¸å€¼é¡å‹
            binance_data_by_date[["Open", "High", "Low", "Close", "Volume"]] = binance_data_by_date[
                ["Open", "High", "Low", "Close", "Volume"]
            ].astype(float)

            # è¨­ç½®ç´¢å¼•ç‚º Time
            binance_data_by_date = binance_data_by_date.set_index("Time")

            self.frequency = interval
            self.source = "binance"
            if hasattr(binance_data_by_date, "attrs"):
                binance_data_by_date.attrs["frequency"] = interval

            return binance_data_by_date

        except Exception as e:
            print(f"âŒ [ERROR] Binance æ•¸æ“šè¼‰å…¥å¤±æ•—: {e}")
            return None

    def _load_coinbase_data_by_date(  # pylint: disable=too-many-locals
        self, config: Dict[str, Any], start_date: str, end_date: str
    ) -> Optional[pd.DataFrame]:
        """æ ¹æ“šæŒ‡å®šæ—¥æœŸç¯„åœè¼‰å…¥ Coinbase æ•¸æ“š"""

        try:

            coinbase_config = config.get("coinbase_config", {})
            symbol = coinbase_config.get("symbol", "BTC-USD")
            granularity = 86400  # 1d = 86400 seconds

            # è½‰æ›ç‚º datetime å°è±¡ï¼ˆç¢ºä¿æ ¼å¼æ­£ç¢ºï¼‰
            start_dt = datetime.strptime(start_date, "%Y-%m-%d")
            end_dt = datetime.strptime(end_date, "%Y-%m-%d")

            # Coinbase API æœ‰é™åˆ¶ï¼Œæ¯æ¬¡è«‹æ±‚æœ€å¤š 300 å€‹æ•¸æ“šé»
            # éœ€è¦åˆ†æ‰¹è«‹æ±‚æ•¸æ“š
            all_data = []

            # è¨ˆç®—æ¯æ‰¹çš„æ™‚é–“ç¯„åœ
            max_candles = 300
            seconds_per_candle = granularity
            batch_seconds = max_candles * seconds_per_candle

            current_start = start_dt

            while current_start < end_dt:
                current_end = min(
                    current_start + timedelta(seconds=batch_seconds), end_dt
                )

                # Coinbase Exchange API endpoint (public, no auth required)
                url = f"https://api.exchange.coinbase.com/products/{symbol}/candles"
                params = {
                    "start": current_start.isoformat(),
                    "end": current_end.isoformat(),
                    "granularity": granularity,
                }

                response = requests.get(url, params=params)

                if response.status_code != 200:
                    print(
                        f"âŒ [ERROR] API è«‹æ±‚å¤±æ•—ï¼š{response.status_code} - {response.text}"
                    )
                    return None

                candles = response.json()

                if candles:
                    all_data.extend(candles)

                # ç§»å‹•åˆ°ä¸‹ä¸€æ‰¹
                current_start = current_end

            if not all_data:
                print(f"âŒ [ERROR] ç„¡æ³•ç²å– '{symbol}' çš„æ•¸æ“š")
                return None

            # è½‰æ›ç‚º DataFrame
            # Coinbase API è¿”å›æ ¼å¼: [timestamp, low, high, open, close, volume]
            coinbase_data_by_date = pd.DataFrame(
                all_data,
                columns=[
                    "timestamp",
                    "low",
                    "high",
                    "open",
                    "close",
                    "volume",
                ],
            )

            # é‡å‘½åæ¬„ä½ç‚ºæ¨™æº–æ ¼å¼
            coinbase_data_by_date = coinbase_data_by_date.rename(
                columns={
                    "timestamp": "Time",
                    "open": "Open",
                    "high": "High",
                    "low": "Low",
                    "close": "Close",
                    "volume": "Volume",
                }
            )

            # è½‰æ›æ™‚é–“æ ¼å¼
            coinbase_data_by_date["Time"] = pd.to_datetime(coinbase_data_by_date["Time"], unit="s")

            # é¸æ“‡éœ€è¦çš„æ¬„ä½
            coinbase_data_by_date = coinbase_data_by_date[["Time", "Open", "High", "Low", "Close", "Volume"]]

            # è½‰æ›ç‚ºæ•¸å€¼é¡å‹
            coinbase_data_by_date[["Open", "High", "Low", "Close", "Volume"]] = coinbase_data_by_date[
                ["Open", "High", "Low", "Close", "Volume"]
            ].astype(float)

            # è¨­ç½®ç´¢å¼•ç‚º Time
            coinbase_data_by_date = coinbase_data_by_date.set_index("Time")

            self.frequency = "1d"
            self.source = "coinbase"
            if hasattr(coinbase_data_by_date, "attrs"):
                coinbase_data_by_date.attrs["frequency"] = "1d"

            return coinbase_data_by_date

        except Exception as e:
            print(f"âŒ [ERROR] Coinbase æ•¸æ“šè¼‰å…¥å¤±æ•—: {e}")
            return None

    def _load_file_data_by_date(
        self, config: Dict[str, Any], start_date: str, end_date: str
    ) -> Optional[pd.DataFrame]:
        """æ ¹æ“šæŒ‡å®šæ—¥æœŸç¯„åœè¼‰å…¥æ–‡ä»¶æ•¸æ“š"""

        try:
            # é©—è­‰å’Œè§£æé…ç½®
            file_config = self._validate_file_config(config)
            if file_config is None:
                return None

            # è®€å–æ–‡ä»¶æ•¸æ“š
            file_data_by_date = self._read_file_data(file_config["file_path"])
            if file_data_by_date is None:
                return None

            # è™•ç†æ¬„ä½æ˜ å°„å’Œé‡å‘½å
            file_data_by_date = self._process_file_columns(file_data_by_date, file_config)
            if file_data_by_date is None:
                return None

            # è™•ç†æ™‚é–“æ ¼å¼å’Œæ—¥æœŸéæ¿¾
            file_data_by_date = self._process_file_time_and_filter(file_data_by_date, start_date, end_date)

            # è¨­ç½®æœ€çµ‚å±¬æ€§
            self._set_file_data_attributes(file_data_by_date)

            return file_data_by_date

        except Exception as e:
            print(f"âŒ [ERROR] æ–‡ä»¶æ•¸æ“šè¼‰å…¥å¤±æ•—: {e}")
            return None

    def _validate_file_config(self, config: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """é©—è­‰æ–‡ä»¶é…ç½®"""
        if "file_config" not in config:
            raise ValueError("dataloader.file_config æœªè¨­å®š")

        file_config = config["file_config"]

        try:
            required_fields = [
                "file_path",
                "time_column",
                "open_column",
                "high_column",
                "low_column",
                "close_column",
            ]
            for field in required_fields:
                if field not in file_config:
                    raise ValueError(f"dataloader.file_config ç¼ºå°‘åƒæ•¸: {field}")

            if not file_config["file_path"]:
                raise ValueError("dataloader.file_config.file_path ä¸å¯ç‚ºç©º")

            # æª¢æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(file_config["file_path"]):
                print(f"âŒ [ERROR] æ–‡ä»¶ä¸å­˜åœ¨: {file_config['file_path']}")
                return None

            return file_config

        except KeyError as missing:
            raise ValueError(f"dataloader.file_config ç¼ºå°‘åƒæ•¸: {missing.args[0]}") from missing

    def _read_file_data(self, file_path: str) -> Optional[pd.DataFrame]:
        """è®€å–æ–‡ä»¶æ•¸æ“š"""
        try:
            if file_path.lower().endswith(".csv"):
                return pd.read_csv(file_path)
            if file_path.lower().endswith((".xlsx", ".xls")):
                return pd.read_excel(file_path)

            print(f"âŒ [ERROR] ä¸æ”¯æ´çš„æ–‡ä»¶æ ¼å¼: {file_path}")
            return None
        except Exception as e:
            print(f"âŒ [ERROR] è®€å–æ–‡ä»¶å¤±æ•—: {e}")
            return None

    def _process_file_columns(
        self, process_data: pd.DataFrame, file_config: Dict[str, Any]
    ) -> Optional[pd.DataFrame]:
        """è™•ç†æ–‡ä»¶æ¬„ä½æ˜ å°„å’Œé‡å‘½å"""
        # å‰µå»ºæ¬„ä½æ˜ å°„
        column_mapping = {
            file_config["time_column"]: "Time",
            file_config["open_column"]: "Open",
            file_config["high_column"]: "High",
            file_config["low_column"]: "Low",
            file_config["close_column"]: "Close",
        }

        # å¦‚æœæœ‰ Volume æ¬„ä½ï¼Œå‰‡æ·»åŠ æ˜ å°„
        volume_column = file_config.get("volume_column")
        if volume_column:
            column_mapping[volume_column] = "Volume"

        process_data = process_data.rename(columns=column_mapping)

        # ç¢ºä¿ Time æ¬„ä½å­˜åœ¨
        if "Time" not in process_data.columns:
            print(f"âŒ [ERROR] æ‰¾ä¸åˆ°æ™‚é–“æ¬„ä½: {file_config['time_column']}")
            return None

        return process_data

    def _process_file_time_and_filter(
        self, filter_data: pd.DataFrame, start_date: str, end_date: str
    ) -> pd.DataFrame:
        """è™•ç†æ™‚é–“æ ¼å¼å’Œæ—¥æœŸéæ¿¾"""
        # è½‰æ›æ™‚é–“æ ¼å¼ï¼ˆæ”¯æŒå¤šç¨®æ ¼å¼ï¼‰
        try:
            # å˜—è©¦ DD/MM/YYYY æ ¼å¼
            filter_data["Time"] = pd.to_datetime(filter_data["Time"], format="%d/%m/%Y")
        except (ValueError, TypeError):
            try:
                # å˜—è©¦ YYYY-MM-DD æ ¼å¼
                filter_data["Time"] = pd.to_datetime(filter_data["Time"], format="%Y-%m-%d")
            except (ValueError, TypeError):
                # è®“ pandas è‡ªå‹•æ¨æ–·æ ¼å¼
                filter_data["Time"] = pd.to_datetime(filter_data["Time"], dayfirst=True)

        # æ ¹æ“šæ—¥æœŸç¯„åœéæ¿¾æ•¸æ“š
        filter_data = filter_data[(filter_data["Time"] >= start_date) & (filter_data["Time"] <= end_date)]

        # é¸æ“‡éœ€è¦çš„æ¬„ä½ï¼ˆVolume ç‚ºå¯é¸ï¼‰
        required_columns = ["Time", "Open", "High", "Low", "Close"]
        optional_columns = ["Volume"]
        available_columns = [col for col in required_columns if col in filter_data.columns]
        available_columns.extend(
            [col for col in optional_columns if col in filter_data.columns]
        )
        filter_data = filter_data[available_columns]

        # è½‰æ›ç‚ºæ•¸å€¼é¡å‹
        numeric_columns = [
            col
            for col in ["Open", "High", "Low", "Close", "Volume"]
            if col in filter_data.columns
        ]
        filter_data[numeric_columns] = filter_data[numeric_columns].astype(float)

        # è¨­ç½®ç´¢å¼•ç‚º Time
        filter_data = filter_data.set_index("Time")

        return filter_data

    def _set_file_data_attributes(self, attr_data: pd.DataFrame) -> None:
        """è¨­ç½®æ–‡ä»¶æ•¸æ“šå±¬æ€§"""
        self.frequency = "1d"
        self.source = "file"
        if hasattr(attr_data, "attrs"):
            attr_data.attrs["frequency"] = "1d"


if __name__ == "__main__":
    # æ¸¬è©¦æ¨¡å¼

    # å‰µå»ºè¼‰å…¥å™¨å¯¦ä¾‹
    loader = DataLoaderAutorunner()

    # æ¸¬è©¦é…ç½®
    test_config = {
        "source": "yfinance",
        "start_date": "2020-01-01",
        "end_date": "2024-01-01",
        "yfinance_config": {"symbol": "AAPL", "period": "1y", "interval": "1d"},
        "predictor_config": {"skip_predictor": True},
        "difference_config": {"enable_difference": False},
        "returns_config": {"calculate_returns": True},
    }

    # æ¸¬è©¦è¼‰å…¥åŠŸèƒ½
    data = loader.load_data(test_config)
    if data is not None:
        loader.display_loading_summary()
